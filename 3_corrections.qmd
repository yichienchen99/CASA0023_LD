---
title: "Corrections"
bibliography: references.bib
---

[Week3: 24&26/Jan/2024]{.underline}

Corrections and enhancement are the two main concepts in this week's teaching. They are the pre-processing of EO data to ensure the data used in the classification/analysis is consistent and usable.

## Summary

### Corrections

4 types of corrections are Geometric, Atmospheric, Topographic and Radiometric.

#### Geometric corrections

Geometric corrections

:   A process to adjust the imagery to correct distortions caused by sensor or terrain with reference to the [ground central points (GCPs)]{.underline}, to ensure the true location of features on Earth's surface, usually, making **off-nadir** (the sensor is tilted at an angle to the Earth's surface, which can result in distortions in the image due to parallax effects) to **nadir** (an image acquired with the imaging sensor pointing straight down, perpendicular to the Earth's surface. The nadir angle =0 degrees).

    Requirement: same resolution (resampling) and same CRS (reprojecting).

::: {.callout-tip style="color: green" appearance="minimal"}
This is especially useful for ancient/historic data that is tilted for certain reasons (see Application section). Correction also improves the data accuracy (esp. important for applications requiring precision like land use mapping, crop monitoring, and disaster management), consistency (that is required for long-term/longitudinal analysis) and allows easier interpretation and analysis (for fusion/overlay, etc. ).
:::

::: {.callout-important style="color: red" appearance="minimal"}
Nevertheless, slight limitations of corrections should be carefully catered for. Some data might be lost and resolution may be reduced after correction. Errors might occur with inaccurate reference data. \> To reduce error, the number of GCPs can be increased.
:::

Ground central point

:   A ground control point (GCP) is a location on the surface of the Earth (e.g., a road intersection) that can be identified on the imagery and located accurately on a map. (Objects (e.g. building) on the image that do not move, as the reference point of corrections.) - correction is basically doing linear regression to the coordination of GCPs.

Image-to-map rectification

:   rectify remotely sensed data to a standard map projection

Image-to-image registration

:   remotely sensed data used in conjunction with other spatial information in a GIS

Forward mapping

:   X: original image -\> Y: target image (input-to-output)

    ::: {.callout-tip style="color: green" appearance="minimal"}
    rectify the location of discrete coordinates found along a linear feature such as a road in a vector map
    :::

    ::: {.callout-important style="color: red" appearance="minimal"}
    possibility of points outside 'gold standard' (the rectified/targeted image) -\> output matrix pixel with no output value
    :::

Backward mapping

:   X: target image -\> Y: original image (output-to-input)

    ::: {.callout-tip style="color: green" appearance="minimal"}
    use points on 'gold standard' to match point on original data
    :::

[![Forward and inverse mapping (Jensen, 2015)](image/geometriccorrection.png)](%5B@jensen2015%5D)

Mosaicking

:   Moisaicking is the process of combining multiple adjacent images into a single seamless composite. Two techniques are -

    1.  Cut-line feathering: cut the images along a common defined boundary line/object and blend them together \> usually output is in a sharper transition \> Applied in cases wihen a clear boundary / discontinuity between images (e.g. road/river)

    2.  Edge feathering: offset the edge of images by certain distance through filter or algorithm \> usually output transition is more gradual and smoother \> Applied in cases when a gradual transition exist in images (e.g. forest/agricultural land)

Finally, the corrected image is resampled to create a new image that accurately reflects the true location and orientation of features on the ground.

#### Atmospheric Corrections

Atmospheric corrections

:   A process to mitigate the effect of atmospheric interference (haze, scattering and absorption) & to avoid loss of reflectance & signature extension thorough space and time [@jensen2015]. This method requires some knowledge of the atmospheric condition and sensors.

::: {.callout-tip style="color: green" appearance="minimal"}
The accuracy and quality of imagery will be improved to represent the true spectral information of the features.
:::

::: {.callout-important style="color: red" appearance="minimal"}
Similar to geometric correction, the data loss may be the minor drawback of this technique, particularly in the case of thin clouds or high aerosol concentrations.
:::

Point Spread Function

:   Measured and modeled point spread functions (PSF) of sensor systems indicate that a significant portion of the recorded signal of each pixel of a satellite image originates from outside the area represented by that pixel. This hinders the ability to derive surface information from satellite images on a per-pixel basis [@huang2002].

Relative

:   1\) to normalize the intensities among the different bands within a single-date remotely sensed image, and 2) to normalize the intensities of bands of remote sensor data in multiple dates of imagery to a standard scene selected by the analyst.

    Difference to Absolute atmospheric correction: does not require atmospheric data but instead relies on the comparison of images acquired at different times or from different sensors, assuming the relative differences in reflectance between different areas of an image remain constant over time (those changes are due to atmospheric interference).

    ::: {.callout-tip style="color: green" appearance="minimal"}
    Good for cases when the atmospheric data is unavailable or when absolute techniques are not feasible..
    :::

    ::: {.callout-important style="color: red" appearance="minimal"}
    can be less accurate than absolute ones (esp. in regions with variable atmospheric conditions or terrain).
    :::

    Two techniques are -

    1.  Dark object subtraction (DOS): identify and subtract the digital number of dark object (like shadow not reflecting light) in the imagery from that of other features (at pixel level). Hence, the reflectance due to surface features is kept.

        ::: {.callout-important style="color: red" appearance="minimal"}
        This technique has some limitations - it assumes unusual brightness of darkest pixel as atmosphere and the dark object reflects no light, which might not be true in all cases. Plus, not all imagery have identifiable dark objects.
        :::

    2.  Multiple-date image normalization using regression: divide the reflectance values in each pixel by a value (mean/median reflectance of a group of pixels in that image).

        -   Pseudo-Invariant Features (PIFs) selection = radiometric GCP

        -   Requirements of PIF: 1) little changes through time; 2) similar elevation as other land in scene; 3) minimal vegetation; 4) in a relatively flat area.

Absolute

:   Estimates the atmospheric properties and removes their influence from measured values to get true surface reflectance.

    Requirement: atmospheric data obtained at the time of image acquisition

    ::: {.callout-important style="color: red" appearance="minimal"}
    High input data requirement like temperature, humidity, air pressure, sensor and sun angels, albedo, emissivity (through fieldwork/meteorological data sources)

    High software requirement (costy)
    :::

    ::: {.callout-tip style="color: green" appearance="minimal"}
    Accounting the actual atmospheric conditions at the time of data acquisition, this method is usually more accurate than the relative ones (but not always necessary/practical!).

    Digital counts in satellite / aircraft image data -\> scaled surface reflectance
    :::

    1.  Empirical Line Calibration (ELC): establish a linear regression model to convert the digital numbers of the unknown pixels to actual physical units.

        Requirements:

        1.  Two or more areas in the scene with different albedos (e.g., one bright target such as sand and one dark target such as a deep, nonturbid water body) & as homogeneous as possible \<- difficult.
        2.  Sensor calibration coefficients
        3.  Radiative transfer code (knowledge of sensor spectral profile & atmospheric properties at the time of data collection) [@jensen2015]

        ::: {.callout-important style="color: red" appearance="minimal"}
        Its accuracy depends on the reference data \> require representative data with a range of surface types and conditions. It also assumes atmospheric conditions are uniform.
        :::

#### Topographic Corrections (Orthorectification)

Topographic corrections

:   A process to remove the effects of topographically induced illumination variation, which is usually conducted after atmospheric corrections (not always needed). (The amount and angle of solor illumination may vary due to topo. variations, affecting the measured values.)

    Requirements: sensor geometry & elevation model

    ::: {.callout-important style="color: red" appearance="minimal"}
    not considering diffuse skylight / light reflected from surrounding mountainsides
    :::

Illumination

:   The cosine of the incident solar angle, thus representing the proportion of the direct solar radiation hitting a pixel.

    Cosine Function: $L_H = L_T*\frac{cosθ_O}{cosi}$

    $i$: Sun's incidence angle - cosine of the angle between the solar zenith and the normal line of the slope (smaller cos i -\> greater over-correction [@jensen2015])

    $L_T$: radiance (DN to TOA) from sloped terrain

Zenith 

:   $θ_O$ : The solar zenith angle is the zenith angle of the sun, i.e., the angle between the sun's rays and the vertical direction. Solar zenith angle is normally used in combination with the solar azimuth angle to determine the position of the Sun as observed from a given location on the surface of the Earth.

Azimuth

:   The solar azimuth angle is the azimuth (horizontal angle with respect to north) of the Sun's position.

![Zenith angle and cosine function (Jensen, 2015)](image/cosinefunction.png){width="300"}

#### Radiometric Calibrations

Radiometric calibrations

:   A process to convert the raw and unitless digital numbers of pixel to radiance/reflectance that is comparable and can be used to analyze Earth's surface, removing atmospheric noise.

    -   TOA radiance -\> TOA reflectance: no light

    -   Surface reflectance: no light, no atmosphere

    -   Hemispherical reflectance (e.g. in Labs)

    -   Apparent reflectance

### Enhancement

This is the process to improve visual quality of imagery to highlight feature of interest.

::: {.callout-important style="color: red" appearance="minimal"}
Caution: please avoid over-enhancement which may cause false interpretation. \> require careful selection of methods.
:::

Techniques include -

1.  Contract enhancement (e.g. done in QGIS in wk1): adjusting the range of pixel values in an image to span the full dynamic range.

    ::: {.callout-tip style="color: green" appearance="minimal"}
    This does not change the data, but the display, and improves the visual contrast/detail of image.
    :::

2.  Ratioing: divide / compare bands with each other, normalized surface reflectance. E.g. Normalised Difference Vegetation Index (NDVI).

    ::: {.callout-tip style="color: green" appearance="minimal"}
    identify a certain landscape feature
    :::

3.  Filtering: enhance specific features of interest. E.g. edge detection filters - sharpen the edges of features; smoothing filters - reduce noise or blur.

4.  PCA: combine a large number of layers within datasets of the same spatial resolution.

5.  Texture analysis: quantify spatial patterns/arrangements of pixel values in an imagery.

    1st order occurrence: ✔️classification

    Edge of building enhanced via 1st order variance

    2nd order co-occurrence: ✔️classification improvement and additional info (to other bands), can then be used in PCA

6.  Fusion: combine bands of multiple images of the same area or scene from different sensors or at different times (or layers from texture analysis), to create a single, high-quality image.

    ::: {.callout-tip style="color: green" appearance="minimal"}
    This method can improve resolution, color balance, and detail of an image.
    :::

    Pan-sharpening: fuse multispectral imagery with [a panchromatic image (capturing all the visible wavelengths of light as a single grayscale image, with detailed information about the shape, size, and texture of features on the ground)]{.underline} of higher spatial resolution to increase the spatial resolution of the former whilst preserving its spectral information.

## Application

Geometric Corrections: [Redlining in the US](https://dsl.richmond.edu/panorama/redlining/#loc=11/42.366/-71.262&city=cambridge-ma).

The historical maps/plans were drawn by hands. Those maps were digitized through geometric corrections, allowing the research/manipulation of this database on housing policy relating to socio-economic wellbeing and zoning.

[![Redlining historic map corrections](image/redlining.png)](https://dsl.richmond.edu/panorama/redlining/#loc=11/42.366/-71.262&city=cambridge-ma)

## Reflection

Different methods of corrections are interlinked, finding some reference points/signatures to rectify the image. The detailed processes (like regressions and data collection methods) are difficult to digest (probably because not being practiced) while the software is available for corrections.

In the future development, the enhancement/like texture analysis can be expanded into 3D data to distinguish vertical structure of land surface.
