[
  {
    "objectID": "1_intro.html#summary",
    "href": "1_intro.html#summary",
    "title": "2  Introduction",
    "section": "2.1 Summary",
    "text": "2.1 Summary\n\n2.1.1 Sensors\nPassive sensors (aka. Optical sensors) are like human eyes/cameras that do not emit Electromagnetic (EM) waves itself. EM waves from solar radiation (thermal energy) are reflected, transmitted or absorbed by objects/surfaces and satellites (e.g. WorldView-3 in Week2 entry) (passively) capture that naturally available energy from existing source.\n\n\n\n\n\n\nImagery is influenced by atmosphere haze and scattering (different wavelengths when there are clouds / in different weather conditions (e.g. blue sky and orange sunset)).\nSolution: the data sometimes requires atmosphere correction as mentioned in Week3\n\n\n\n\n\n\n\n\n\nThis type of sensor does not disturb objects or areas of interests.\n\n\n\nActive sensors (aka. Radar sensors) emit and receive EM wave / energy like radar and x-ray. The changes in return signal are detected. Examples include Synthetic aperture radar (SAR) and Light Detection and Ranging (LiDAR).\n\n\n\n\n\n\n(Not necessarily bad) currently there are limited datasets available on GEE.\n\n\n\n\n\n\n\n\n\nIt can pass clouds (which is good if the weather conditions are not suitable to use passive sensors) because it operates in microwave on the EM spectrum.\n\n\n\n\n\n\n\n\n\n(Source: NASA Applied Remote Sensing Training Program)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.1.2 Four types of resolutions\n\nSpatial resolution\n\nThe size of the raster grid / pixel in terms of Earth’s surface area (e.g. 20cm: each grid is 20cm by 20cm area on the ground).\nTrade-off between time, costs and spatial resolution: Low spatial resolution data usually has shorter revisit time; while high spatial resolution data is finer, more detail but costly.\n\nSpectral resolution\n\nThe ability of the sensor to distinguish finer wavelengths, i.e. more and narrower bands.\nObjects on Earth have different spectral signatures (reflectance/emittance as a function of wavelength), which can be measured via multiple approaches like spectrometre. At high spectral resolution meaning more bands, distinctions can be made between rock and mineral types, vegetation types, and other features.\n\nMultispectral data = 3-10 bands\nHyperspectral data (stack all colour bands) = hundreds to even thousands of bands\nBoth active and passive techniques work with wavelength ranges contained in the atmospheric windows (where Earth’s surface receive EM energy from the Sun, and for thermal radiation from the surface to leave to space).\n\n\n\n(Source: National Weather Service)\n\n\n\n\nRadiometric resolution\n\nThe amount of information in each pixel, that is, the number of bits representing the energy recorded (e.g. 8 bit: 28 (256) potential digital values (0-255) to store information).\nHigher bits, more possible values, more capable of discerning subtle differences in light or reflectance (reduce sharpness, more like gradient changes in colour)\nSentinel-2 is 12-bit (brightness levels from 0 – 4095) (beyond True Colour Image (TCI) values)\n\nTemporal resolution\n\nThe time it takes for a satellite to complete an orbit and revisit the same observation area.\n\n\nConsidering the trade-off between resolution and time (and cost), the choice of sensors depends on the purpose of the analysis.\n\n\n\nTrade-off between spatial and temporal resolution (Source: Jensen et al., 2015)\n\n\n\n2.1.2.1 Sentinel and Landsat\n\n\n\n\nSentinel-2\nLandsat (8-9 OLI and TIRS)\n\n\n\n\nSpatial resolution\nResolutions vary for each bands (e.g. 10m resolution for Band 2)\n30m resolution\n\n\nTemporal resolution\n10 days (5 days for combined constellation 2A & 2B)\n16 days\n\n\nSpectral resolution\n13 spectral bands\n9 spectral bands\n\n\nCentral wavelength\nB1 443nm = Band 1 has central wavelength of 442 nm\n\n\n\n\n\nSentinel tends to have shorter download time than Landsat.\nLandsat has less available data in a given time range (due to slightly longer revisit time).\n\n\n\n\n2.1.3 Pre-processing workflow in SNAP\nDownload > New project in SNAP > Save downloaded file in a Data folder in the same directory as the project > Open product/zipped data > Select RGB-image channel (on product explorer panel right click product) > Fig. a,b,c\nTo inspect/change image display: -> Colour Manipulation panel (View -> Tool Windows) -> Change the range of histogram\nTo analyse spectral feature space: -> Scatter plot (under Analysis tab) => Fig. d\nTo mask the study area: -> Resampling to 20m (since both masking and the Tasseled Cap function require same resolution while B2/B3/B4/B8 are 10m and B11/B12 are 20m) -> Import vector (ESRI shapefile) -> Select the imported layer in layer manager -> Masking under Raster - Masks - Land/Sea Mask (select bands that would be used)\nTo reduce dimensionality via Tasseled Cap transformation : -> Apply transformation functions in Band Math -> Select RGB-image channel => Fig. e,f\nSince Landsat has different spatial resolution than Sentinel, the latter will be resampled again (upscale). And since the Sentinel data has been masked/selected useful bands for Tasseled cap, it will be masked again to select B1-B7.\nTo compare spectral reflectance: -> Make sure both data in the same resolution with the same bands -> Add polygons by land cover -> Export polygons as shapefiles -> Export both dataset as GeoTIFF -> Check in QGIS -> Compare in R using terra (or stars) => Fig. g,h & Table 1\n\n\n\n\n\n\n\nProcess by Software\nSNAP\n\n\nColour composite\nrecreate by changing RBG channels (Fig. a, b, c)\n\n\nEnhancement\nImage histogram\n\n\nSpectral feature space\nScatter plot (Fig. d)\n\n\nResampling\nB11 and B12 are at a 20m resolution whereas all the others at a 10m resolution. -> resample others to 20m (upscale) Sentinel 2 resampling toolbox\nA) Traditional resample: considers the neighbouring pixels (time-efficient?)\nB) Sentinel 2 products resample: account for the particularities of the angle (satellite viewing) bands\n\n\nMasking\nMasks. Land/sea mask.\nCan only mask bands on the same resolution\n\n\nTasseled Cap function\nBand Maths.\nReduce dimensionality: (similar to PCA) spectral index combining two or more bands to highlight certain features of an image. Then change RGB channel to those new data to show results (Fig. e)\n\n\n\n\nQGIS can conduct similar analysis. For instance, colour composite can be set by merging the BOA bands (B2, B3, B4, B8 to make true colour composite (B1=Blue, B2=Green, B3=Red))\n\n\n2.1.3.1 Masking vs. cropping\n\nMasking\n\nThe outline of the geographic boundary\n\nCropping\n\nTo the extent, the rectangular parameter of the geographic boundary\n\n\n\n\n2.1.3.2 Case study: Kinmen County\nI’ve chosen Kinmen County in Taiwan as my case study area for this week’s practical. It consists of several islands and is in close proximity to Xiamen, mainland China. The main/largest island is the H-shaped one at the lower end of the first few maps (or see Fig e).\nThis is where i spent the majority of summer in 2022 so i’ve got some knowledge of the city/island’s land use. I also cycled a lot here (so having some sense of the topography). There is less traffic and a abundance of greenery. However, it tends to be slightly cloudy/rainy in certain months which may constrain remote sensing analysis.\nThe initial exploration using Sentinel data:\n\n\n\n\n\n\na) Natural colour\n\n\n\n\n\n\n\nb) False colour composite\n\n\n\n\n\n\n\n\n\nc) Atmospheric penetration composite\n\n\n\n\n\n\n\nd) Scatter plot (B4 Red - B8 NIR)\n\n\n\n\n\n\nFalse colour composite: B8, B4, B3. Plants reflect near-infrared and green light whilst absorbing red.\nAtmospheric penetration composite: B12, B11, B8A with no visible bands to penetrate atmospheric particles. Vegetation = blue, urban area = white, gray cyan or purple.\n\nThree maps show that Xiamen’s built-up areas are mostly close to the seashore (in fact most cities in eastern China are coastal). This is mainly due to its historical ports that are open to international trades and thus becoming more urbanized. Kinmen Islands are less populous compared to Xiamen and the majority of land is bare soil / vegetation. Fig d shows that the dry bare soil is prominent in some areas (black dots at high B4 and high B8), while the image has large ratio of biomass (yellow peak at low B4 and high B8).\n\nTasseled Cap function\n\nThe function is originally designed to monitor crop’s life cycle / changes through time (Source: ArcPro).\n\nBrightness = bare or partially covered soil, man-made, and natural features such as concrete, asphalt, gravel, rock outcrops, and other bare areas\nGreenness = green vegetation\nWetness = soil moisture, water, and other moist features.\n\n\n\n\n\n\n\nThose three components of imagery contain about 97% of the meaningful information available in the imagery (removing noise and atmospheric effects).\n\n\n\n\n\n\n\n\n\n\n\ne) PCA / Tasseled Cap function transformed (May 2022)\n\n\n\n\n\n\n\nf) PCA / Tasseled Cap function transformed (November 2022)\n\n\n\n\n\nDarker blue and red areas are generally unchanged - representing water (lakes/reservoir/sea), soil and built-up area. The pink areas are built-up areas / concrete / asphalt / human-made (e.g. southern inner bay’s long linear shape is the airport, and western area on the main island is the most populous town)\nGreenness in Fig e is less than that in Fig f, indicating the vegetation is less in May. During May (or generally spring time), there should be roughly similar amount of vegetation / crops, compared to November (autumn), while the crops during autumn reach maturity leading to more greenness in the latter figure.\nIt might also be the case that the light blue areas are soil moisture / higher humidity. As can be seen from both figures, the shaded blue areas in the central/slightly eastern-central location of the largest island is mountainous. The humidity can be higher there.\nAnother difference between the two images is that the redness is more intense in the first figure (more NIR), while more organgy in the second. This indicates that the those areas are soil or bare areas. During autumn, the vegetation on those land increase, so the yellowness/greenness overlays.\nTo mitigate the atmospheric effects (cloudy and foggy from April to May and rainy during summer) and due to data availability, the sensing time for Landsat is in December.\n\n\n\n\n\n\ng) Spectral reflectance Sentinel\n\n\n\n\n\n\n\nh) Spectral reflectance Landsat\n\n\n\n\n\nThe ranges of the datasets are different visually. Landsat has higher mean reflectance for all land cover in all bands.\nFor both sensors, the relationship between each land cover is similar. Water, forest and grass have lowest reflectance, and albeit less visible in Sentinel, bare earth has the highest reflectance.\nThen, t-test is conducted to test the difference mean land cover reflectance between two sensors.\n\nTable 1. Welch two sample t-test (Sentinel and Landsat)\n\n\nlandcover\nt\ndf\np-value\n\n\n\n\nlow_urban\n-129.55\n2224.5\n< 2.2e-16\n\n\nhigh_urban\n-289.79\n7115.3\n< 2.2e-16\n\n\nbare_earth\n-223.36\n7141.2\n< 2.2e-16\n\n\ngrass\n-71.533\n674.71\n< 2.2e-16\n\n\nforest\n-256.12\n7799.9\n< 2.2e-16\n\n\nwater\n-175.3\n270.91\n< 2.2e-16\n\n\n\nSince p-values are all below 0.05, the difference in average reflectance of Landsat and of Sentinel data is statistically significant.\n\n\n\ni) Landsat vs. Sentinel (NASA, 2015)\n\n\nFig i from NASA shows that spectral bands are similar between Landsat 8 and Sentinel-2, except TIRS. Hence, the comparison above is possible. However, the atmospheric transmission varies. Sentinel bands have higher atmospheric transmission rate (white areas) and relatively low reflectance across all land cover type. Conversely, most Landsat bands are in atmospheric windows (gery areas), which allow energy to pass through the atmosphere, thus resulting in higher reflectance. \n\n\n\n2.1.4 QGIS vs. SNAP\nQGIS\n\n\n\n\n\n\nGood to check stuff / visualize outputs.\n\n\n\nSNAP\n\n\n\n\n\n\nEasier to recreate TCC.\nCan manually set the histogram / contract enhancement.\nHaving data from multiple sensors in the same software that can be explored/compared together.\n\n\n\n\n\n\n\n\n\nit’s a pain to reopen a project.. and I found when setting up the project, it’s more straightforward to create a new project before opening up a product.\n\n\n\nTwo software can work together (using QGIS to check everything as did in CASA0005).\n\n\n2.1.5 Question\n\nWhy in the practical book before Landsat when resampling Sentinel, the equation for brightness does not include B11 and B12 (but using 0.5082 and 0.1863)?\n\n\nA: It should be B11 and B12.\n\n\nFig e looks different in terms of colour scheme? Since the majority of the island is coloured in blue, what do the blueish areas represent? Physically those areas are vegetations/forests, shouldn’t those be in green?\n\n\nA: The colour depends on the colour gun set via the RGB. Also, another possible explanation would be the soil contains high amount of moisture. Hence, requirements for accurate understanding of LULC is either field work at the time of data collection or accurate spectral signature of the object/features or the huge abundance of knowledge to the local geography."
  },
  {
    "objectID": "1_intro.html#application",
    "href": "1_intro.html#application",
    "title": "2  Introduction",
    "section": "2.2 Application",
    "text": "2.2 Application\nOne more question would be what possible factors contribute to the difference in mean reflectance analysed above and how to mitigate the difference. Apart from the atmospheric window discussed above, the temporal difference in the sensing date (19th November 2022 for Sentinel and 19th December 2022 for Landsat) might contribute to difference in atmospheric effects and in path radiance / noise from sky irradiance and radiance from surrounding areas. Hence, to increase data consistency and reduce reflectance difference for similar sensors, removing atmospheric effects and noise is needed. This could be done through linear regression methods (e.g. to get surface reflectance for Sentinel using radiometric calibration method mentioned in Week3). Moreover, Time-series-based Reflectance Adjustment (TRA) approach is developed to mitigate the drawbacks of fixed/global band transformation coefficients by considering difference in land cover type and locations (Shang and Zhu 2019a)."
  },
  {
    "objectID": "1_intro.html#reflection",
    "href": "1_intro.html#reflection",
    "title": "2  Introduction",
    "section": "2.3 Reflection",
    "text": "2.3 Reflection\nEO data availability depends on cloud cover, time, weather (sometimes study areas may not have data under the filtered criteria). There are methods to overcome this issue after manually selecting the cloud% when downloading/sourcing the data mentioned in following weeks, but possible downsides of this would be the possibility of over-correction (remove too much of the image data, resulting in loss of information and reduced accuracy); misidentification of clouds in cloud-free areas; or the sensitivity to geographical conditions (atmospheric conditions, terrain, or land cover may affect performance in different regions or seasons). And the set cloud% still may not be ideal for the time range targeted. SAR data would be a valuable addition to cope with this (Andy’s lecture in Week9).\n\nThere were so many wrong decisions made when producing this analysis. Without solid understanding of concepts/theories, the practical is like a maze 👾. It would be more efficient to do the practical after fully understanding every concept and data (although it is also rewarding to discover and learn from mistakes..). For instance, when comparing the spectral reflectance of Landsat and Sentinel, i selected band 1 to 7 for both sensors at first. However, after reading the paper by Shang and Zhu (2019b), i realized the wavelength ranges/band numbers are different for both sensors (e.g. NIR is band 5 in Landsat while 8A for Sentinel.) After modifying this mistake, the overall patterns do not change much, albeit slight difference in t-statistics.\n\n\n\n\n\nShang, Rong, and Zhe Zhu. 2019b. “Harmonizing Landsat 8 and Sentinel-2: A Time-Series-Based Reflectance Adjustment Approach.” Remote Sensing of Environment 235 (December): 111439. https://doi.org/10.1016/j.rse.2019.111439.\n\n\n———. 2019a. “Harmonizing Landsat 8 and Sentinel-2: A Time-Series-Based Reflectance Adjustment Approach.” Remote Sensing of Environment 235 (December): 111439. https://doi.org/10.1016/j.rse.2019.111439."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CASA0023 Learning Diary",
    "section": "",
    "text": "Preface\nThis website presents the online learning diary for CASA0023 Remote Sensing Cities and Environments 22/23. It contains brief overview of the weekly lectures including summary of key concepts, some practical outputs showing applications and examples of remote sensing techniques, open source applications from web source and literature, and individual reflection on the learnt concepts/techniques.\n\nAbout the author\n\nEducation\nYi-Chien Chen is currently the master student at CASA, UCL in the MSc Urban Spatial Science programme 2022/23. She studied urban planning at BSP, UCL during 2019-2022 and hold a BSc in Urban Planning, Design and Management.\n\n\nBio\nShe has some internship experience in architecture industry focusing on architecture design of residential high-rise complexes and one public space project in a mountainous area, in real estate agency doing quantitative market research, and a university career service role conducting a range of duties from data analysis to poster design. In this uni admin role, her fondness for figures and data grows. She was also a voluntary translator for ArchDaily as she’s interested in architecture and urban design.\nHer recent 2-week (but super productive!) work shadowing in summer 2022 with AECOM London office is the most relevant experience to her planning background, gathering information from the policy and qualitatively constructing design guidance and architecture models at neighbourhood level for the local authorities/government. In this experience, she met the GIS team virtually and see the demands on (geospatial) data-oriented planning policy recommendation and interventions.\nEmail: zcfther@ucl.ac.uk\nGitHub"
  },
  {
    "objectID": "index.html#content",
    "href": "index.html#content",
    "title": "CASA0023_LD",
    "section": "Content",
    "text": "Content\n\nIntroduction\n\n\nRemote sensing intro / sensors / resolutions\n\n\nSensor - WorldView3\nCorrections"
  },
  {
    "objectID": "index.html#structure-of-each-chapter",
    "href": "index.html#structure-of-each-chapter",
    "title": "CASA0023_LD",
    "section": "Structure (of each chapter)",
    "text": "Structure (of each chapter)\n\nSummary:\nContent summary (outputs from the practical, small code chunks with relevant explanation and flow charts)\nQuestions (data, methods, or applications)\nApplications:\nApplication of data / concepts / methods in literature / policy (largely sourced from weekly reading).\nReflection:\nA personal reflection on the presented content (e.g. what was interesting, why and why might the data or tools presented this week be useful in the future to you or perhaps they won’t be useful but something similar might be)"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "CASA0023_LD",
    "section": "Education",
    "text": "Education\nUniversity College London"
  },
  {
    "objectID": "index.html#professional-experience",
    "href": "index.html#professional-experience",
    "title": "CASA0023_LD",
    "section": "Professional experience",
    "text": "Professional experience"
  },
  {
    "objectID": "index.html#interests",
    "href": "index.html#interests",
    "title": "CASA0023_LD",
    "section": "Interests",
    "text": "Interests"
  },
  {
    "objectID": "index.html#what-i-hope-to-get-from-the-module",
    "href": "index.html#what-i-hope-to-get-from-the-module",
    "title": "CASA0023_LD",
    "section": "What I hope to get from the module",
    "text": "What I hope to get from the module"
  },
  {
    "objectID": "2_portfolio.html#summary-application-and-reflection",
    "href": "2_portfolio.html#summary-application-and-reflection",
    "title": "3  Sensor-WorldView3",
    "section": "3.1 Summary, Application and Reflection",
    "text": "3.1 Summary, Application and Reflection\nA Xaringan presentation A basic introduction on WorldView-3 is produced and this diary itself is a Quarto Book."
  },
  {
    "objectID": "intro.html#structure-of-each-chapter",
    "href": "intro.html#structure-of-each-chapter",
    "title": "Content",
    "section": "Structure (of each chapter)",
    "text": "Structure (of each chapter)\n\nSummary:\n\nContent summary (outputs from the practical, small code chunks with relevant explanation and flow charts)\n\n✔️&❌: indicate Pros and Cons of specific idea / concept / object…\n\nQuestions (data, methods, or applications)\n\nApplications:\n\nApplication of data / concepts / methods in literature / policy (largely sourced from weekly reading).\n\nReflection:\n\nA personal reflection on the presented content (e.g. what was interesting, why and why might the data or tools presented this week be useful in the future to you or perhaps they won’t be useful but something similar might be)"
  },
  {
    "objectID": "1_intro.html",
    "href": "1_intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "2 Summary"
  },
  {
    "objectID": "1_intro.html#sensors",
    "href": "1_intro.html#sensors",
    "title": "1  Introduction",
    "section": "2.1 Sensors",
    "text": "2.1 Sensors\n\nPassive (Sun energy reflection in EM wave, don’t emit EM waves)\n\nExample: human eyes, satellite\nCon: Atmosphere Haze (require atmosphere correction, no haze in outer space due to no atmosphere) and scattering (wavelength (e.g. blue sky and orange sunset)), clouds and weather\n\nActive (emit and receive EM wave / energy)\n\nExample: radar, x-ray, LiDAR\nPro: can pass clouds"
  },
  {
    "objectID": "1_intro.html#four-resolutions",
    "href": "1_intro.html#four-resolutions",
    "title": "1  Introduction",
    "section": "2.2 Four resolutions",
    "text": "2.2 Four resolutions\n\nSpatial\n\nPro: fast\nCon: costly\n\nSpectral\n\nSpectral signature (EM): Objects on Earth have difference wavelengths = Bands\n\nMulti-spectral data / image\nHyperspectral data / image: stack all colour bands\n\nTrue colour (human eye can see) and false colour (human cant see)\nCon: atmospheric window (atmospheric transmission / opacity, e.g. water vapour, ozone, CO…)\nSpectroradiometer\n\nRadiometric\n\nCell/ pixel\nIncrease bit -> increase possible values\n8-bit\n\nTemporal\n\nRevisit time of sensor\nHigh resolution / pixel -> low revisit = low cost and number [graph]\n\n\nTrade off between resolution and time (and cost)\n\n2.2.1 Questions"
  },
  {
    "objectID": "3_corrections.html#summary",
    "href": "3_corrections.html#summary",
    "title": "4  Corrections",
    "section": "4.1 Summary",
    "text": "4.1 Summary\n\n4.1.1 Corrections\n\n4.1.1.1 Geometric Corrections\n\nTo reduce geometric distortion\nOff-Nadir -> Nadir\n\n\nGround central point: GCP\n\nA ground control point (GCP) is a location on the surface of the Earth (e.g., a road intersection) that can be identified on the imagery and located accurately on a map.\n(Objects (e.g. building) on the image that do not move, as the reference point of corrections.)\n\n\n\nCoordinates of each GCP -> linear regression\nReduce error <- increase GCP\nRequirement for corrections:\n\nsame resolution (resampling)\nsame CRS (reprojecting)\n\n\n\nImage-to-map rectification (rectify remotely sensed data to a standard map projection)\nImage-to-image registration (remotely sensed data used in conjunction with other spatial information in a GIS)\n\n\nForward (input-to-output) mapping\n\nForward mapping\n\nX: original image -> Y: target image\n\n\n\n✔️rectify the location of discrete coordinates found along a linear feature such as a road in a vector map\n❌possibility of points outside ‘gold standard’ (the rectified/targeted image) -> output matrix pixel with no output value\n\nInverse (output-to-input) mapping\n\nBackward mapping\n\nX: target image -> Y: original image\n\n\n✔️ use points on ‘gold standard’ to match point on original data\n\n\n\n\nForward and inverse mapping (Jensen, 2015)\n\n\n\nMoisaicking\n\nMosaicking\n\nMoisaicking is the process of combining multiple images into a single seamless composite image.\n\n\n\ncut-line feathering: offset the edge of images by certain distance\nedge feathering: specify objects (e.g. roads/rivers) as edge\n\n\n\n\n4.1.1.2 Practical: Merging imagery\nAlthough Kinmen County is rather a small area, covered sufficiently within one tile of the Landsat imagery, another adjacent tile would be chosen to practice merging.\n\n\n4.1.1.3 Atmospheric Corrections\n\nTo mitigate the effect of scattering and absorption & to avoid loss of reflectance & signiture extension thorough space and time (Jensen 2015)\nPoint Spread Function\n\nPoint Spread Function\n\nMeasured and modeled point spread functions (PSF) of sensor systems indicate that a significant portion of the recorded signal of each pixel of a satellite image originates from outside the area represented by that pixel. This hinders the ability to derive surface information from satellite images on a per-pixel basis (Huang et al. 2002).\n\n\nRelative\n1) to normalize the intensities among the different bands within a single-date remotely sensed image, and 2) to normalize the intensities of bands of remote sensor data in multiple dates of imagery to a standard scene selected by the analyst.\n\nDark object subtraction (DOS)\n❌ assuming unusual brightness of darkest pixel as atmosphere\nMultiple-date image normalization using regression\n\nPseudo-Invariant Features (PIFs) selection = radiometric GCP\nRequirements of PIF: 1) little changes through time; 2) similar elevation as other land in scene; 3) minimal vegetation; 4) in a relatively flat area.\n\nUse middle of years, Y: base image\n\nAbsolute\n❌ High data requirement (fieldwork/…); High software requirement (costy)\n✔️Digital counts in satellite / aircraft image data -> scaled surface reflectance\n\nEmpirical Line Calibration (ELC)\n\nRequirements:\n\nTwo or more areas in the scene with different albedos (e.g., one bright target such as sand and one dark target such as a deep, nonturbid water body) & as homogeneous as possible <- difficult.\nSensor calibration coefficients\nRadiative transfer code (knowledge of sensor spectral profile & atmospheric properties at the time of data collection) (Jensen 2015)\n\n\n\n\n\n\n4.1.1.4 Topographic Corrections (Orthorectification)\n\nTo remove topographically induced illumination variation\n\nIllumination\n\nthe cosine of the incident solar angle, thus representing the proportion of the direct solar radiation hitting a pixel.\n\n\nRequirements: sensor geometry & elevation model\nShould be done after atmospheric corrections\nCosine Function: \\(LH=LT\\frac{cosθO}{cosi}\\)\n\nZenith\n\nThe solar zenith angle is the zenith angle of the sun, i.e., the angle between the sun’s rays and the vertical direction. Solar zenith angle is normally used in combination with the solar azimuth angle to determine the position of the Sun as observed from a given location on the surface of the Earth.\n\nAzimuth\n\nThe solar azimuth angle is the azimuth (horizontal angle with respect to north) of the Sun’s position.\n\n\n\n\n\n\nZenith angle and cosine function (Jensen, 2015)\n\n\n\n❌ not considering diffuse skylight / light reflected from surrounding mountainsides\nsmaller cos i -> greater over-correction (Jensen 2015)\n\n\n\n4.1.1.5 Radiometric Calibrations\n\nDigital number of each pixel = raw, unitless\nRegression = unit\nReflectance (BOA) = comparable\nTOA radiance -> TOA reflectance = no light\nSurface reflectance = no light, no atmosphere\nHemispherical reflectance (e.g. in Labs)\nApparent reflectance\n\n\n\n\n4.1.2 Enhancement\n\n4.1.2.1 Feathering / joining\n\nGEE: median\nsurface reflectance data not comparable -> standardization, normalization\n\n\n\n4.1.2.2 Image Enhancement\n\nContract enhancement (QGIS)\n✔️ not changing data, but the display\nRatioing\ndivide / compare bands with each other, normalized surface reflectance\n✔️ identify a certain landscape feature\nExample: Normalised Difference Vegetation Index (NDVI)\nFiltering\nPCA\nTexture analysis\n1st order occurrence: ✔️classification\nEdge of building enhanced via 1st order variance\n2nd order co-occurrence: ✔️classification improvement and additional info (to other bands)\ncan then be used in PCA\nFusion\nCombine bands from different sensors / texture analysis layer\nResampling - different pixel/location\n\nDecision\nObject\nImage\nPan sharpen: for better visualization\n\n\n\n\n\n4.1.3 Question"
  },
  {
    "objectID": "3_corrections.html#application",
    "href": "3_corrections.html#application",
    "title": "4  Corrections",
    "section": "4.2 Application",
    "text": "4.2 Application\n\n4.2.1 Corrections\n\nGeometric Corrections: Redlining in the US.\nThe historical maps/plans were drawn by hands. Those maps were digitized through geometric corrections, allowing the research/manipulation of this database on housing policy relating to socio-economic wellbeing and zoning.\n\n\n\nRedlining historic map corrections"
  },
  {
    "objectID": "3_corrections.html#reflection",
    "href": "3_corrections.html#reflection",
    "title": "4  Corrections",
    "section": "4.3 Reflection",
    "text": "4.3 Reflection\nDifferent methods of corrections are interlinked, finding some reference points/signatures to rectify the image. The detailed processes (like regressions and data collection methods) are difficult to digest (probably because not being practiced) while the software is available for corrections.\n\n\n\n\nHuang, Chengquan, John R. G. Townshend, Shunlin Liang, Satya N. V. Kalluri, and Ruth S. DeFries. 2002. “Impact of Sensor’s Point Spread Function on Land Cover Characterization: Assessment and Deconvolution.” Remote Sensing of Environment 80 (2): 203–12. https://doi.org/10.1016/S0034-4257(01)00298-X.\n\n\nJensen, John R. 2015. Introductory Digital Image Processing. 4th ed. A Remote Sensing Perspective. Pearson Higher Education US."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "10  Summary",
    "section": "",
    "text": "By the end of this module, concepts and techniques on processing and analyzing remote sensing data are learnt. EO data could be an effective source of understanding urban system (like LULC and changes across time). However, some barriers do exist and could be figured out in future years / possibly have been solved already (such as the difficulty in monitoring the verticality of high density urban space).\nMore importantly, how to involve the EO data into the city planning to solve urban challenges have been practiced through group work. Our group work focuses on heatwave monitoring and early-warning for slum population in Ahmedabad, India (Presentation & GitHub repo, with contribution from Atsumi, Eunyoung, Josiah, Yifei and myself).\nThis is the end of this learning diary. Thanks for reading!\n– END –"
  },
  {
    "objectID": "dictionary.html",
    "href": "dictionary.html",
    "title": "11  Dictionary",
    "section": "",
    "text": "12"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "“A Comparison of Greenspace Loss and Urban Expansion over Time in\nLondon and Nairobi  EOES Hub.” 2017. https://blogs.kcl.ac.uk/eoes/2017/03/23/a-comparison-of-greenspace-loss-and-urban-expansion-over-time-in-london-and-nairobi/.\n\n\nBrown, Christopher F., Steven P. Brumby, Brookie Guzder-Williams, Tanya\nBirch, Samantha Brooks Hyde, Joseph Mazzariello, Wanda Czerwinski, et\nal. 2022. “Dynamic World, Near Real-Time Global 10 m Land Use Land\nCover Mapping.” Scientific Data 9 (1): 251. https://doi.org/10.1038/s41597-022-01307-4.\n\n\nCardille, Jeffrey A., Gennadii Donchyts, Ujaval Gandhi, Txomin\nHermosilla, Saverio Francini, Andréa P. Nicolau, and Michael A. Wulder.\nn.d. “F4 - Earth Engine Fundamentals and Applications - EEFA -\nLive Document.” https://docs.google.com/document/d/11oo1TuvXyEvReoYLDeTcoh16rEN90I8Bf5qp0KxVu7U/edit?usp=embed_facebook.\n\n\nChen, Tzu-Ling, Hung Lin, and Yin-Hao Chiu. 2022. “Heat\nVulnerability and Extreme Heat Risk at the Metropolitan Scale: A Case\nStudy of Taipei Metropolitan Area, Taiwan.” Urban\nClimate 41 (January): 101054. https://doi.org/10.1016/j.uclim.2021.101054.\n\n\nGandhi, Ujaval, and Jeff Howarth. n.d. “F1 - Earth Engine\nFundamentals and Applications - EEFA - Live Document.” https://docs.google.com/document/d/1dLSaGXlAnI0jK6LAB6F-gQLBA30NTT0pz1tovHfOmvI/edit?usp=sharing&usp=embed_facebook.\n\n\nGISGeography. 2014. “Image Classification Techniques in Remote\nSensing.” https://gisgeography.com/image-classification-techniques-remote-sensing/.\n\n\nGorelick, Noel, Matt Hancher, Mike Dixon, Simon Ilyushchenko, David\nThau, and Rebecca Moore. 2017. “Google Earth Engine:\nPlanetary-Scale Geospatial Analysis for Everyone.” Remote\nSensing of Environment, Big Remotely Sensed Data: tools,\napplications and experiences, 202 (December): 18–27. https://doi.org/10.1016/j.rse.2017.06.031.\n\n\nHuang, Chengquan, John R. G. Townshend, Shunlin Liang, Satya N. V.\nKalluri, and Ruth S. DeFries. 2002. “Impact of Sensor’s Point\nSpread Function on Land Cover Characterization: Assessment and\nDeconvolution.” Remote Sensing of Environment 80 (2):\n203–12. https://doi.org/10.1016/S0034-4257(01)00298-X.\n\n\nJensen, John R. 2015. Introductory Digital Image Processing.\n4th ed. A Remote Sensing Perspective. Pearson Higher Education US.\n\n\nKarasiak, N., J.-F. Dejoux, C. Monteil, and D. Sheeren. 2022.\n“Spatial Dependence Between Training and Test Sets: Another\nPitfall of Classification Accuracy Assessment in Remote Sensing.”\nMachine Learning 111 (7): 2715–40. https://doi.org/10.1007/s10994-021-05972-1.\n\n\nlanenok. 2015. “Answer to \"When to Use Random Forest\nover SVM and Vice Versa?\".” https://datascience.stackexchange.com/a/6855.\n\n\nLi, Dongying, Galen D Newman, Bev Wilson, Yue Zhang, and Robert D Brown.\n2022. “Modeling the Relationships Between Historical Redlining,\nUrban Heat, and Heat-Related Emergency Department Visits: An Examination\nof 11 Texas Cities.” Environment and Planning B: Urban\nAnalytics and City Science 49 (3): 933–52. https://doi.org/10.1177/23998083211039854.\n\n\nLi, Meng-Yi, Ding-Ju Zhu, Wen Xu, Yu-Jie Lin, Kai-Leung Yung, and Andrew\nW. H. Ip. 2021. “Application of U-Net with Global Convolution\nNetwork Module in Computer-Aided Tongue Diagnosis.” Journal\nof Healthcare Engineering 2021 (November): e5853128. https://doi.org/10.1155/2021/5853128.\n\n\nLovelace, Robin, Jakub Nowosad, and Jannes Muenchow. 2019. Chapter\n12 Statistical Learning | Geocomputation with R. https://r.geocompx.org/spatial-cv.html.\n\n\nMacLachlan, Andrew, Eloise Biggs, Gareth Roberts, and Bryan Boruff.\n2021. “Sustainable City Planning: A Data-Driven Approach for\nMitigating Urban Heat.” Frontiers in Built Environment\n6. https://www.frontiersin.org/articles/10.3389/fbuil.2020.519599.\n\n\nPal, M., and P. M. Mather. 2005. “Support Vector Machines for\nClassification in Remote Sensing.” International Journal of\nRemote Sensing 26 (5): 1007–11. https://doi.org/10.1080/01431160512331314083.\n\n\nPragati21. 2020. “SVM AND RANDOM FOREST: A Case Study.” https://medium.com/@pandeypragati2112/svm-and-random-forest-a-case-study-6213da5be02f.\n\n\nRahbar, Morteza, Mohammadjavad Mahdavinejad, Amir H. D. Markazi, and\nMohammadreza Bemanian. 2022. “Architectural Layout Design Through\nDeep Learning and Agent-Based Modeling: A Hybrid Approach.”\nJournal of Building Engineering 47 (April): 103822. https://doi.org/10.1016/j.jobe.2021.103822.\n\n\nRonneberger, Olaf, Philipp Fischer, and Thomas Brox. 2015. “U-Net:\nConvolutional Networks for Biomedical Image Segmentation.” In,\nedited by Nassir Navab, Joachim Hornegger, William M. Wells, and\nAlejandro F. Frangi, 9351:234–41. Cham: Springer International\nPublishing. http://link.springer.com/10.1007/978-3-319-24574-4_28.\n\n\nShang, Rong, and Zhe Zhu. 2019a. “Harmonizing Landsat 8 and\nSentinel-2: A Time-Series-Based Reflectance Adjustment Approach.”\nRemote Sensing of Environment 235 (December): 111439. https://doi.org/10.1016/j.rse.2019.111439.\n\n\n———. 2019b. “Harmonizing Landsat 8 and Sentinel-2: A\nTime-Series-Based Reflectance Adjustment Approach.” Remote\nSensing of Environment 235 (December): 111439. https://doi.org/10.1016/j.rse.2019.111439.\n\n\nSirko, Wojciech, Sergii Kashubin, Marvin Ritter, Abigail Annkah, Yasser\nSalah Eddine Bouchareb, Yann Dauphin, Daniel Keysers, Maxim Neumann,\nMoustapha Cisse, and John Quinn. n.d. “Continental-Scale Building\nDetection from High Resolution Satellite Imagery.”\n\n\nUstuner, Mustafa, Fusun Balik Sanli, and Barnali Dixon. 2015.\n“Application of Support Vector Machines for Landuse Classification\nUsing High-Resolution RapidEye Images: A Sensitivity Analysis.”\nEuropean Journal of Remote Sensing 48 (1): 403–22. https://doi.org/10.5721/EuJRS20154823.\n\n\nWan, Da, Xiaoyu Zhao, Wanmei Lu, Pengbo Li, Xinyu Shi, and Hiroatsu\nFukuda. 2022. “A Deep Learning Approach Toward Energy-Effective\nResidential Building Floor Plan Generation.”\nSustainability 14 (13): 8074. https://doi.org/10.3390/su14138074.\n\n\nWang, Sherrie, George Azzari, Michelle Stuhlmacher, Ran Goldblatt, Erin\nTrochim, Zander Venter, and Sourangsu Chowdhury. n.d. “A1 - Earth\nEngine Fundamentals and Applications - EEFA - Live Document.” https://docs.google.com/document/d/1MIPIFMJakC6eNGOhlkXLcwjUKFyY6QJLHElzBCOfyn4/edit?usp=embed_facebook.\n\n\nWeih, Robert C, and Norman D Riggan. n.d. “OBJECT-BASED\nCLASSIFICATION VS. PIXEL-BASED CLASSIFICATION: COMPARITIVE IMPORTANCE OF\nMULTI-RESOLUTION IMAGERY.”\n\n\nWilber, Jared. n.d. “Precision and Recall.” https://mlu-explain.github.io/precision-recall/.\n\n\nZhao, Yi, Bin Wu, Qiaoxuan Li, Lei Yang, Hongchao Fan, Jianping Wu, and\nBailang Yu. 2023. “Combining ICESat-2 Photons and Google Earth\nSatellite Images for Building Height Extraction.”\nInternational Journal of Applied Earth Observation and\nGeoinformation 117 (March): 103213. https://doi.org/10.1016/j.jag.2023.103213."
  },
  {
    "objectID": "4_policy.html#summary-reflection",
    "href": "4_policy.html#summary-reflection",
    "title": "4  Policy",
    "section": "4.1 Summary & Reflection",
    "text": "4.1 Summary & Reflection\n(the summary of the policy and city you have selected)\n(how the remotely sensed data you sourced could be used to assist with contributing to the policy goal. How could the data be applied to solve the policy challenge.)\n\n4.1.1 Policy Challenge in London\nThe 2021 London Plan incorporates Urban Heat Island (UHI) effect into the strategic spatial planning. Below are some themes/policies related to UHI.\n\n\n\n\n\n\n\nSolutions to mitigate & adapt UHI set by the Plan\nLinkage to remote sensing data\n\n\n\n\nEnsure efficiency and resilience in building and infrastructure design (GG6 B)\n\n\n\n(more towards adaptation) Set minimum building height to ensure daylight and ventilation (passive cooling) (3.6.3)\n(maybe) using SAR phasing to monitor the building heights, and Sentinel to measure the distance between building blocks, to find areas that would be most affected by insufficient indoor daylight and ventilation and act upon.\n\n\nGreen infrastructure provision in an integrated way (8.1)\nSuggesting/optimizing tree placement in new developments & public space (MacLachlan et al. 2021)\n\n\nGreen Belt protection (comply with NPPF) –constrain urban sprawl and drive re-use of previously developed brownfield land (8.2.1)\nMonitoring Green Belt & open greenspace\n\n\nUrban greening (street trees, green roofs, green walls, and rain gardens) (8.5.2)\nSuggesting/optimizing tree placement in new developments & public space (MacLachlan et al. 2021)\n\n\nManage heat risk through applying cooling hierarchy in new developments (through design, layout, orientation, materials and the incorporation of green infrastructure) (SI 4A; SI 4B; 9.4.1)\n\n\n\n\n\nLondon Green Belt\n\nLondon’s Green Belt provides an important long-term benefit for all those living in, around and visiting London; its landscape beauty and the haven it provides for an improved and thriving wildlife; its significant contribution to the mitigation of the climate emergency and enhancing people’s health and wellbeing; the facilities it offers for outdoor recreation, and its resource for food and farming close to London; all this in addition to its traditional role of containing urban sprawl and encouraging regeneration. (Source: CPRE, 2019)\n\n\n\n\n4.1.2 Green Belt and open space\nRough workflow:\n\nAnalyse spatial and temporal patterns of urban growth and loss of greenspace.\nInvestigate the quality of GB and open greenspace. (since it is found that densification of existing urban areas and development of inner-city brownfield sites are the main source of land use change, instead of expansion to GB which is controlled by GB policies in 2000 (“A Comparison of Greenspace Loss and Urban Expansion over Time in London and Nairobi  EOES Hub” 2017))\n\n\n\n\n\n\n\n\n\n\n\nPro ✔️ | Con ❌ | | | | | | | |\n\n\n\n\n1 To measure heat vulnerability / temperature through LST\n1) strong correlations between LST and air temperature;\n2) Compared to other measures such as air and surface temperature values taken at meteorological stations with coarse spatial resolution, satellite imagery derived LST presents data at higher spatial resolutions, thereby enabling comparisons among different neighborhoods.\n1) does not fully capture the set of micrometeorological conditions that factor into human thermal comfort or heat stress;\n2) Some of the images might be covered by clouds, which could seriously affect LST estimates. => limit the data to only clear-sky images\n\n\n\nDataset\nMOD11A2 Level-3 MODIS Land Surface Temperature and Emissivity (LST/E) 8-day products (1-km resolution) (Chen, Lin, and Chiu 2022) ❌ Spatial resolution of 1-km might be too broad for land use analysis.. so may require downscaling (could be achieved based on the inverse relationship between LST and NDVI)\nECOSTRESS Land Surface Temperature and Emissivity products (Li et al. 2022) ✔️ Fine-scaled atmospherically-corrected imagery throughout diurnal cycles at a 70m spatial resolution base on MODIS data, which allows the estimation of daytime and nighttime LSTs. | SOLWEIG: localised temperature modelling(MacLachlan et al. 2021) Requirement: Elevation (EO: OSM+ CSIRO) + Land cover data (EO: OSM+ CSIRO) + Meteorological data (air temperature, relative humidity, barometric pressure, wind speed, wind direction, and downward shortwave radiation) (e.g. Perth International Airport weather station) ✔️ 1) compare temperature dynamics within low- and high-density urban areas; 2) use as a basis for assessing a planned redevelopment and how optimizing tree placement relative to modeled temperature values could assist in mitigating localized UHI impacts. ❌ Owing to these data frequently being unavailable in a spatially continuous form (e.g., raster data), the input required for SOLWEIG is often limited to point data, acquired from weather stations. |\n\n\n\n\n\n\n\n\n2 To see the boundary of GB (land cover / land use changes)\nSentinel –> classification (veg vs land) (e.g. a supervised classifier (Random Forest). (“A Comparison of Greenspace Loss and Urban Expansion over Time in London and Nairobi  EOES Hub” 2017)\n\n\n\n\n\n\n\n4.1.3 Linkages to global goals\nThe 2030 Agenda for Sustainable Development tied “sustainable cities and communities” to both safety and resilience (SDG 11)\nThe United Nation New Urban Agenda highlighted cities’ importance to\n\n(g) Adopt and implement disaster risk reduction and management, reduce vulnerability, build resilience and responsiveness to natural and human-made hazards and foster mitigation of and adaptation to climate change;\n(h) Protect, conserve, restore and promote their ecosystems, water, natural habitats and biodiversity, minimize their environmental impact and change to sustainable consumption and production patterns.\nhttps://habitat3.org/the-new-urban-agenda/\n\nThe United Nation World Cities Report: fostering nature-based solutions and ecosystem services (5.4);\n\nNBSs are promising in the context of halting biodiversity loss and restoring urban ecosystem services in economically viable ways\nThe International Union for Conservation of Nature (IUCN) defines NBSs as “actions to protect, sustainably manage, and restore (create) natural or modified ecosystems” that simultaneously address social challenges, providing both human well-being and biodiversity benefits.\nNBSs are aligned with the United Nations 2030 Agenda for Sustainable Development\nhttps://unhabitat.org/sites/default/files/2022/06/wcr_2022.pdf\n\n\n\n4.1.4 Advancing local, national and global approach\n(local)\nCurrent protection of GB: 1) protected from inappropriate development. 2)improvement projects (discrete cases)\nAdd-on values: Besides combating UHI (and preventing sprawl), GB also reduces air pollutions, provides local food source and enhances ecosystem and biodiversity.  \nOptimization for plans: Global policies lack an effective data-driven approach in deriving optimal vegetative placement—particularly for reducing the ever-increasing socio-economic and environmental impacts associated with UHI effects (MacLachlan et al. 2021)\nQuality and monitoring. – long-term inspection of quality (changes through time and seasons – identify key areas for improvements / where to spend money on)\n(national)\n(global)\nUrban planning rarely integrates biodiversity and ecosystem services into service and design, aside from demonstration projects. (World Cities Report)"
  },
  {
    "objectID": "4_policy.html#reflection",
    "href": "4_policy.html#reflection",
    "title": "5  Policy",
    "section": "5.2 Reflection",
    "text": "5.2 Reflection\nThis section will list the lessons learnt from the policy and remote sensing data application.\n\nRemote sensing data can be used effectively to reduce the labor-intensive work / 3-Ds work (e.g. physically surveying and collecting data) and to some extent increase the accuracy of data collection.\nNational and global higher level policies and goals tend to be more generic and vague in terms of the solutions and approaches to reach the stated visions. Local policy and guidance, complying the higher level policies, tend to consider the contextual attributes. Thus, it can sometimes be difficult to provide one-size-fit-all solutions in local policy (and academic papers). Nevertheless, the case studies and more detailed guidelines may help in this context (from city planning perspective but many not for other themes like ecology and forestry), as well as the provision of tools and methods like the one on optimization of tree placement.\nSome challenges might not be under the control of the city. For instance, Green Belt is beyond the London metropolitan boundary and extend to wider areas. The regulation and effective maintenance might require collaboration from different local authorities. Plus majority of the land on Green Belt is privately owned..\nWhen writing papers, the recommendations / long-term solutions on how to reach the policy goals should be proposed in addition to the findings from the data.\n\n\n\n\n\n“A Comparison of Greenspace Loss and Urban Expansion over Time in London and Nairobi  EOES Hub.” 2017. https://blogs.kcl.ac.uk/eoes/2017/03/23/a-comparison-of-greenspace-loss-and-urban-expansion-over-time-in-london-and-nairobi/.\n\n\nChen, Tzu-Ling, Hung Lin, and Yin-Hao Chiu. 2022. “Heat Vulnerability and Extreme Heat Risk at the Metropolitan Scale: A Case Study of Taipei Metropolitan Area, Taiwan.” Urban Climate 41 (January): 101054. https://doi.org/10.1016/j.uclim.2021.101054.\n\n\nLi, Dongying, Galen D Newman, Bev Wilson, Yue Zhang, and Robert D Brown. 2022. “Modeling the Relationships Between Historical Redlining, Urban Heat, and Heat-Related Emergency Department Visits: An Examination of 11 Texas Cities.” Environment and Planning B: Urban Analytics and City Science 49 (3): 933–52. https://doi.org/10.1177/23998083211039854.\n\n\nMacLachlan, Andrew, Eloise Biggs, Gareth Roberts, and Bryan Boruff. 2021. “Sustainable City Planning: A Data-Driven Approach for Mitigating Urban Heat.” Frontiers in Built Environment 6. https://www.frontiersin.org/articles/10.3389/fbuil.2020.519599.\n\n\nRahbar, Morteza, Mohammadjavad Mahdavinejad, Amir H. D. Markazi, and Mohammadreza Bemanian. 2022. “Architectural Layout Design Through Deep Learning and Agent-Based Modeling: A Hybrid Approach.” Journal of Building Engineering 47 (April): 103822. https://doi.org/10.1016/j.jobe.2021.103822.\n\n\nWan, Da, Xiaoyu Zhao, Wanmei Lu, Pengbo Li, Xinyu Shi, and Hiroatsu Fukuda. 2022. “A Deep Learning Approach Toward Energy-Effective Residential Building Floor Plan Generation.” Sustainability 14 (13): 8074. https://doi.org/10.3390/su14138074."
  },
  {
    "objectID": "4_policy.html#summary-application",
    "href": "4_policy.html#summary-application",
    "title": "5  Policy",
    "section": "5.1 Summary & Application",
    "text": "5.1 Summary & Application\n\n5.1.1 Policy Challenge in London\nThe 2021 London Plan incorporates Urban Heat Island (UHI) effect into the strategic spatial planning. Below are some themes/policies related to UHI.\n\n\n\n\n\n\n\nSolutions to mitigate & adapt UHI set by the Plan\nLinkage to remote sensing data\n\n\n\n\nEnsure efficiency and resilience in building and infrastructure design (GG6 B)\nNot RS’s specialty\n\n\n(more towards adaptation) Set minimum building height to ensure daylight and ventilation (passive cooling) (3.6.3)\n(maybe) using SAR phasing to monitor the building heights, and Sentinel to measure the distance between building blocks, to find areas that would be most affected by insufficient indoor daylight and ventilation and act upon.\n\n\nGreen infrastructure provision in an integrated way (8.1)\nSuggesting/optimizing tree placement in the hottest areas of new developments & public space (MacLachlan et al. 2021)\n\n\nGreen Belt protection (comply with NPPF) –constrain urban sprawl and drive re-use of previously developed brownfield land (8.2.1)\nMonitoring Green Belt & open greenspace [detailed below]\n\n\nUrban greening (street trees, green roofs, green walls, and rain gardens) (8.5.2)\nSuggesting/optimizing tree placement in the hottest areas of new developments & public space (MacLachlan et al. 2021)\nSuggesting green roof locations in areas with darker roofs and higher temperature.\n\n\nManage heat risk through applying cooling hierarchy in new developments (through design, layout, orientation, materials and the incorporation of green infrastructure) (SI 4A; SI 4B; 9.4.1)\nNot RS’s specialty, largely depends on design/project management/planning enforcement.\nNevertheless, energy-efficient architecture layout can be generated through deep learning (Wan et al. 2022)and Agent Based Modelling (Rahbar et al. 2022)!\n\n\n\n\nLondon Green Belt\n\nLondon’s Green Belt provides an important long-term benefit for all those living in, around and visiting London; its landscape beauty and the haven it provides for an improved and thriving wildlife; its significant contribution to the mitigation of the climate emergency and enhancing people’s health and wellbeing; the facilities it offers for outdoor recreation, and its resource for food and farming close to London; all this in addition to its traditional role of containing urban sprawl and encouraging regeneration. (Source: CPRE, 2019)\n\n\n\n\n5.1.2 Green Belt and open space\nRough workflow:\n\nAnalyse spatial and temporal patterns of urban growth and loss of greenspace.\nInvestigate the quality of GB and open greenspace. (since it is found that densification of existing urban areas and development of inner-city brownfield sites are the main source of land use change, instead of expansion to GB which is controlled by GB policies in 2000 (“A Comparison of Greenspace Loss and Urban Expansion over Time in London and Nairobi  EOES Hub” 2017))\n\nTo see the boundary of GB (land cover / land use changes):\n\nSentinel –> classification (veg vs land) (e.g. a supervised classifier (Random Forest). (“A Comparison of Greenspace Loss and Urban Expansion over Time in London and Nairobi  EOES Hub” 2017)\n\nTo measure heat vulnerability / temperature through LST:\n\n✔️1) strong correlations between LST and air temperature;\n✔️2) Compared to other measures such as air and surface temperature values taken at meteorological stations with coarse spatial resolution, satellite imagery derived LST presents data at higher spatial resolutions, thereby enabling comparisons among different neighborhoods.\n❌1) does not fully capture the set of micrometeorological conditions that factor into human thermal comfort or heat stress;\n❌2) Some of the images might be covered by clouds, which could seriously affect LST estimates. => limit the data to only clear-sky images\nMOD11A2 Level-3 MODIS Land Surface Temperature and Emissivity (LST/E) 8-day products (1-km resolution) (Chen, Lin, and Chiu 2022)\n\n❌ Spatial resolution of 1-km might be too broad for land use analysis.. so may require downscaling (could be achieved based on the inverse relationship between LST and NDVI)\n\nECOSTRESS Land Surface Temperature and Emissivity products (Li et al. 2022)\n\n✔️ Fine-scaled atmospherically-corrected imagery throughout diurnal cycles at a 70m spatial resolution base on MODIS data, which allows the estimation of daytime and nighttime LSTs.\n\nSOLWEIG: localised temperature modelling(MacLachlan et al. 2021)\n\nRequirement: Elevation (EO: OSM+ CSIRO) + Land cover data (EO: OSM+ CSIRO) + Meteorological data (air temperature, relative humidity, barometric pressure, wind speed, wind direction, and downward shortwave radiation) (e.g. Perth International Airport weather station)\n✔️ 1) compare temperature dynamics within low- and high-density urban areas;\n✔️ 2) use as a basis for assessing a planned redevelopment and how optimizing tree placement relative to modeled temperature values could assist in mitigating localized UHI impacts.\n❌ Owing to these data frequently being unavailable in a spatially continuous form (e.g., raster data), the input required for SOLWEIG is often limited to point data, acquired from weather stations.\n\n\n\n\n5.1.3 Linkages to global goals\nThe 2030 Agenda for Sustainable Development tied “sustainable cities and communities” to both safety and resilience (SDG 11)\nThe United Nation New Urban Agenda highlighted cities’ importance to\n\n(g) Adopt and implement disaster risk reduction and management, reduce vulnerability, build resilience and responsiveness to natural and human-made hazards and foster mitigation of and adaptation to climate change;\n(h) Protect, conserve, restore and promote their ecosystems, water, natural habitats and biodiversity, minimize their environmental impact and change to sustainable consumption and production patterns.\nhttps://habitat3.org/the-new-urban-agenda/\n\nThe United Nation World Cities Report: fostering nature-based solutions and ecosystem services (5.4);\n\nNBSs are promising in the context of halting biodiversity loss and restoring urban ecosystem services in economically viable ways\nThe International Union for Conservation of Nature (IUCN) defines NBSs as “actions to protect, sustainably manage, and restore (create) natural or modified ecosystems” that simultaneously address social challenges, providing both human well-being and biodiversity benefits.\nNBSs are aligned with the United Nations 2030 Agenda for Sustainable Development\nhttps://unhabitat.org/sites/default/files/2022/06/wcr_2022.pdf\n\n\n\n5.1.4 Advancing local, national and global approach\nLocal\n\nCurrent protection of GB: 1) protected from inappropriate development. 2) improvement projects (discrete cases)\nAdd-on values: Besides combating UHI (and preventing sprawl), GB also reduces air pollutions, provides local food source and enhances ecosystem and biodiversity.  \nOptimization for plans: Global policies lack an effective data-driven approach in deriving optimal vegetative placement—particularly for reducing the ever-increasing socio-economic and environmental impacts associated with UHI effects (MacLachlan et al. 2021)\nQuality and monitoring. – long-term inspection of quality (changes through time and seasons – identify key areas for improvements / where to spend money on)\n\nNational\n\nNational Planning Policy Framework (NPPF) states to protect the integrity of Green Belt. but does not mention how.\n\nGlobal\n\nUrban planning rarely integrates biodiversity and ecosystem services into service and design, aside from demonstration projects. (World Cities Report)\n\n\n\n5.1.5 Question\n\nIs there any privacy concern on monitoring via remotely sensed data? (e.g. in the case of watering gardens, what if the residents get angry about being monitored and refuse to make changes?)\n\n\nYes. If the solution/intervention is in private land, the alternative in public space would be provided. The government / clients tend to prevent privacy concerns when deploying a model so the actual deployment could be affected… (could be another drawback of using EO/remote sensing data?)."
  },
  {
    "objectID": "5_GEE.html#summary",
    "href": "5_GEE.html#summary",
    "title": "6  Google Earth Engine",
    "section": "6.1 Summary",
    "text": "6.1 Summary\n\n\n\n\n\n\nThe key benefit of using GEE is that the datasets are cloud-hosted and efficient computations can be executed through servers (Gandhi and Howarth, n.d.).\nPlus, it is efficient in sharing the codes with the used data to others (albeit that person will need a GEE account) (i.e. there is less pain to share the processes - no downloading and pasting the code in the scripts by collaborators - which is still required when using SNAP and QGIS). This benefit will be deployed below/in following weeks when outputs from GEE are attached.\n\n\n\n\nServer vs. Client\n\nServer is like the back-end of GEE, responsible for data storage, including Earth Engine Objects. On the other hand, client is the browser/interface of GEE, including polygons imported from local.\n\n\n\n6.1.1 Scale\nImagery is pre-processed (cut into 256x256 tiles in original projection and resolution) (Gorelick et al. 2017). Scale is related to the spatial resolution/pixel of the datasets. The scale of Landsat-8 10m and 30m has the same value because the nominal/native resolution of Landsat-8 is at 30m. For different purpose of analysis, the resolution / scale would be different. Continental level analysis may use coarse scale and forest/tree placement may require fine scale.\nAs scale can be influenced by zoom levels, it should be set to ensure the consistency of the values across analysis (explore pixel resolution values at different scales > set pixel resolution when Map.addLayer).\n\n\n\n\n\n\nThis will enable fast and efficient access and fast visualization (Gorelick et al. 2017).\n\n\n\n\n\n6.1.2 Filter\nImagery (raster data) can be filtered by date / by location (specified path and row)/boundary/polygon (imported shapefile or drawn manually) (similar to st.join/st.intersect) / by bands. Feature (vector/polygon) can also be filtered by ID/attributes usually.\n\n\n6.1.3 Map\nNot looping. Load the image collection once and repeat the calculation/function for each image.\n\n\n\n\n\n\nThis ensures more efficient codes and computation, being certain on the amount of objects in the collection (otherwise looping use x+1 iteration).\n\n\n\n\n\n6.1.4 Reducer\nReducer is like conducting zonal statistics in QGIS (similar to groupby in R). It summarizes lots of images into one image composite through specified methods (Cardille et al., n.d.). For example:\nBy median of the pixels in collections -\n\n\n\n\n\n\nMedian is good for distinct/large difference in index values (e.g. forest vs. non-forest).\n\n\n\n\n\n\n\n\n\nbut.. not as good when the area has few pixels > use the normalizing statistics (= percentiles) instead (high percentiles concentrate on top indicate the classifier is more robust)\nand.. not representing seasonality (esp. for vegetation/crop/forest) > medians of the pixels in 4 seasons (divide the time series into 4 in a list) (Source: Google Earth)\n\n\n\nBy geographical boundary -\n\nImage.reduceRegion: one boundary (e.g. GLA boundary)\nImage.reduceRegions: sub-divided regions within a boundary (e.g. Boroughs within GLA boundary) - more like zonal statistics.\n\n\n\n\nFilter, map, reduce (Cardille et al., n.d.)\n\n\n\n\n6.1.5 Join\nCombine data/elements from different collections. Join can be applied to 2+ datasets (e.g. Landsat and Sentinel), data in different time series, etc. An equal filter ee.Filter.equals() will be used for matching different data.\n\n\n6.1.6 Risks/limitations of GEE\n\n\n\n\n\n\n\nUncertainty of future change in GEE openness (can be closed / charged (and currently it is charged for business/commercial use))\nSAR phased data cannot be used on GEE (need SNAP for this).\nGEE is better at live exploration and mapping but not good at analysis (recommended workflow: GEE (reduce data size&pre-processing) > R (analysis))\n\n\n\n\n\n\n\n\n\n\nHence, future development of GEE could be the inclusion of more advanced analytical capabilities like prediction and wider datasets like LiDAR. Also, a better integration with other softwares could be aimed for (like Xaringan to R, GEE could develop some add-ins/packages for analysis)."
  },
  {
    "objectID": "5_GEE.html#application",
    "href": "5_GEE.html#application",
    "title": "6  Google Earth Engine",
    "section": "6.2 Application",
    "text": "6.2 Application\nThis section demonstrates some applications utilizing the benefits of GEE in analyzing changes through timelapse and comparing across locations.\n\n6.2.1 Built-up area / urban expansion\n\nGIF of the urbanization trajectories using Landsat 8 Level 2 Tier 1 (Wang et al., n.d., chap. A1.2)\n\n\n\n\nmy first GEE GIF!\n\n\nFollowing the practical by (Wang et al., n.d., chap. A1.2), the above GIF (GEE code here) shows the 2010-2020 changes in the area of the Kempegowda International Airport in India visually (its now the fourth busiest airport in the country). Then it would be helpful to quantify the change in the areas by classification.\n\n\n\n\n\n\nGIF is more efficient to show changes across time compared to sliders and A/B diagrams. Sometimes using sliders takes time to load the data and makes the comparison less direct, while showing A/B diagrams in the report may be restricted to the limited specified set of years (e.g. 2010 and 2020, instead of all the available time).\n\n\n\n\nUrban / LCLU classification (also detailed in two following weeks’ chapters)\n\nMany datasets are available, with different coverage and properties. The MODIS Land Cover Type Yearly Global can be used to map the changes in urban areas (it is the global dataset!) (Wang et al., n.d., chap. A1.2)\nOnce the urban/built-up area is classified, the result could be further integrated into analysis on urbanization challenges like UHI, flooding…\n\n\n6.2.2 Urban Heat Island (UHI)\nMODIS & Landsat (EE LST toolbox) can both be used to calculate land surface temperature (LST) (Wang et al., n.d., chap. A1.5). Since surface UHI can be quantified as the urban temperature subtracts rural reference, the rural/urban classification in the previous section can be applied to 1) mask the urban area for analysis and 2) calculate the difference between urban and rural LST.\n\n\n\nSurface Urban Heat Island in Kinmen\n\n\nWith reference to (Wang et al., n.d., chap. A1.5), the above map (GEE code here) shows the spatial variability in Surface UHI in summers between 2014 and 2019 for Kinmen County using Landsat-8. (Red pixels: higher (diff.max=8°C); blue pixels: lower (diff.min=2°C). Summer temperature is used here to avoid the difference in seasons balancing out the peak values. The built-up area (shown as all the colored pixels) is quite small, as the county is still urbanizing slowly with a population of 140,843 within a 151.6 km2 area in 2022 as per Wikipedia. Arguably, this city with limited ‘urban sprawl’ might not be a proper site for analyzing UHI. However, the intensity of UHI is high in the most populous town Jincheng (with population density of 1,946 ppl/km2, whereas the whole county’s density is 929 ppl/km2). Plus, the usual residents is 40% of the total census population in the county. The elderly who live alone take up a large share of the usual residents. High temperature in the urban areas may increase the threats to those vulnerable groups.\nAnother hot-spot is in the central-south of the island which is the location of the Airport. More specifically, that is the location of the Airport hall, bus stops, taxi and car park, while the runway of the Airport is not classified as urban by MODIS (yet the LST is also high on runway). High reflectance of the road and building material, the absence of trees and vegetation and the high volume of GHG emissions may contribute to the high temperature in this area compared to its rural neighbours.\n\n\n6.2.3 Earth Engine APP\nA range of pre-processed / classified GEE models are openly shared here. With the benefit of displaying large data and information quickly, the interaction between users and data is enhanced. Some excellent examples/techniques/visualisations to learn from e.g. using sliders to change the year / cities / show before-after comparison, etc.."
  },
  {
    "objectID": "5_GEE.html#reflection",
    "href": "5_GEE.html#reflection",
    "title": "6  Google Earth Engine",
    "section": "6.3 Reflection",
    "text": "6.3 Reflection\nFrom the analysis on UHI in Kinmen, one lesson learnt is that UHI mitigation should not focus on large urbanized areas only. When considering the local context, some rural locations (e.g. based on low population density) with high urban infrastructure or poor building material may similarly associate with high changes/difference in temperature (albeit land surface temperature might not be identical to the ambient temperature). Those areas are usually lack of proper regulation or with some vulnerable groups. Hence, government and planners should not left those areas behind when making national plans. The local authorities, communities and researchers may work together to achieve high resilience.\n\n\n\n\n\n\nFuture development around heat management in local areas may incorporate remote sensing in monitoring and predicting high risks areas. Planning application data on building material type, year of construction and energy efficiency of the building could be integrated into a shared platform to further regulate housing development. Various approaches could be conducted by the public body to enhance energy efficiency of the built construction, like providing incentives for renovation and compiling design code for new built projects. Communities may also advertise and educate local on the UHI and its adaptation measures.\n\n\n\n\nWhen calculating the UHI, several familiar concepts from week 1 reoccur like the different surface reflectance for materials being sampled to determine the land cover type - done by the MODIS dataset. The transformation of the data where the brightness temperature and emissivity (based on fractional vegetation cover from NDVI) are combined to find LST - done by the EE toolbox/module within a few steps.\n\n\n\n\n\nCardille, Jeffrey A., Gennadii Donchyts, Ujaval Gandhi, Txomin Hermosilla, Saverio Francini, Andréa P. Nicolau, and Michael A. Wulder. n.d. “F4 - Earth Engine Fundamentals and Applications - EEFA - Live Document.” https://docs.google.com/document/d/11oo1TuvXyEvReoYLDeTcoh16rEN90I8Bf5qp0KxVu7U/edit?usp=embed_facebook.\n\n\nGandhi, Ujaval, and Jeff Howarth. n.d. “F1 - Earth Engine Fundamentals and Applications - EEFA - Live Document.” https://docs.google.com/document/d/1dLSaGXlAnI0jK6LAB6F-gQLBA30NTT0pz1tovHfOmvI/edit?usp=sharing&usp=embed_facebook.\n\n\nGorelick, Noel, Matt Hancher, Mike Dixon, Simon Ilyushchenko, David Thau, and Rebecca Moore. 2017. “Google Earth Engine: Planetary-Scale Geospatial Analysis for Everyone.” Remote Sensing of Environment, Big Remotely Sensed Data: tools, applications and experiences, 202 (December): 18–27. https://doi.org/10.1016/j.rse.2017.06.031.\n\n\nWang, Sherrie, George Azzari, Michelle Stuhlmacher, Ran Goldblatt, Erin Trochim, Zander Venter, and Sourangsu Chowdhury. n.d. “A1 - Earth Engine Fundamentals and Applications - EEFA - Live Document.” https://docs.google.com/document/d/1MIPIFMJakC6eNGOhlkXLcwjUKFyY6QJLHElzBCOfyn4/edit?usp=embed_facebook."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Content",
    "section": "",
    "text": "In this diary,\nEach chapter is the content taught in the corresponding week:\n\nIntroduction\n\nRemote sensing data intro / sensors / resolutions (using QGIS/SNAP/R)\n\nSensor - WorldView3\nCorrections\n\nCorrections / Enhancements (using R)\n\nPolicy\nGEE\n\nFilter/reduce/map (using GEE)\n\nClassification\n\nPixel-based (supervised and unsupervised)\n\nClassification 2\n\nObject-based, sub-pixel, accuracy assessment\n\nTemperature\n\n\n\n1.0.1 In each chapter,\nThere will be a summary of key concepts learnt in lecture or practical in that week (!= all the contents but those that are more interesting/useful/powerful (personally)).\n\nContent summary (outputs from the practical, small code chunks with relevant explanation and flow charts)\n\n\n\n\n\n\n= Benefits of data, policy or methods\n\n\n\n\n\n\n\n\n\n= Limitations of data, policy or methods\n\n\n\n\n\n\n\n\n\n= Potential future development\n\n\n\nQuestions on data, policy or methods (but mostly on practicals) and answers to them.\n\nA section of applications will follow, focusing on weekly reading but sometimes expanding to wider literature based on interests.\nFinally, there will be a personal reflection on the presented content. This section will include what was interesting (to my planning knowledge) and why (e.g. why the content presented this week will be useful in the future).\nHappy reading!"
  },
  {
    "objectID": "6_classification.html#summary",
    "href": "6_classification.html#summary",
    "title": "7  Classification 1",
    "section": "7.1 Summary",
    "text": "7.1 Summary\nHuman is good at finding patterns in imagery while computers are not. The patterns / land cover types are useful for analysis, but it is tedious to digitize huge amount of data manually. Hence, the task is given to the computers (being more accurate and faster), extracting patterns from remote sensing data. Decision trees replicate human decisions on detecting patterns and making conclusions based on given information (expert system!). Multiple methods based on decision trees are developed to classify remote sensing image!\n\nImage classification: Segregate pixels of a remote sensing image into groups of similar spectral character / spectral categorical classification.\n\n\n7.1.1 3 types of image classification\n\nUnsupervised image classification\n\n\n\n\n(GISGeography, 2014)\n\n\n\nUnsupervised image classification\n\nA method of categorizing data without any prior knowledge of the data [main difference with supervised classification], based solely on the inherent structure of the image itself (i.e. No ground truth examples are provided to the training algorithm / not know information on class, except the number of class).\n\n\nProcess: Clustering algorithm: K-means; ISODATA > number of clusters [Fewer clusters have more resembling pixels within groups. More clusters increase the variability within groups. (GISGeography 2014)] > manually assign land cover classes to each cluster\n\n\n\n\n\n\nThis technique addresses the issue mentioned in Week1 about the reliance on prior knowledge of the local geography when selecting training/labelling LC features. This may enhance the analysis efficiency through increasing accuracy and lowering time consumed, with the possibility of scaling up. Furthermore, patterns that are less apparent to human-eye can be detected by this technique.\n\n\n\n\n\n\n\n\n\nThe output may be harder to interpret, requiring further analysis to understand the classes. In this case, the involvement of human knowledge (not necessarily prior knowledge) would be needed to ensure the accuracy and usefulness of the outputs (which also depend on functions and data).\n\n\n\n\nSupervised image classification\n\n\n\n\n(GISGeography, 2014)\n\n\n\nSupervised image classification\n\nA method of categorizing data based on a training dataset of labeled examples.\n\n\nProcess: Select representative training samples for each land cover class > generate a signature file, storing all training samples’ spectral information > use the signature file to run a classification (through one of the classification algorithm: Maximum likelihood (normal distribution/parametric); Density slicing; Nearest neighbor; Minimum-distance; Principal components; Support vector machine (SVM); CART; RF; Iso cluster; Neural network) > pixel assignment > accuracy assessment\n\nCART: a tree\nRF: merging many trees, trained with bagging methods (to create a combination of learning models which improves the overall result)\nSVM: optimal multi-dimensional decision hyperplane boundary that divides the dataset (test all possibilities of C and Gamma > compare with testing data > choose the combination with best accuracy)\n\n\n\n\n\n\n\nIt tends to produce highly accurate results since the training data is given by human. And it is easier to interpret to the same reason. Plus, this technique is powerful given its wide application to different data and project purposes.\n\n\n\n\n\n\n\n\n\nAs mentioned, the outcomes can be limited to the labelled classes, so it is harder to apply the same model to wider coverage / different locations where the LULC is different. Contrary to unsupervised one, this method cannot detect patterns that are not visible to human-eye / knowledge (e.g. substances under water..). Hence, more attention to training data accuracy and comprehensiveness is required (but overall this method is powerful!).\n\n\n\n\n\n\n\n\n\nFuture development on classification techniques could focus on enhancing the accuracy and reducing the need of labeling. The deep learning techniques like CNNs could be incorporated to detect complex patterns (already being developed in some cases like the Dynamic World (Brown et al. 2022)). Ancillary data can also be integrated to the imagery, being the additional context of the locations (e.g. terrain, climate, soil…). This may reduce some concerns on the difference between places/time series making the model less applicable/reproducible.\nAdvancement in sensors increases the possibility of recording more data in the imagery, leading to better accuracy in classification (RedEdge band in RapidEye for example). Image fusion methods are also important to allow new data to be incorporated. Optical and radar imagery fusion may allow more information being included in one analysis.\n\n\n\n\nObject-based image analysis (OBIA)\n\n\n\n\n(GISGeography, 2014)\n\n\n\nObject-based image classification (more in Week7)\n\nA method integrating image segmentation with classification algorithms to group pixels together into meaningful objects/vector shapes.\n\n\n\n\n7.1.2 Overfitting (of trees)\n\nOverfitting\n\nThis happens when a model is trained on a limited dataset that is not representative of the full range of possible inputs, resulting in a model that performs well on the training data but poorly on new, unseen data.\nIt can also occur when a model is too complex and includes too many parameters, resulting in a model that is too closely tailored to the training data and unable to generalize. This is often referred to as “memorizing” the training data rather than learning from it. This will result in leaves on the decision tree having one value..\n\n\n\nLarge difference between predicted values and true value (= high bias = oversimplified model);\nHigh variability of a model for a given point (= high variance = not generalize enough)\n\n\n\n\nVariance and Bias (Singh, 2018)\n\n\n\n7.1.2.1 2 methods to balance bias and variance (regularization)\n\nLimit the minimum number of pixels in leaves (usually 20 pixels) = top-down, easier to perform, but less mathematically sound.\nWeakest link pruning with tree score (find the weakest link and delete it) = bottom-up.\n\nTree score = SSR + tree penalty (alpha) * T(number of leaves)\nFor all data > Use alpha=0 for all data (=full tree = SSR) > increase alpha values > find the Alpha with lowest tree score compared to the full tree when decreasing number of leaves\nTrain and test split > Use the Alpha for train data > new trees > put test data in new trees > calculate SSR for test data > find the tree/alpha with the smallest SSR\nRepeat 10 times the above train and test split (using different data combinations) > find the alpha with lowest SSR across 10 repetitions\nApply this final alpha to the whole data\n\n\nCross-validation in Week7 can also be conducted to assess the performance of the model to new data.\n\n\n\n7.1.3 Question\n\n(Practical) Whats the difference between .reduce(ee.Reducer.median()) and .median() ?\n\n\nTested - mostly no difference in the outputs. but the band name becomes B1_median when using reducer.median..\n\n\n\noutput using .reduce\n\n\n\n\n\noutput using .median\n\n\n\n\n(Practical) Why the background vector map is not consistent with the remote sensing map (like the roads and buildings are not in the same position, see below snapshot)? Will this influence the data selection and accuracy (i assume other datasets may also have different consistency)?\n\n\n\n(A: projection, but dont bother..)\n\n\n(Practical) How to select high and low urban samples for training for supervised classification? (High and low as of albedo or as of density? Based on Andy’s practical workbook, it is albedo. Is this for analyzing the impact of albedo/building material on the micro-climate and earth surface temperature?)\n\n\nA: Albedo - building reflectence - analysing the energy and temperature. For density - Google building data - areas of building / area of whole pixel ..\n\n\n(Practical) Error occur when trying to print the training data after selecting different land cover as feature collection: FeatureCollection: Collection query aborted after accumulating over 5000 elements.\n\n\nAnswers online: when printing the training data, use .limit(5000) to allow printing subset of large data. (not sure if it is the right way to do, but this is the checking process afterall) (and not sure why the data is so large..)"
  },
  {
    "objectID": "6_classification.html#application",
    "href": "6_classification.html#application",
    "title": "7  Classification 1",
    "section": "7.2 Application",
    "text": "7.2 Application\nClassification of EO imagery allows extracting (and predicting) patterns/land cover from the data. This supports analysis on LULC, urban expansion, urban green space, illegal logging, forest fire, etc.\nImage classification workflow: DN/reflectance of imagery > (some fieldwork / Google Earth selection of training land cover type data >) being divided based on similarities/closeness to each other using different forms of classifiers/algorithms > revealing/predicting the LULC of the Earth surface > testing accuracy > being used for further analysis / practical applications in assisting decision making.\n\n7.2.1 CART & Random Forest\nAs done in the practical, the Sentinel data is classified using CART and RF. When selecting training data (selecting land cover geometries as variables), the false inference on the landuse and the inclusion of other land cover type in the geometry may add noise to the prediction, hence lowering the accuracy. Also, mentioned in the practical, when splitting the data into training and testing (for accuracy testing), the pixels of the selected geometries should be used, rather than the geometry that may add more noise to the results.\n\n\n\nOutput from practical - land cover classification using CART\n\n\n\n\n\nOutput from practical - land cover classification using RF\n\n\nThe accuracy is not as high as Andy’s output. For RF, the OOB error is 6%.. and the accuracy is 93%. Resubstitution accuracy is 99% (original training data vs. model output). When comparing testing data and model output, the accuracy gives 93%. > Is there any correlations between OOB accuracy and the confusion matrix? (and is it possible to add the legend to the output?)\nComparing two outputs visually, RF captures the difference in high and low urban land cover types better than CART. However, both methods produce outputs that seems like salt and pepper since they are pixel-based. Although the low urban type might exist in the forest (like meterological stations), it might not be necessary when drawing out the forest boundary. Object-based methods could be used for this purpose and for higher resolution building boundary detection for instance.\n\n\n7.2.2 SVM\n[Technical / methods] Study by (Ustuner, Sanli, and Dixon 2015) constructs the a classification model for agricultural landuse in Turkey using SVM method with RapidEye imargery. With fieldwork and Google Earth information on land cover types, it compares the classification accuracy with the result from Maximum Likelihood Classification (MLC) and internally among the results using different parameters (error penalty (C), gamma, bias term (r), polynomial degree (d)) and kernel types (linear, polynomial, radial basis function, sigmoid). Accuracy is assessed through kappa coefficient (comparing classified images against ground truth data). Results show that the SVM method outperforms MLC and classification accuracy is influenced by the choice of parameters (and kernels) (Ustuner, Sanli, and Dixon 2015). However, the generalization performance of kernels is influenced by the types of dataset (multi- or hyper-spectural or SAR…) so the conclusion on the best-performing kernel type is not fixed (may vary due to dataset).\n[Context / application] The country’s agricultural productivity highly influence its economy. However, the data on agricultural statistics is manually collected by government employees from farmers’ declaration. The data could be unreliable (Ustuner, Sanli, and Dixon 2015) and labour-intensive, being not cost-effective for the government. Hence, methods like applying image classification on remote sensing data could provide viable, up-to-data and reliable information for sustainable crop management and planning. Before putting into practice, the sensitivity / reliability of the methods is tested through comparing between different models and within SVM using different parameters and kernels. The best combination of parameter and kernel will be used to inform decisions.\nFrom the ground truth map, different crop types usually looks similar to human eyes while obtaining different reflectance. Hence, field works would be required to collect in-situ point data using GPS and Google Earth ancillary data could be the additional data source with experts opinions (Ustuner, Sanli, and Dixon 2015).\n\n\n\n(Ustuner, Sanli and Dixon, 2015)\n\n\n[Result / recommendation] The above output shows highest accuracy selections (compared to results from other models with different error penalty in the same kernel) of four different kernels from SVM + the result from MLC. Kappa for MS9 = 0.8209, MR5 = 0.8222, ML11 = 0.8223, MP9 = 0.8411. >> Recommendation from the authors: optimum parameters for SVM should be analyzed in detail before choosing one for best classification result.\nAnother study by (Pal and Mather 2005) suggests that SVM (using pair-wise comparison for multi-class) achieves higher accuracy than ML and ANN. Nevertheless, effective use depends on the values of a few user‐defined parameters. SVM in dealing with multi-class: n hyperplanes should be determined (comparing one class with the rest > may produce unclassified data, hence lowing the accuracy) or n(n-1)/2 classifiers (pair-wise comparison) (Pal and Mather 2005)."
  },
  {
    "objectID": "6_classification.html#reflection",
    "href": "6_classification.html#reflection",
    "title": "7  Classification 1",
    "section": "7.3 Reflection",
    "text": "7.3 Reflection\nTo choose classifier, things to consider include:\n\nReference to literature on relevant themes might hint the direction.\nPerforming/comparing different classifiers might just be within several lines of code in GEE. (but.. Does the accuracy means everything? Choosing the one with highest accuracy might not be reproducible in the sense that different regions/time of year/giving new data could yield varying results?)\nThe choice of classifier depends on the intended outcomes and the data quality (Pragati21 2020; lanenok 2015).\n\n> SVM > sparse data & binary classification & non-linear data (faster and better results, gives distance to boundary)\n> RF > numerical and categorical features & multi-class (gives probability of belonging to class)\n> MLC (parametric) > assuming normally distributed data (not common in LULC data > may results in lower accuracy)\n\n\nClassification is valuable for urban planning mainly since its ability to identify LULC. As mentioned in previous weeks, LULC can be used to identify urban areas/growth, UHI, biodiversity and green space and flooding. It can be used in the ex-ante policy appraisal, identifying areas of improvements. Since it has information on different time series, EO data is also effective in evaluating policy outcomes / ex-post impact assessment, whereas census or other quantitative data might be constrained by the time scale and difference in sampling.\n\n\n\n\nBrown, Christopher F., Steven P. Brumby, Brookie Guzder-Williams, Tanya Birch, Samantha Brooks Hyde, Joseph Mazzariello, Wanda Czerwinski, et al. 2022. “Dynamic World, Near Real-Time Global 10 m Land Use Land Cover Mapping.” Scientific Data 9 (1): 251. https://doi.org/10.1038/s41597-022-01307-4.\n\n\nGISGeography. 2014. “Image Classification Techniques in Remote Sensing.” https://gisgeography.com/image-classification-techniques-remote-sensing/.\n\n\nlanenok. 2015. “Answer to \"When to Use Random Forest over SVM and Vice Versa?\".” https://datascience.stackexchange.com/a/6855.\n\n\nPal, M., and P. M. Mather. 2005. “Support Vector Machines for Classification in Remote Sensing.” International Journal of Remote Sensing 26 (5): 1007–11. https://doi.org/10.1080/01431160512331314083.\n\n\nPragati21. 2020. “SVM AND RANDOM FOREST: A Case Study.” https://medium.com/@pandeypragati2112/svm-and-random-forest-a-case-study-6213da5be02f.\n\n\nUstuner, Mustafa, Fusun Balik Sanli, and Barnali Dixon. 2015. “Application of Support Vector Machines for Landuse Classification Using High-Resolution RapidEye Images: A Sensitivity Analysis.” European Journal of Remote Sensing 48 (1): 403–22. https://doi.org/10.5721/EuJRS20154823."
  },
  {
    "objectID": "7_classification2.html#summary",
    "href": "7_classification2.html#summary",
    "title": "8  Classification 2",
    "section": "8.1 Summary",
    "text": "8.1 Summary\n\n8.1.1 OBIA\nCritique on pixel-based classification: Spatial autocorrelation (test/train) may influence the outcome of accuracy assessment (Tobler 1st Law). If not consider SA – model would be too good / high accuracy. SA could be solved by:\n\napplying distance filter/metrics or Moran’s I to the test/train data\nor classify the image through Object-based image analysis (OBIA).\n\nTwo parameters for OBIA:\n\nDistance (between centroids/seeds)\nHomogeneity/similarity of pixels around the centroids\n\nThe output would be features of the objects (e.g. mean of the pixel values) that look like art rather than imagery. OBIA is originally applied in medical and surgery (e.g. cancer detection).\nSegmentation algorithms: Multi-resolution segmentation in eCognition; The segment mean shift tool in ArcGIS > different methods to classify objects (shape; texture; spectral; geographic context; nearest neighbor)\n\n\n\n\n\n\nEsp. good for high spatial resolution image by avoiding the noisiness in the outputs of pixel-based methods, more like human in processing patterns (and hence more detailed information). Because OBIA used both spectral and contextual information, it had higher accuracy compared to pixel-based methods (when comparing high and medium spatial resolution imagery) (Weih and Riggan, n.d.). > gaining popularity due to increasingly amount of high-resolution data available! More in next chapter.. Similar to supervised classification, it is also flexible in dealing with different datasets.\n\n\n\n\n\n\n\n\n\nSegmentation can be time-consuming, computationally intensive and require some relevant knowledge. It can be biased depending on the algorithms and parameters used to define object.\n\n\n\n\n\n8.1.2 Sub-pixel analysis\n\nSub-pixel analysis\n\nThe composition of pixels at a sub-pixel scale / the fraction of selected features (endmember) per pixel\n\nEndmember\n\nThe pure spectral signatures of each land cover class\n\n\n\n\n\n\n\n\nThis technique may improve the accuracy of LULC classification. Due to its fine scale, detailed LC information and changes can be detected. Heterogeneity in LULC within pixel can be better classified.\n\n\n\n\n\n\n\n\n\nDifficult to assess accuracy (due to no test/train split and accuracy depends on endmember identification) > harden. Also, the outcomes are sensitive to the spatial resolution of imagery and better outcomes depend on the high quality data input with low noise and high radiometric resolution.\n\n\n\nApplications on pollution detection and % of vegetation\n\nspectrally pure ENDMEMBER selection: library (), lab, points/polygon (one point), value specification\nend-member * fraction >> unconstrained >> constrained (sum to one)\nif multiple points = MESMA\n\n\n\n8.1.3 Accuracy Assessment\nRandom sampling > test/train > model output > test output > matrix\n\nPA (producer accuracy)\n\n\\(\\frac{TP}{TP+FN}\\) == recall / sensitivity (correctly classified pixel vs. ground truth data)\n\n\n\nHigh PA: Low FN and High FP: e.g. predicted urban but actually other land cover type\nError of omission = 100-PA\n\n\nUA (user accuracy)\n\n\\(\\frac{TP}{TP+FP}\\) == precision (correctly classified pixel vs. same class pixels as classified)\n\n\n\nHigh UA: High FN and Low FP: e.g. predicted other but actually urban\nError of commission = 100-UA\n\nOA (overall accuracy): (TP+FP+FN+TN)\nPA and UA never both good: model with Low FN and Low FP does not exist. Since data is not balanced, changes in decision threshold of classification may vary the outcomes. Increasing FP (more predicted positive) > UA worsens > FN reduces > PA improves. The matrix are related and may change together. The trade-offs between the two make the ideal situation with high PA and high UA impossible.\nHence, one of them would be more important than the other under different scenarios and the one with higher relevance to the problem should be picked when analyzing accuracy and designing the model (Wilber, n.d.):\n\nRecall/PA is important when we believe False Negatives are more important than False Positives (e.g. our problem of cancer detection).\nPrecision/UA is important when we believe False Positives are more important than False Negatives (e.g. spam detection).\n\n\n8.1.3.1 F1 score\n\nF1 score\n\nTo solve the issue above with decision threshold, F1 score includes the information of both PA and UA in one single coefficient. \\(\\frac{TP}{TP+\\frac{1}{2}∗(FP+FN)}\\)\n\n\n\n\n\n(Wilber, 2022)\n\n\nWhen PA and UA are similarly well-performed, the F1 and OA are also highest (when decision boundary threshold = 0.50-0.58).\n\n\n\n\n\n\nNot considering TN & Assuming UA and PA equally important\n\n\n\n\nOther matrix to assess accuracy: calibration, popular diagnostic tools (specificity, likelihood ratios, etc.), expectation frameworks, Receiver Operating Characteristic Curve (ROC), Area Under the Receiver Operator Characteristic Curve (AUROC) (popular for binomial model).\n\n\n\n8.1.3.2 Kappa\n\nKappa coefficient\n\nThe accuracy of an image compared to the results by chance\\(k=\\frac{p_o−p_e}{1−p_e}\\)\n\\(p_o\\): the proportion of cases correctly classified (accuracy)\n\\(p_e\\): expected cases correctly classified by chance\n\n\n\n\n\n\n\n\nDifferent definitions by authors in terms of good Kappa & Different accuracy can have different ranges of kappa\n\n\n\n\n\n8.1.3.3 Cross validation\nData-splitting: based on simple, stratified, random selection.\nRepeated selection (resampling by bootstrapping): to compute the sampling variability of the accuracy metric (changing the split) (Karasiak et al. 2022)\nFind the average of different scenarios to test how generalisable the model is\n\n\n\n\n\n\nRandomly distributed points for testing may have spatial autocorrelation with nearby training data > influencing overestimating the accuracy / overfitting the model.\n\n\n\nSpatial cross validation\nTo mitigate issue with Spatial autocorrelation in Cross validation, randomly distributed clusters of points (clustering through Moran’s I, DBSCAN, Distance metrics..) are selected for testing (Lovelace, Nowosad, and Muenchow 2019).\n\nreference data are also split into subsets like in cross validation but the number of subsets can vary (k-fold) (Karasiak et al. 2022).\nk-fold > random sample > > best values of C and gamma for SVM > fold >> ML3 IN R > GEE not good at data analysis but for remote sensing data\n\n\n\n\n(Lovelace et al., 2019)\n\n\n\n\n\n\n\n\nmlr3 to split data for spatial CV:\n3 stages: 1) task: data specification (including response and predictor variables) and the model type (such as regression or classification). 2) learner defines the specific learning algorithm that is applied to the created task. 3) resampling approach assesses the predictive performance of the model, i.e., its ability to generalize to new data.\nDetailed example see (Lovelace, Nowosad, and Muenchow 2019).\n\n\n\nLeave one out (for everything except one point) – more extreme / computationally extensive\n\n\n\n\n\n\nSelecting data for training / testing / accuracy:\n>> reproducible (same model for different years data) == (choose land that not change to much –  pseudo-invariant features) / (manual selection of ROI) / (choose same parcel/feature from different years = generalizable) == no fixed rules"
  },
  {
    "objectID": "7_classification2.html#application",
    "href": "7_classification2.html#application",
    "title": "8  Classification 2",
    "section": "8.2 Application",
    "text": "8.2 Application\nBelow are some examples of pre-classified data that could be imported in GEE.\n\n8.2.1 Dynamic world\n\nGEE data catalog\n\nProcess: World / region / biomes > experts / non-experts to label training pixels (5x5) > pre-processing (> TOA > rotate > band math/ratioing) > normalisation (log) > classification (CNN)\n\n\n\n\n\n\nNear real time data at 10m resolution (Sentinel-2 with 2-5 days revisit)\n\n\n\n\n\n\n\n\n\nBlobbing – since ppl/users train data + CNN (deep learning, moving window of filtering..)\n\n\n\n\n\n8.2.2 Google open building data\n\nGEE data catalog\n\nThis dataset includes building info like outlines, footprints on the ground, confidence score (on if this is a building / accuracy), the centroid of the building (not having info like building typology, address, and other details beyond geometry).\n\n\n\n\n\n\n50cm high-resolution\n\n\n\n\n\n\n\n\n\nCurrently constrains to Africa, South Asia and South-East Asia locations\n\n\n\nThoughts on applications suggested by developers:\n\nPopulation mapping: largely related to the population estimates based on building block. Estimating population based on building outline seems less convincing as the building height data is not assessed. This could be solved by combining the method of detecting building shades from satellite imagery and sample building height annotations with longitude, latitude, and elevation from the ICESat-2, ATL03 photons (Zhao et al. 2023). Hence, a 3D building data can be used to estimate population more accurately. However, the population density per building may vary spatially and over time, influenced by the building functions. Offices for instance should be omitted during prediction. The detailed land use type per building may be beyond the scope of remote sensing data. That said, population estimation for informal settlements can be valuable, which is not included in the census data.\nHumanitarian response: the location and density of settlements could be used to evaluate the risk zones and potential loss due to natural disasters, integrated with deep learning from data like past disaster events, social media, and weather reports to forecast the affected areas and consolidate early-warning system. Te detailed methods may subject to the types of disasters (flooding/earthquake/landslide/volcanic eruptions..). Corresponding interventions (e.g. relocation of hospitals and residence within the risk zones) in relation to the local demographics of vulnerable groups can be integrated to reduce risks, complying to the Sendai Framework for Disaster Risk reduction 2015-2030. Nevertheless, the LULC classifications may already achieve this goal, albeit without building outline..\nAddressing systems & Statistical indicators: the location of buildings can be used to simulate transport demands and routing, hence planning a more robust transport system.\n\nOther possible uses of the data:\n\nPlanning support: The space between buildings / street width could be useful for analyzing the environmental conditions in urban public realm, guiding regulations on building heights – narrow streets with high buildings should be avoided, increasing wind speed and reducing daylight penetration.\n\n\n8.2.2.1 Accuracy\nThe accuracy is enhanced through the novel method using U-Net Model (mixup, self-training, distance weighting with Gaussian convolutions, and residual decoder blocks) (Sirko et al., n.d.). For randomly selected test data (Figure2c), the areas with potential bias are omitted, including those with vast rural land and empty area (.ibid).\n\n\n\n(Sirko et al, 2021)\n\n\nU-Net Model originates from biomed image semantic segmentation (Ronneberger, Fischer, and Brox 2015; Li et al. 2021), having wide range of applications in different fields, outperforming the original sliding-window convolutional network.\n\n\n\nU-Net Architecture (Ronneberger, Fischer and Brox, 2015)\n\n\nThe performance of open building data can be accessed from the confidence score. However, there is difference in the performance spatially. Some areas like single building in rural area and dessert terrain can have lower accuracy (Sirko et al., n.d.). In urban areas, large buildings may be split into smaller ones, with most cases seen in Egypt - Cairo (ibid.).\n\n\n\n(Sirko et al, 2021)"
  },
  {
    "objectID": "7_classification2.html#reflection",
    "href": "7_classification2.html#reflection",
    "title": "8  Classification 2",
    "section": "8.3 Reflection",
    "text": "8.3 Reflection\nAccuracy of LULC classification is essential for analysis. Various factors may contribute to the accuracy of model outputs. The quality of ground truth data could be improved in future development through novel channels like Dynamic World deploying crowdsourcing knowledge. High-resolution information from unmanned aerial vehicles can be used as the source.\nIn terms of urban planning, the information on Earth’s surface is sometimes not enough. A site with LULC being classified as urban land does not help the planners to identify which specific land use it is (although nightlight data can be used to imply some retail/high streets). Although land use maps are available from OSM or Digimap for example, those maps/data are usually incompatible with GEE or other processing software. Hence, it would be more powerful if the EO data can obtain land use information like offices, housing, etc. This may be done by scrapping/accessing planning application documents, or using crowdsourcing data and Google Maps, or analyzing the time people use those buildings. (Nevertheless, this might be too complicated and not worth the effort, compared to adding EO data (like air pollution) to the land use map as different layers, which already exist). Planners could use this information to refine planning guidance and masterplan. For instance, areas suffering from UHI could be assessed by land use to give further interventions. Residential land may require measures on passive cooling esp. at night while offices/retail areas may focus on daytime energy-saving appliances and effective sharing/co-working space. Public space and the private realm can also be identified with land use information, hence differentiating the interventions that could be taken.\n\n\n\n\nKarasiak, N., J.-F. Dejoux, C. Monteil, and D. Sheeren. 2022. “Spatial Dependence Between Training and Test Sets: Another Pitfall of Classification Accuracy Assessment in Remote Sensing.” Machine Learning 111 (7): 2715–40. https://doi.org/10.1007/s10994-021-05972-1.\n\n\nLi, Meng-Yi, Ding-Ju Zhu, Wen Xu, Yu-Jie Lin, Kai-Leung Yung, and Andrew W. H. Ip. 2021. “Application of U-Net with Global Convolution Network Module in Computer-Aided Tongue Diagnosis.” Journal of Healthcare Engineering 2021 (November): e5853128. https://doi.org/10.1155/2021/5853128.\n\n\nLovelace, Robin, Jakub Nowosad, and Jannes Muenchow. 2019. Chapter 12 Statistical Learning | Geocomputation with R. https://r.geocompx.org/spatial-cv.html.\n\n\nRonneberger, Olaf, Philipp Fischer, and Thomas Brox. 2015. “U-Net: Convolutional Networks for Biomedical Image Segmentation.” In, edited by Nassir Navab, Joachim Hornegger, William M. Wells, and Alejandro F. Frangi, 9351:234–41. Cham: Springer International Publishing. http://link.springer.com/10.1007/978-3-319-24574-4_28.\n\n\nSirko, Wojciech, Sergii Kashubin, Marvin Ritter, Abigail Annkah, Yasser Salah Eddine Bouchareb, Yann Dauphin, Daniel Keysers, Maxim Neumann, Moustapha Cisse, and John Quinn. n.d. “Continental-Scale Building Detection from High Resolution Satellite Imagery.”\n\n\nWeih, Robert C, and Norman D Riggan. n.d. “OBJECT-BASED CLASSIFICATION VS. PIXEL-BASED CLASSIFICATION: COMPARITIVE IMPORTANCE OF MULTI-RESOLUTION IMAGERY.”\n\n\nWilber, Jared. n.d. “Precision and Recall.” https://mlu-explain.github.io/precision-recall/.\n\n\nZhao, Yi, Bin Wu, Qiaoxuan Li, Lei Yang, Hongchao Fan, Jianping Wu, and Bailang Yu. 2023. “Combining ICESat-2 Photons and Google Earth Satellite Images for Building Height Extraction.” International Journal of Applied Earth Observation and Geoinformation 117 (March): 103213. https://doi.org/10.1016/j.jag.2023.103213."
  },
  {
    "objectID": "8_temperature.html#summary",
    "href": "8_temperature.html#summary",
    "title": "9  Temperature",
    "section": "9.1 Summary",
    "text": "9.1 Summary\n\n9.1.1 UHI and its impacts\nUHI is correlated with the material (e.g. darker surfaces absorb and retain more heat than reflective ones), vegetation that cools the environment through evapotranspiration and shading, building heights and road widths (e.g. low Sky View Factor reduces outgoing longwave radiation), hard surface that reduces the emitance of heat (as opposed to vegetation/soft surface) and air speed, etc. Some of the factors may also related to others. For example, low SVF with clusters of high-rise buildings can sometimes cause high wind speed and reflective building material.\nUHI has wide impacts socially, economically and environmentally on urban areas and its periphery:\n\n\n\n\n\n\n\npillars\nimpacts\n\n\n\n\nSocial\n\nHeat-related illness\nHigher mortality rate\n\n\n\nEconomic\n\nLower GDP in some areas\nLocal government and related sectors increase spending on coping with UHI impacts\n\n\n\nEnvironmental\n\nPositive feedback loop where people would use more energy for cooling at high temperature, increasing GHG emissions which further contributing to higher temperature..\nRising use of energy (burning fossil fuels) increases air pollution\n\n\n\n\n\n\n9.1.2 UHI and policy response\nDifferent policy strategies and scales can have varying outcomes on GHG emissions and related UHI impacts at non-identical rates. Global policies (and national policies) are broader and context-less, guiding the overall directions and providing some standard indicators (like New Urban Agenda and Sustainable Development Goals). In some ways, global policies may boost creativity and diversity in approaches to climate mitigation and adaptations.\nLocal policies tend to be more detailed, considering the context and implementation. However, the actual interventions/projects can diverge from the policy statements due to several reasons. First, limited resources (funding/technique/human capital) slow down policy enforcement by the government and other stakeholders. For example, (in the British planning system) the viability assessment can be provided by the developers to claim/negotiate for a lower amount of affordable housing provision than initially planned in the application to ensure the project delivery and viability (and so can the green infrastructure provision be reduced by this means!). Second, the quality of green infrastructure is usually not guaranteed, relying on the developers’ efforts. Plus, the interventions may not be in the location of demands. Usually people with more decision-making power vote for plans benefiting the wealthier neighborhoods, where people are less affected by the heat, neglecting the poorer ones (e.g. informal settlements). Third, implementations take time to become effective or accepted by the public, while the change in political conditions can influence the project objectives. Introducing projects that are operated by businesses and funded by the government, benefiting the public, would effectively mitigate this challenge as the external political factors may have limited impacts on project delivery."
  },
  {
    "objectID": "8_temperature.html#application",
    "href": "8_temperature.html#application",
    "title": "9  Temperature",
    "section": "9.2 Application",
    "text": "9.2 Application\nRemote sensing data steps in to cope with the detection of factors related to urban heat. For instance, albedo could be classified through LULC. Areas/buildings with reflective roofs would be areas of focus on introducing green roofs. Also, land surface temperature could be monitored using Sentinel data. The census/demographic data (or other social background information like redlining areas) can be incorporated into the temperature analysis, uncovering places that are most in need of mitigation and adaptation, providing equitable solutions to the residents while making justice changes to the neighborhood.\nThe building outline (pre)classified data such as Google open building data (see last week’s application section) can be applied to investigate urban morphology, implying street width and suggesting appropriate building height for each application. This could be included in the planning process at site-level, rather than using current planning guidance that depends on some zoning / special area regulation which is at area-scale and negotiable. The figure-ground map could also be used to masterplan the transport system. Borrowing the idea from Barcelona superblocks, the transformation of roads could be low-cost solution to promote sustainable mobility."
  },
  {
    "objectID": "8_temperature.html#reflection",
    "href": "8_temperature.html#reflection",
    "title": "9  Temperature",
    "section": "9.3 Reflection",
    "text": "9.3 Reflection\nThe applications of remote sensing data tend to be passive and focus on the aftermath analysis of urban challenges (heat/temperature and climate change, as well as natural disasters and illegal logging, etc.). This may be less valuable in reversing and recovering the loss to the city.\nFront-ended/active applications like incorporating the optimization of tree placement in the planning process through remote sensing techniques should increase the spread to cover more expansive areas. More similar approaches could be developed to increase the awareness of the applicability and usefulness of remote sensing data. It would also be valuable to form the quadruple helix collaboration between government, industry, academia and the public to develop innovative business plans for such applications, ensuring long-term use and maintenance.\nNevertheless, barriers in remote sensing data such as the temporal resolution and accuracy may limit the application scope. Although there could be efficient and reproducible project management plans, the actual acquisition of data may be time-consuming, lagging the data processing and analysis, delaying the interventions and rapid response. Comparable indicators/methods and agreed analytic frameworks would be needed to cope with the great diversity of contextual scenarios. Plus, the remote sensing surface temperature may not imply the trend of air temperature experienced by normal human.. This could be further proved with increasing the coverage of temperature sensors."
  }
]