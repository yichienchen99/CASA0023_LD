[
  {
    "objectID": "1_intro.html#summary",
    "href": "1_intro.html#summary",
    "title": "1¬† Introduction",
    "section": "1.1 Summary",
    "text": "1.1 Summary\n\n1.1.1 Sensors\nPassive\n\nAttribute: Sun energy reflection in EM wave, don‚Äôt emit EM waves\nExample: human eyes, satellite (e.g.¬†Wk2 sensor summary - WorldView-3)\n‚ùå Influenced by atmosphere haze(require atmosphere correction, no haze in outer space due to no atmosphere) and scattering (wavelength (e.g.¬†blue sky and orange sunset)), clouds and weather\n‚úîÔ∏è does not disturb the object or area of interest\n\nActive\n\nAttribute: Emit and receive EM wave / energy\nExample: radar, x-ray, LiDAR\n‚úîÔ∏è can pass clouds\n\n\n\n1.1.2 Four resolutions\n\nSpatial\n\nthe size of the raster grid per pixel (e.g.¬†20cm or 30m)\nLow spatial resolution: fast (short revisit time); High spatial resolution: costly\n\nSpectral\n\nSpectral signature (EM): Objects on Earth have difference wavelengths = Bands\n\nMulti-spectral data / image\nHyperspectral data / image: stack all colour bands\n\nTrue colour (human eye can see) and false colour (human cant see)\n‚ùå atmospheric window (atmospheric transmission / opacity, e.g.¬†water vapour, ozone, CO‚Ä¶)\nSpectroradiometer\n\nRadiometric\n\nidentify differences in light or reflectance, in practice this is the range of possible values.\nIncrease bit -> increase possible values\n8-bit sensor: 0-255; 11-bit sensor: 0-2047\nSentinel-2 is 12-bit (brightness levels from 0 ‚Äì 4095) (beyond True Colour Image (TCI) values)\n\nTemporal\n\nRevisit time of sensor\nHigh resolution / pixel -> low revisit = low cost and number [graph]\n\n\nTrade off between resolution and time (and cost)\n\n\n1.1.3 Practical\nOverview/Workflow (SNAP):\nDownload -> New project in SNAP -> Save downloaded file in a Data folder in the same directory as the project -> Open product/zipped data -> Select RGB-image channel (on product explorer panel right click product) => Fig. a,b,c\nTo inspect/change image display: -> Colour Manipulation panel (View -> Tool Windows) -> Change the range of histogram\nTo analyse spectral feature space: -> Scatter plot (under Analysis tab) => Fig. d\nTo mask the study area: -> Resampling to 20m (since both masking and the Tasseled Cap function require same resolution while B2/B3/B4/B8 are 10m and B11/B12 are 20m) -> Import vector (ESRI shapefile) -> Select the imported layer in layer manager -> Masking under Raster - Masks - Land/Sea Mask (select bands that would be used)\nTo reduce dimensionality via Tasseled Cap transformation : -> Apply transformation functions in Band Math -> Select RGB-image channel => Fig. e,f\nSince Landsat has different spatial resolution than Sentinel, the latter will be resampled again (upscale). And since the Sentinel data has been masked/selected useful bands for Tasseled cap, it will be masked again to select B1-B7.\nTo compare spectral reflectance: -> Make sure both data in the same resolution with the same bands -> Add polygons by land cover -> Export polygons as shapefiles -> Export both dataset as GeoTIFF -> Check in QGIS -> Compare in R using terra (or stars) => Fig. g,h & Table 1\n\n1.1.3.1 Sentinel and Landsat\n\nData availability depends on cloud cover, time, weather (sometimes study area may not have data under the filtered criteria)\nSentinel tends to have shorter download time than Landsat.\nLandsat has less available data in a given time range (due to slightly longer revisit time).\n\n\nSentinel and Landsat data in QGIS and SNAP\n\n\n\nSentinel-2\nLandsat (8-9 Operational Land Imager (OLI) and Thermal Infrared Sensor (TIRS))\n\n\n\n\nSpatial resolution\nResolutions varied for each bands. (E.g. 10m resolution for Band 2)\n30m resolution\n\n\nTemporal resolution\n10 days (5 days for combined constellation 2A & 2B)\n16 days\n\n\nSpectral resolution\n13 spectral bands\n9 spectral bands\n\n\nCentral wavelength\nB1 443nm = Band 1 has central wavelength of 442 nm\n\n\n\n\n\n\n\n\nProcess by Software\nQGIS\nSNAP\n\n\nColour composite\nmerge the BOA bands (B2, B3, B4, B8) to make true colour composite (B1=Blue, B2=Green, B3=Red)\nrecreate by changing RBG channels (Fig. a, b, c)\n\n\nEnhancement\nContrast enhancement\nImage histogram\n\n\nSpectral feature space\n\nScatter plot (Fig. d)\n\n\nResampling\n\nB11 and B12 are at a 20m resolution whereas all the others at a 10m resolution. -> resample others to 20m (upscale) Sentinel 2 resampling toolbox\n\n\n\n\nA) Traditional resample: considers the neighbouring pixels (time-efficient?)\nB) Sentinel 2 products resample: account for the particularities of the angle (satellite viewing) bands\n\n\nMasking\n\nMasks. Land/sea mask.\nCan only mask bands on the same resolution\n\n\nTasseled Cap function\n\nBand Maths.\nReduce dimensionality: (similar to PCA) spectral index combining two or more bands to highlight certain features of an image. Then change RGB channel to those new data to show results (Fig. e)\n\n\n\n\n\n1.1.3.2 Masking vs.¬†cropping\n\nmasking: the outline of the geo boundary\ncropping: to the extent, the rectangular parameter of the geo boundary\n\n\n\n1.1.3.3 Example: Processing of Sentinel and Landsat data of Kinmen County\nI‚Äôve chosen Kinmen County in Taiwan as my case study area for practical. It consists of several islands and is in close proximity to Xiamen, China. The main/largest island is the H-shaped one at the lower end of the first few maps (or see Fig. e).\nThis is where i spent the majority of summer in 2022 so i‚Äôve got some knowledge of the city/island‚Äôs land use. I also cycled a lot on this island (so having some sense of the topography). It is really enjoyable to cycle here as there is less traffic and more greenery. However, it tends to be slightly cloudy/rainy in certain months which may constrain the analysis. Anyhow, let‚Äôs see how it goes.\n\n1.1.3.3.1 Sentinel\nThe initial exploration using Sentinel data:\n\n\n\n\n\n\na) Natural colour\n\n\n\n\n\n\n\nb) False colour composite\n\n\n\n\n\n\n\n\n\nc) Atmospheric penetration composite\n\n\n\n\n\n\n\nd) Scatter plot (B4 Red - B8 NIR)\n\n\n\n\n\n\nFalse colour composite: B8, B4, B3. Plants reflect near-infrared and green light whilst absorbing red.\nAtmospheric penetration composite: B12, B11, B8A with no visible bands to penetrate atmospheric particles. Vegetation = blue, urban area = white, gray cyan or purple.\n\nBasically, Fig a,b,c show that the coastal city Xiamen‚Äôs built-up areas are mostly close to the seashore. This is mainly due to its historical ports that are open to international trades and thus becoming more urbanized. Kinmen Islands are less populous compared to Xiamen and the majority of land is bare soil / vegetation. Fig d shows that the dry bare soil is prominent in some areas (black dots at high B4 and high B8), while the image has large ratio of biomass (yellow peak at low B4 and high B8).\n\n\n1.1.3.3.2 Tasseled Cap function\nArcPro‚Äôs explanation:\nThe function is originally designed to monitor crop‚Äôs life cycle / changes through time.\n\nBrightness = bare or partially covered soil, man-made, and natural features such as concrete, asphalt, gravel, rock outcrops, and other bare areas\nGreenness = green vegetation\nWetness = soil moisture, water, and other moist features.\n\n‚úîÔ∏è Those three components of imagery contain about 97% of the meaningful information available in the image (removing noise and atmospheric effects).\n\n\n\n\n\n\ne) PCA / Tasseled Cap function transformed (May 2022)\n\n\n\n\n\n\n\nf) PCA / Tasseled Cap function transformed (November 2022)\n\n\n\n\n\n(Darker) blue and red areas are generally unchanged - representing water (lakes/reservoir/sea), soil and built-up area. The pink areas are built-up areas / concrete / asphalt / human-made (e.g.¬†southern inner bay‚Äôs long linear shape is the airport, and western area on the main island is the most populous town)\nGreenness in Fig. e is less than that in Fig. f, indicating the vegetation is less in May. During May (or generally spring time), there should be roughly similar amount of vegetation / crops, compared to November (autumn), while the crops during autumn reach maturity leading to more greenness in the latter figure.\nIt might also be the case that the light blue areas are soil moisture / higher humidity. As can be seen from both figures, the shaded blue areas in the central/slightly eastern-central location of the largest island is mountainous. The humidity can be higher there.\nAnother difference between the two images is that the redness is more intense in the first figure (more NIR?), while more organgy in the second. This indicates that the those areas are soil or bare areas. During autumn, the vegetation on those land increase, so the yellowness/greenness overlays.\n\n\n1.1.3.3.3 Landsat\nTo mitigate the atmospheric effects (cloudy and foggy from April to May and rainy during summer) (and also due to data availability), the sensing time for Landsat is in December.\n\n\n1.1.3.3.4 Compare spectral reflectance\n\n\n\n\n\n\ng) Spectral reflectance Sentinel\n\n\n\n\n\n\n\nh) Spectral reflectance Landsat\n\n\n\n\n\nThe ranges of the datasets are different visually. Landsat has higher mean reflectance for all land cover in all bands.\nFor both sensors, the relationship between each land cover is similar, with water, forest and grass having lowest reflectance, and albeit less visible in Sentinel, bare earth having highest reflectance.\nThen, t-test is conducted to test the difference in average of the land cover reflectance between two sensors.\n\nTable 1. Welch two sample t-test (Sentinel and Landsat)\n\n\nlandcover\nt\ndf\np-value\n\n\n\n\nlow_urban\n-129.55\n2224.5\n< 2.2e-16\n\n\nhigh_urban\n-289.79\n7115.3\n< 2.2e-16\n\n\nbare_earth\n-223.36\n7141.2\n< 2.2e-16\n\n\ngrass\n-71.533\n674.71\n< 2.2e-16\n\n\nforest\n-256.12\n7799.9\n< 2.2e-16\n\n\nwater\n-175.3\n270.91\n< 2.2e-16\n\n\n\nSince p-values are all below 0.05, the difference in average reflectance of Landsat and of Sentinel data is statistically significant.\n\n\n\ni) Landsat vs.¬†Sentinel (NASA, 2015)\n\n\nFig. i from NASA shows that spectral bands are similar between Landsat 8 and Sentinel-2, except TIRS. Hence, the comparison above is possible. However, the atmospheric transmission varies. Sentinel bands have higher atmospheric transmission rate (white areas) and relatively low reflectance across all land cover type. Conversely, most Landsat bands are in atmospheric windows (gery areas), which allow energy to pass through the atmosphere, thus resulting in higher reflectance.¬†\n\n\n\n1.1.3.4 QGIS vs.¬†SNAP\nQGIS:\n\neasy to check stuff / visualize outputs\n\nSNAP: pre-processing and analysing remotely sensed / raster data. For sentinel and other sensors comparison\n\nEasier to recreate TCC\nCan manually set the histogram / contract enhancement as in QGIS\nHaving data from multiple sensors in the same software that can be explored together\nbut it‚Äôs a pain to reopen a project.. and I found when setting up the project, it‚Äôs more straightforward to create a new project before opening up a product.\n\nTwo software can work together (using QGIS to check everything as did in CASA0005).\n\nwhen i checked GeoTIFFs and shapefiles in QGIS, nothing is shown.. so probably something went wrong when selecting POIs.\n\n\n\n\n1.1.4 Questions\n\nwhy in the practical book before Landsat when resampling Sentinel, the equation for brightness does not include B11 and B12 (but using 0.5082 and 0.1863)?\nA: It should be B11 and B12.\nFig e looks different in terms of colour scheme? Since the majority of the city is coloured in blue, what do the blueish areas represent/mean (physically those areas are vegetations/forests, shouldn‚Äôt those be in green)?\nA: It depends on the colour gun set by the RGB."
  },
  {
    "objectID": "1_intro.html#application",
    "href": "1_intro.html#application",
    "title": "1¬† Introduction",
    "section": "1.2 Application",
    "text": "1.2 Application\nOne more question would be what possible factors contribute to the difference in mean reflectance analysed above and how to mitigate the difference. Apart from the atmospheric window discussed above, the temporal difference in the sensing date (19th November 2022 for Sentinel and 19th December 2022 for Landsat) might contribute to difference in atmospheric effects and in path radiance / noise from sky irradiance and radiance from surrounding areas. Hence, to increase data consistency and reduce reflectance difference for similar sensors, removing atmospheric effects and noise is needed this could be done through linear regression methods (e.g.¬†to get surface reflectance for Sentinel using radiometric calibration method) (see Week 3). Moreover, Time-series-based Reflectance Adjustment (TRA) approach is developed to mitigate the drawbacks of fixed/global band transformation coefficients by considering difference in land cover type and locations (Shang and Zhu 2019a).\n\n\n\n\n\n\nNote\n\n\n\nHowever, if just using one sensor for analysis, there would be no/less concerns on the consistency issue?"
  },
  {
    "objectID": "1_intro.html#reflection",
    "href": "1_intro.html#reflection",
    "title": "1¬† Introduction",
    "section": "1.3 Reflection",
    "text": "1.3 Reflection\nThere are so many wrong decisions made when producing this analysis. And without solid understanding of concepts/theories, the practical is like a maze üëæ. It would be more efficient to do the practical after fully understanding every concept and data (although it is also rewarding to discover and learn from mistakes..). For instance, when comparing the spectral reflectance of Landsat and Sentinel, i selected band 1 to 7 for both sensors at first. However, after reading the paper by Shang and Zhu (2019b), i realized the wavelengths ranges/band numbers are different for both sensors (e.g.¬†NIR is band 5 in Landsat while 8A for Sentinel.) After modifying this mistake, the overall patterns do not change much, albeit slight difference in t-statistics.\n\n\n\n\nShang, Rong, and Zhe Zhu. 2019b. ‚ÄúHarmonizing Landsat 8 and Sentinel-2: A Time-Series-Based Reflectance Adjustment Approach.‚Äù Remote Sensing of Environment 235 (December): 111439. https://doi.org/10.1016/j.rse.2019.111439.\n\n\n‚Äî‚Äî‚Äî. 2019a. ‚ÄúHarmonizing Landsat 8 and Sentinel-2: A Time-Series-Based Reflectance Adjustment Approach.‚Äù Remote Sensing of Environment 235 (December): 111439. https://doi.org/10.1016/j.rse.2019.111439."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CASA0023 Learning Diary",
    "section": "",
    "text": "Preface\nThis website presents the online learning diary for CASA0023 Remote Sensing Cities and Environments 22/23. It contains brief overview of the weekly lectures including summary of key concepts, some practical outputs showing applications and examples of remote sensing techniques, open source applications from web source and literature, and individual reflection on the learnt concepts/techniques.\n\nAbout the author\n\nEducation\nYi-Chien Chen is currently the master student at CASA, UCL in the MSc Urban Spatial Science programme 2022/23. She studied urban planning at BSP, UCL during 2019-2022 and hold a BSc in Urban Planning, Design and Management.\n\n\nBio\nShe has some internship experience in architecture industry focusing on architecture design of residential high-rise complexes and one public space project in a mountainous area, in real estate agency doing quantitative market research, and a university career service role conducting a range of duties from data analysis to poster design. In this uni admin role, her fondness for figures and data grows. She was also a voluntary translator for ArchDaily as she‚Äôs interested in architecture and urban design.\nHer recent 2-week (but super productive!) work shadowing in summer 2022 with AECOM London office is the most relevant experience to her planning background, gathering information from the policy and qualitatively constructing design guidance and architecture models at neighbourhood level for the local authorities/government. In this experience, she met the GIS team virtually and see the demands on (geospatial) data-oriented planning policy recommendation and interventions.\nEmail: zcfther@ucl.ac.uk\nGitHub"
  },
  {
    "objectID": "index.html#content",
    "href": "index.html#content",
    "title": "CASA0023_LD",
    "section": "Content",
    "text": "Content\n\nIntroduction\n\n\nRemote sensing intro / sensors / resolutions\n\n\nSensor - WorldView3\nCorrections"
  },
  {
    "objectID": "index.html#structure-of-each-chapter",
    "href": "index.html#structure-of-each-chapter",
    "title": "CASA0023_LD",
    "section": "Structure (of each chapter)",
    "text": "Structure (of each chapter)\n\nSummary:\nContent summary (outputs from the practical, small code chunks with relevant explanation and flow charts)\nQuestions (data, methods, or applications)\nApplications:\nApplication of data / concepts / methods in literature / policy (largely sourced from weekly reading).\nReflection:\nA personal reflection on the presented content (e.g.¬†what was interesting, why and why might the data or tools presented this week be useful in the future to you or perhaps they won‚Äôt be useful but something similar might be)"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "CASA0023_LD",
    "section": "Education",
    "text": "Education\nUniversity College London"
  },
  {
    "objectID": "index.html#professional-experience",
    "href": "index.html#professional-experience",
    "title": "CASA0023_LD",
    "section": "Professional experience",
    "text": "Professional experience"
  },
  {
    "objectID": "index.html#interests",
    "href": "index.html#interests",
    "title": "CASA0023_LD",
    "section": "Interests",
    "text": "Interests"
  },
  {
    "objectID": "index.html#what-i-hope-to-get-from-the-module",
    "href": "index.html#what-i-hope-to-get-from-the-module",
    "title": "CASA0023_LD",
    "section": "What I hope to get from the module",
    "text": "What I hope to get from the module"
  },
  {
    "objectID": "2_portfolio.html#summary-application-and-reflection",
    "href": "2_portfolio.html#summary-application-and-reflection",
    "title": "2¬† Sensor-WorldView3",
    "section": "2.1 Summary, Application and Reflection",
    "text": "2.1 Summary, Application and Reflection\nA basic introduction on WorldView-3."
  },
  {
    "objectID": "intro.html#structure-of-each-chapter",
    "href": "intro.html#structure-of-each-chapter",
    "title": "Content",
    "section": "Structure (of each chapter)",
    "text": "Structure (of each chapter)\n\nSummary:\n\nContent summary (outputs from the practical, small code chunks with relevant explanation and flow charts)\n\n‚úîÔ∏è&‚ùå: indicate Pros and Cons of specific idea / concept / object‚Ä¶\n\nQuestions (data, methods, or applications)\n\nApplications:\n\nApplication of data / concepts / methods in literature / policy (largely sourced from weekly reading).\n\nReflection:\n\nA personal reflection on the presented content (e.g.¬†what was interesting, why and why might the data or tools presented this week be useful in the future to you or perhaps they won‚Äôt be useful but something similar might be)"
  },
  {
    "objectID": "1_intro.html",
    "href": "1_intro.html",
    "title": "1¬† Introduction",
    "section": "",
    "text": "2 Summary"
  },
  {
    "objectID": "1_intro.html#sensors",
    "href": "1_intro.html#sensors",
    "title": "1¬† Introduction",
    "section": "2.1 Sensors",
    "text": "2.1 Sensors\n\nPassive (Sun energy reflection in EM wave, don‚Äôt emit EM waves)\n\nExample: human eyes, satellite\nCon: Atmosphere Haze (require atmosphere correction, no haze in outer space due to no atmosphere) and scattering (wavelength (e.g.¬†blue sky and orange sunset)), clouds and weather\n\nActive (emit and receive EM wave / energy)\n\nExample: radar, x-ray, LiDAR\nPro: can pass clouds"
  },
  {
    "objectID": "1_intro.html#four-resolutions",
    "href": "1_intro.html#four-resolutions",
    "title": "1¬† Introduction",
    "section": "2.2 Four resolutions",
    "text": "2.2 Four resolutions\n\nSpatial\n\nPro: fast\nCon: costly\n\nSpectral\n\nSpectral signature (EM): Objects on Earth have difference wavelengths = Bands\n\nMulti-spectral data / image\nHyperspectral data / image: stack all colour bands\n\nTrue colour (human eye can see) and false colour (human cant see)\nCon: atmospheric window (atmospheric transmission / opacity, e.g.¬†water vapour, ozone, CO‚Ä¶)\nSpectroradiometer\n\nRadiometric\n\nCell/ pixel\nIncrease bit -> increase possible values\n8-bit\n\nTemporal\n\nRevisit time of sensor\nHigh resolution / pixel -> low revisit = low cost and number [graph]\n\n\nTrade off between resolution and time (and cost)\n\n2.2.1 Questions"
  },
  {
    "objectID": "3_corrections.html#summary",
    "href": "3_corrections.html#summary",
    "title": "3¬† Corrections",
    "section": "3.1 Summary",
    "text": "3.1 Summary\n\n3.1.1 Corrections\n\n3.1.1.1 Geometric Corrections\n\nTo reduce geometric distortion\nOff-Nadir -> Nadir\n\n\nGround central point: GCP\n\nA ground control point (GCP) is a location on the surface of the Earth (e.g., a road intersection) that can be identified on the imagery and located accurately on a map.\n(Objects (e.g.¬†building) on the image that do not move, as the reference point of corrections.)\n\n\n\nCoordinates of each GCP -> linear regression\nReduce error <- increase GCP\nRequirement for corrections:\n\nsame resolution (resampling)\nsame CRS (reprojecting)\n\n\n\nImage-to-map rectification (rectify remotely sensed data to a standard map projection)\nImage-to-image registration (remotely sensed data used in conjunction with other spatial information in a GIS)\n\n\nForward (input-to-output) mapping\n\nForward mapping\n\nX: original image -> Y: target image\n\n\n\n‚úîÔ∏èrectify the location of discrete coordinates found along a linear feature such as a road in a vector map\n‚ùåpossibility of points outside ‚Äògold standard‚Äô (the rectified/targeted image) -> output matrix pixel with no output value\n\nInverse (output-to-input) mapping\n\nBackward mapping\n\nX: target image -> Y: original image\n\n\n‚úîÔ∏è use points on ‚Äògold standard‚Äô to match point on original data\n\n\n\n\nForward and inverse mapping (Jensen, 2015)\n\n\n\nMoisaicking\n\nMosaicking\n\nMoisaicking is the process of combining multiple images into a single seamless composite image.\n\n\n\ncut-line feathering: offset the edge of images by certain distance\nedge feathering: specify objects (e.g.¬†roads/rivers) as edge\n\n\n\n\n3.1.1.2 Practical: Merging imagery\nAlthough Kinmen County is rather a small area, covered sufficiently within one tile of the Landsat imagery, another adjacent tile would be chosen to practice merging.\n\n\n3.1.1.3 Atmospheric Corrections\n\nTo mitigate the effect of scattering and absorption & to avoid loss of reflectance & signiture extension thorough space and time (Jensen 2015)\nPoint Spread Function\n\nPoint Spread Function\n\nMeasured and modeled point spread functions (PSF) of sensor systems indicate that a significant portion of the recorded signal of each pixel of a satellite image originates from outside the area represented by that pixel. This hinders the ability to derive surface information from satellite images on a per-pixel basis (Huang et al. 2002).\n\n\nRelative\n1) to normalize the intensities among the different bands within a single-date remotely sensed image, and 2) to normalize the intensities of bands of remote sensor data in multiple dates of imagery to a standard scene selected by the analyst.\n\nDark object subtraction (DOS)\n‚ùå assuming unusual brightness of darkest pixel as atmosphere\nMultiple-date image normalization using regression\n\nPseudo-Invariant Features (PIFs) selection = radiometric GCP\nRequirements of PIF: 1) little changes through time; 2) similar elevation as other land in scene; 3) minimal vegetation; 4) in a relatively flat area.\n\nUse middle of years, Y: base image\n\nAbsolute\n‚ùå High data requirement (fieldwork/‚Ä¶); High software requirement (costy)\n‚úîÔ∏èDigital counts in satellite / aircraft image data -> scaled surface reflectance\n\nEmpirical Line Calibration (ELC)\n\nRequirements:\n\nTwo or more areas in the scene with different albedos (e.g., one bright target such as sand and one dark target such as a deep, nonturbid water body) & as homogeneous as possible <- difficult.\nSensor calibration coefficients\nRadiative transfer code (knowledge of sensor spectral profile & atmospheric properties at the time of data collection) (Jensen 2015)\n\n\n\n\n\n\n3.1.1.4 Topographic Corrections (Orthorectification)\n\nTo remove topographically induced illumination variation\n\nIllumination\n\nthe cosine of the incident solar angle, thus representing the proportion of the direct solar radiation hitting a pixel.\n\n\nRequirements: sensor geometry & elevation model\nShould be done after atmospheric corrections\nCosine Function: \\(LH=LT\\frac{cosŒ∏O}{cosi}\\)\n\nZenith\n\nThe solar zenith angle is the zenith angle of the sun, i.e., the angle between the sun‚Äôs rays and the vertical direction. Solar zenith angle is normally used in combination with the solar azimuth angle to determine the position of the Sun as observed from a given location on the surface of the Earth.\n\nAzimuth\n\nThe solar azimuth angle is the azimuth (horizontal angle with respect to north) of the Sun‚Äôs position.\n\n\n\n\n\n\nZenith angle and cosine function (Jensen, 2015)\n\n\n\n‚ùå not considering diffuse skylight / light reflected from surrounding mountainsides\nsmaller cos i -> greater over-correction (Jensen 2015)\n\n\n\n3.1.1.5 Radiometric Calibrations\n\nDigital number of each pixel = raw, unitless\nRegression = unit\nReflectance (BOA) = comparable\nTOA radiance -> TOA reflectance = no light\nSurface reflectance = no light, no atmosphere\nHemispherical reflectance (e.g.¬†in Labs)\nApparent reflectance\n\n\n\n\n3.1.2 Enhancement\n\n3.1.2.1 Feathering / joining\n\nGEE: median\nsurface reflectance data not comparable -> standardization, normalization\n\n\n\n3.1.2.2 Image Enhancement\n\nContract enhancement (QGIS)\n‚úîÔ∏è not changing data, but the display\nRatioing\ndivide / compare bands with each other, normalized surface reflectance\n‚úîÔ∏è identify a certain landscape feature\nExample: Normalised Difference Vegetation Index (NDVI)\nFiltering\nPCA\nTexture analysis\n1st order occurrence: ‚úîÔ∏èclassification\nEdge of building enhanced via 1st order variance\n2nd order co-occurrence: ‚úîÔ∏èclassification improvement and additional info (to other bands)\ncan then be used in PCA\nFusion\nCombine bands from different sensors / texture analysis layer\nResampling - different pixel/location\n\nDecision\nObject\nImage\nPan sharpen: for better visualization\n\n\n\n\n\n3.1.3 Questions"
  },
  {
    "objectID": "3_corrections.html#application",
    "href": "3_corrections.html#application",
    "title": "3¬† Corrections",
    "section": "3.2 Application",
    "text": "3.2 Application\n\n3.2.1 Corrections\n\nGeometric Corrections: Redlining in the US.\nThe historical maps/plans were drawn by hands. Those maps were digitized through geometric corrections, allowing the research/manipulation of this database on housing policy relating to socio-economic wellbeing and zoning.\n\n\n\nRedlining historic map corrections"
  },
  {
    "objectID": "3_corrections.html#reflection",
    "href": "3_corrections.html#reflection",
    "title": "3¬† Corrections",
    "section": "3.3 Reflection",
    "text": "3.3 Reflection\nDifferent methods of corrections are interlinked, finding some reference points/signatures to rectify the image. The detailed processes (like regressions and data collection methods) are difficult to digest (probably because not being practiced) while the software is available for corrections.\n\n\n\n\nHuang, Chengquan, John R. G. Townshend, Shunlin Liang, Satya N. V. Kalluri, and Ruth S. DeFries. 2002. ‚ÄúImpact of Sensor‚Äôs Point Spread Function on Land Cover Characterization: Assessment and Deconvolution.‚Äù Remote Sensing of Environment 80 (2): 203‚Äì12. https://doi.org/10.1016/S0034-4257(01)00298-X.\n\n\nJensen, John R. 2015. Introductory Digital Image Processing. 4th ed. A Remote Sensing Perspective. Pearson Higher Education US."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "4¬† Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "dictionary.html",
    "href": "dictionary.html",
    "title": "7¬† Dictionary",
    "section": "",
    "text": "8 Dictionary / Terminology\nGround central point: GCP"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "‚ÄúA Comparison of Greenspace Loss and Urban Expansion over Time in\nLondon and Nairobi  EOES Hub.‚Äù 2017. https://blogs.kcl.ac.uk/eoes/2017/03/23/a-comparison-of-greenspace-loss-and-urban-expansion-over-time-in-london-and-nairobi/.\n\n\nCardille, Jeffrey A., Gennadii Donchyts, Ujaval Gandhi, Txomin\nHermosilla, Saverio Francini, Andr√©a P. Nicolau, and Michael A. Wulder.\nn.d. ‚ÄúF4 - Earth Engine Fundamentals and Applications - EEFA -\nLive Document.‚Äù https://docs.google.com/document/d/11oo1TuvXyEvReoYLDeTcoh16rEN90I8Bf5qp0KxVu7U/edit?usp=embed_facebook.\n\n\nChen, Tzu-Ling, Hung Lin, and Yin-Hao Chiu. 2022. ‚ÄúHeat\nVulnerability and Extreme Heat Risk at the Metropolitan Scale: A Case\nStudy of Taipei Metropolitan Area, Taiwan.‚Äù Urban\nClimate 41 (January): 101054. https://doi.org/10.1016/j.uclim.2021.101054.\n\n\nGandhi, Ujaval, and Jeff Howarth. n.d. ‚ÄúF1 - Earth Engine\nFundamentals and Applications - EEFA - Live Document.‚Äù https://docs.google.com/document/d/1dLSaGXlAnI0jK6LAB6F-gQLBA30NTT0pz1tovHfOmvI/edit?usp=sharing&usp=embed_facebook.\n\n\nGISGeography. 2014. ‚ÄúImage Classification Techniques in Remote\nSensing.‚Äù https://gisgeography.com/image-classification-techniques-remote-sensing/.\n\n\nGorelick, Noel, Matt Hancher, Mike Dixon, Simon Ilyushchenko, David\nThau, and Rebecca Moore. 2017. ‚ÄúGoogle Earth Engine:\nPlanetary-Scale Geospatial Analysis for Everyone.‚Äù Remote\nSensing of Environment, Big Remotely Sensed Data: tools,\napplications and experiences, 202 (December): 18‚Äì27. https://doi.org/10.1016/j.rse.2017.06.031.\n\n\nHuang, Chengquan, John R. G. Townshend, Shunlin Liang, Satya N. V.\nKalluri, and Ruth S. DeFries. 2002. ‚ÄúImpact of Sensor‚Äôs Point\nSpread Function on Land Cover Characterization: Assessment and\nDeconvolution.‚Äù Remote Sensing of Environment 80 (2):\n203‚Äì12. https://doi.org/10.1016/S0034-4257(01)00298-X.\n\n\nJensen, John R. 2015. Introductory Digital Image Processing.\n4th ed. A Remote Sensing Perspective. Pearson Higher Education US.\n\n\nKarasiak, N., J.-F. Dejoux, C. Monteil, and D. Sheeren. 2022.\n‚ÄúSpatial Dependence Between Training and Test Sets: Another\nPitfall of Classification Accuracy Assessment in Remote Sensing.‚Äù\nMachine Learning 111 (7): 2715‚Äì40. https://doi.org/10.1007/s10994-021-05972-1.\n\n\nlanenok. 2015. ‚ÄúAnswer to \"When to Use Random Forest\nover SVM and Vice Versa?\".‚Äù https://datascience.stackexchange.com/a/6855.\n\n\nLi, Dongying, Galen D Newman, Bev Wilson, Yue Zhang, and Robert D Brown.\n2022. ‚ÄúModeling the Relationships Between Historical Redlining,\nUrban Heat, and Heat-Related Emergency Department Visits: An Examination\nof 11 Texas Cities.‚Äù Environment and Planning B: Urban\nAnalytics and City Science 49 (3): 933‚Äì52. https://doi.org/10.1177/23998083211039854.\n\n\nLi, Meng-Yi, Ding-Ju Zhu, Wen Xu, Yu-Jie Lin, Kai-Leung Yung, and Andrew\nW. H. Ip. 2021. ‚ÄúApplication of U-Net with Global Convolution\nNetwork Module in Computer-Aided Tongue Diagnosis.‚Äù Journal\nof Healthcare Engineering 2021 (November): e5853128. https://doi.org/10.1155/2021/5853128.\n\n\nLovelace, Robin, Jakub Nowosad, and Jannes Muenchow. 2019. Chapter\n12 Statistical Learning | Geocomputation with R. https://r.geocompx.org/spatial-cv.html.\n\n\nMacLachlan, Andrew, Eloise Biggs, Gareth Roberts, and Bryan Boruff.\n2021. ‚ÄúSustainable City Planning: A Data-Driven Approach for\nMitigating Urban Heat.‚Äù Frontiers in Built Environment\n6. https://www.frontiersin.org/articles/10.3389/fbuil.2020.519599.\n\n\nPal, M., and P. M. Mather. 2005. ‚ÄúSupport Vector Machines for\nClassification in Remote Sensing.‚Äù International Journal of\nRemote Sensing 26 (5): 1007‚Äì11. https://doi.org/10.1080/01431160512331314083.\n\n\nPragati21. 2020. ‚ÄúSVM AND RANDOM FOREST: A Case Study.‚Äù https://medium.com/@pandeypragati2112/svm-and-random-forest-a-case-study-6213da5be02f.\n\n\nRonneberger, Olaf, Philipp Fischer, and Thomas Brox. 2015. ‚ÄúU-Net:\nConvolutional Networks for Biomedical Image Segmentation.‚Äù In,\nedited by Nassir Navab, Joachim Hornegger, William M. Wells, and\nAlejandro F. Frangi, 9351:234‚Äì41. Cham: Springer International\nPublishing. http://link.springer.com/10.1007/978-3-319-24574-4_28.\n\n\nShang, Rong, and Zhe Zhu. 2019a. ‚ÄúHarmonizing Landsat 8 and\nSentinel-2: A Time-Series-Based Reflectance Adjustment Approach.‚Äù\nRemote Sensing of Environment 235 (December): 111439. https://doi.org/10.1016/j.rse.2019.111439.\n\n\n‚Äî‚Äî‚Äî. 2019b. ‚ÄúHarmonizing Landsat 8 and Sentinel-2: A\nTime-Series-Based Reflectance Adjustment Approach.‚Äù Remote\nSensing of Environment 235 (December): 111439. https://doi.org/10.1016/j.rse.2019.111439.\n\n\nSirko, Wojciech, Sergii Kashubin, Marvin Ritter, Abigail Annkah, Yasser\nSalah Eddine Bouchareb, Yann Dauphin, Daniel Keysers, Maxim Neumann,\nMoustapha Cisse, and John Quinn. n.d. ‚ÄúContinental-Scale Building\nDetection from High Resolution Satellite Imagery.‚Äù\n\n\nUstuner, Mustafa, Fusun Balik Sanli, and Barnali Dixon. 2015.\n‚ÄúApplication of Support Vector Machines for Landuse Classification\nUsing High-Resolution RapidEye Images: A Sensitivity Analysis.‚Äù\nEuropean Journal of Remote Sensing 48 (1): 403‚Äì22. https://doi.org/10.5721/EuJRS20154823.\n\n\nWang, Sherrie, George Azzari, Michelle Stuhlmacher, Ran Goldblatt, Erin\nTrochim, Zander Venter, and Sourangsu Chowdhury. n.d. ‚ÄúA1 - Earth\nEngine Fundamentals and Applications - EEFA - Live Document.‚Äù https://docs.google.com/document/d/1MIPIFMJakC6eNGOhlkXLcwjUKFyY6QJLHElzBCOfyn4/edit?usp=embed_facebook.\n\n\nWeih, Robert C, and Norman D Riggan. n.d. ‚ÄúOBJECT-BASED\nCLASSIFICATION VS. PIXEL-BASED CLASSIFICATION: COMPARITIVE IMPORTANCE OF\nMULTI-RESOLUTION IMAGERY.‚Äù\n\n\nWilber, Jared. n.d. ‚ÄúPrecision and Recall.‚Äù https://mlu-explain.github.io/precision-recall/.\n\n\nZhao, Yi, Bin Wu, Qiaoxuan Li, Lei Yang, Hongchao Fan, Jianping Wu, and\nBailang Yu. 2023. ‚ÄúCombining ICESat-2 Photons and Google Earth\nSatellite Images for Building Height Extraction.‚Äù\nInternational Journal of Applied Earth Observation and\nGeoinformation 117 (March): 103213. https://doi.org/10.1016/j.jag.2023.103213."
  },
  {
    "objectID": "4_policy.html#summary-reflection",
    "href": "4_policy.html#summary-reflection",
    "title": "4¬† Policy",
    "section": "4.1 Summary & Reflection",
    "text": "4.1 Summary & Reflection\n(the summary of the policy and city you have selected)\n(how the remotely sensed data you sourced could be used to assist with contributing to the policy goal. How could the data be applied to solve the policy challenge.)\n\n4.1.1 Policy Challenge in London\nThe 2021 London Plan incorporates Urban Heat Island (UHI) effect into the strategic spatial planning. Below are some themes/policies related to UHI.\n\n\n\n\n\n\n\nSolutions to mitigate & adapt UHI set by the Plan\nLinkage to remote sensing data\n\n\n\n\nEnsure efficiency and resilience in building and infrastructure design (GG6 B)\n\n\n\n(more towards adaptation) Set minimum building height to ensure daylight and ventilation (passive cooling) (3.6.3)\n(maybe) using SAR phasing to monitor the building heights, and Sentinel to measure the distance between building blocks, to find areas that would be most affected by insufficient indoor daylight and ventilation and act upon.\n\n\nGreen infrastructure provision in an integrated way (8.1)\nSuggesting/optimizing tree placement in new developments & public space (MacLachlan et al. 2021)\n\n\nGreen Belt protection (comply with NPPF) ‚Äìconstrain urban sprawl and drive re-use of previously developed brownfield land (8.2.1)\nMonitoring Green Belt & open greenspace\n\n\nUrban greening (street trees, green roofs, green walls, and rain gardens) (8.5.2)\nSuggesting/optimizing tree placement in new developments & public space (MacLachlan et al. 2021)\n\n\nManage heat risk through applying cooling hierarchy in new developments (through design, layout, orientation, materials and the incorporation of green infrastructure) (SI 4A; SI 4B; 9.4.1)\n\n\n\n\n\nLondon Green Belt\n\nLondon‚Äôs Green Belt provides an important long-term benefit for all those living in, around and visiting London; its landscape beauty and the haven it provides for an improved and thriving wildlife; its significant contribution to the mitigation of the climate emergency and enhancing people‚Äôs health and wellbeing; the facilities it offers for outdoor recreation, and its resource for food and farming close to London; all this in addition to its traditional role of containing urban sprawl and encouraging regeneration. (Source: CPRE, 2019)\n\n\n\n\n4.1.2 Green Belt and open space\nRough workflow:\n\nAnalyse spatial and temporal patterns of urban growth and loss of greenspace.\nInvestigate the quality of GB and open greenspace. (since it is found that densification of existing urban areas and development of inner-city brownfield sites are the main source of land use change, instead of expansion to GB which is controlled by GB policies in 2000 (‚ÄúA Comparison of Greenspace Loss and Urban Expansion over Time in London and Nairobi  EOES Hub‚Äù 2017))\n\n\n\n\n\n\n\n\n\n\n\nPro ‚úîÔ∏è | Con ‚ùå | | | | | | | |\n\n\n\n\n1 To measure heat vulnerability / temperature through LST\n1) strong correlations between LST and air temperature;\n2) Compared to other measures such as air and surface temperature values taken at meteorological stations with coarse spatial resolution, satellite imagery derived LST presents data at higher spatial resolutions, thereby enabling comparisons among different neighborhoods.\n1) does not fully capture the set of micrometeorological conditions that factor into human thermal comfort or heat stress;\n2) Some of the images might be covered by clouds, which could seriously affect LST estimates. => limit the data to only clear-sky images\n\n\n\nDataset\nMOD11A2 Level-3 MODIS Land Surface Temperature and Emissivity (LST/E) 8-day products (1-km resolution) (Chen, Lin, and Chiu 2022) ‚ùå Spatial resolution of 1-km might be too broad for land use analysis.. so may require downscaling (could be achieved based on the inverse relationship between LST and NDVI)\nECOSTRESS Land Surface Temperature and Emissivity products (Li et al. 2022) ‚úîÔ∏è Fine-scaled atmospherically-corrected imagery throughout diurnal cycles at a 70m spatial resolution base on MODIS data, which allows the estimation of daytime and nighttime LSTs. | SOLWEIG: localised temperature modelling(MacLachlan et al. 2021) Requirement: Elevation (EO: OSM+ CSIRO) + Land cover data (EO: OSM+ CSIRO) + Meteorological data (air temperature, relative humidity, barometric pressure, wind speed, wind direction, and downward shortwave radiation) (e.g.¬†Perth International Airport weather station) ‚úîÔ∏è 1) compare temperature dynamics within low- and high-density urban areas; 2) use as a basis for assessing a planned redevelopment and how optimizing tree placement relative to modeled temperature values could assist in mitigating localized UHI impacts. ‚ùå Owing to these data frequently being unavailable in a spatially continuous form (e.g., raster data), the input required for SOLWEIG is often limited to point data, acquired from weather stations. |\n\n\n\n\n\n\n\n\n2 To see the boundary of GB (land cover / land use changes)\nSentinel ‚Äì> classification (veg vs land) (e.g.¬†a supervised classifier (Random Forest). (‚ÄúA Comparison of Greenspace Loss and Urban Expansion over Time in London and Nairobi  EOES Hub‚Äù 2017)\n\n\n\n\n\n\n\n4.1.3 Linkages to global goals\nThe 2030 Agenda for Sustainable Development tied ‚Äúsustainable cities and communities‚Äù to both safety and resilience (SDG 11)\nThe United Nation New Urban Agenda highlighted cities‚Äô importance to\n\n(g) Adopt and implement disaster risk reduction and management, reduce vulnerability, build resilience and responsiveness to natural and human-made hazards and foster mitigation of and adaptation to climate change;\n(h) Protect, conserve, restore and promote their ecosystems, water, natural habitats and biodiversity, minimize their environmental impact and change to sustainable consumption and production patterns.\nhttps://habitat3.org/the-new-urban-agenda/\n\nThe United Nation World Cities Report: fostering nature-based solutions and ecosystem services (5.4);\n\nNBSs are promising in the context of halting biodiversity loss and restoring urban ecosystem services in economically viable ways\nThe International Union for Conservation of Nature (IUCN) defines NBSs as ‚Äúactions to protect, sustainably manage, and restore (create) natural or modified ecosystems‚Äù that simultaneously address social challenges, providing both human well-being and biodiversity benefits.\nNBSs are aligned with the United Nations 2030 Agenda for Sustainable Development\nhttps://unhabitat.org/sites/default/files/2022/06/wcr_2022.pdf\n\n\n\n4.1.4 Advancing local, national and global approach\n(local)\nCurrent protection of GB: 1) protected from inappropriate development. 2)improvement projects (discrete cases)\nAdd-on values: Besides combating UHI (and preventing sprawl), GB also reduces air pollutions, provides local food source and enhances ecosystem and biodiversity. ¬†\nOptimization for plans: Global policies lack an effective data-driven approach in deriving optimal vegetative placement‚Äîparticularly for reducing the ever-increasing socio-economic and environmental impacts associated with UHI effects (MacLachlan et al. 2021)\nQuality and monitoring. ‚Äì long-term inspection of quality (changes through time and seasons ‚Äì identify key areas for improvements / where to spend money on)\n(national)\n(global)\nUrban planning rarely integrates biodiversity and ecosystem services into service and design, aside from demonstration projects. (World Cities Report)"
  },
  {
    "objectID": "4_policy.html#reflection",
    "href": "4_policy.html#reflection",
    "title": "4¬† Policy",
    "section": "4.2 Reflection",
    "text": "4.2 Reflection\nThis section will list the lessons learnt from the policy and remote sensing data application.\n\nRemote sensing data can be used effectively to reduce the labor-intensive work / 3-Ds work (e.g.¬†physically surveying and collecting data) and to some extent increase the accuracy of data collection.\nNational and global higher level policies and goals tend to be more generic and vague in terms of the solutions and approaches to reach the stated visions. Local policy and guidance, complying the higher level policies, tend to consider the contextual attributes. Thus, it can sometimes be difficult to provide one-size-fit-all solutions in local policy (and academic papers). Nevertheless, the case studies and more detailed guidelines may help in this context (from city planning perspective but many not for other themes like ecology and forestry), as well as the provision of tools and methods like the one on optimization of tree placement.\nSome challenges might not be under the control of the city. For instance, Green Belt is beyond the London metropolitan boundary and extend to wider areas. The regulation and effective maintenance might require collaboration from different local authorities. Plus majority of the land on Green Belt is privately owned..\nWhen writing papers, the recommendations / long-term solutions on how to reach the policy goals should be proposed in addition to the findings from the data.\n\n\n\n\n\n‚ÄúA Comparison of Greenspace Loss and Urban Expansion over Time in London and Nairobi  EOES Hub.‚Äù 2017. https://blogs.kcl.ac.uk/eoes/2017/03/23/a-comparison-of-greenspace-loss-and-urban-expansion-over-time-in-london-and-nairobi/.\n\n\nChen, Tzu-Ling, Hung Lin, and Yin-Hao Chiu. 2022. ‚ÄúHeat Vulnerability and Extreme Heat Risk at the Metropolitan Scale: A Case Study of Taipei Metropolitan Area, Taiwan.‚Äù Urban Climate 41 (January): 101054. https://doi.org/10.1016/j.uclim.2021.101054.\n\n\nLi, Dongying, Galen D Newman, Bev Wilson, Yue Zhang, and Robert D Brown. 2022. ‚ÄúModeling the Relationships Between Historical Redlining, Urban Heat, and Heat-Related Emergency Department Visits: An Examination of 11 Texas Cities.‚Äù Environment and Planning B: Urban Analytics and City Science 49 (3): 933‚Äì52. https://doi.org/10.1177/23998083211039854.\n\n\nMacLachlan, Andrew, Eloise Biggs, Gareth Roberts, and Bryan Boruff. 2021. ‚ÄúSustainable City Planning: A Data-Driven Approach for Mitigating Urban Heat.‚Äù Frontiers in Built Environment 6. https://www.frontiersin.org/articles/10.3389/fbuil.2020.519599.\n\n\nRahbar, Morteza, Mohammadjavad Mahdavinejad, Amir H. D. Markazi, and Mohammadreza Bemanian. 2022. ‚ÄúArchitectural Layout Design Through Deep Learning and Agent-Based Modeling: A Hybrid Approach.‚Äù Journal of Building Engineering 47 (April): 103822. https://doi.org/10.1016/j.jobe.2021.103822.\n\n\nWan, Da, Xiaoyu Zhao, Wanmei Lu, Pengbo Li, Xinyu Shi, and Hiroatsu Fukuda. 2022. ‚ÄúA Deep Learning Approach Toward Energy-Effective Residential Building Floor Plan Generation.‚Äù Sustainability 14 (13): 8074. https://doi.org/10.3390/su14138074."
  },
  {
    "objectID": "4_policy.html#summary-application",
    "href": "4_policy.html#summary-application",
    "title": "4¬† Policy",
    "section": "4.1 Summary & Application",
    "text": "4.1 Summary & Application\nThe lecture this week shows a range of policy relevant to remote sensing data, from urban heat island to air pollution to disaster response. The following summary will detail London‚Äôs policy response to Urban Heat Island effect and how can remote sensing be incorporated into the strategic planning and solve the current challenges. London Green Belt will be the focus in this entry but admittedly it can be a less effective/direct solution to tackle increasing temperature in the city.\n\n4.1.1 Policy Challenge in London\nThe 2021 London Plan incorporates Urban Heat Island (UHI) effect into the strategic spatial planning. Below are some themes/policies related to UHI.\n\n\n\n\n\n\n\nSolutions to mitigate & adapt UHI set by the Plan\nLinkage to remote sensing data\n\n\n\n\nEnsure efficiency and resilience in building and infrastructure design (GG6 B)\nNot RS‚Äôs specialty\n\n\n(more towards adaptation) Set minimum building height to ensure daylight and ventilation (passive cooling) (3.6.3)\n(maybe) using SAR phasing to monitor the building heights, and Sentinel to measure the distance between building blocks, to find areas that would be most affected by insufficient indoor daylight and ventilation and act upon.\n\n\nGreen infrastructure provision in an integrated way (8.1)\nSuggesting/optimizing tree placement in the hottest areas of new developments & public space (MacLachlan et al. 2021)\n\n\nGreen Belt protection (comply with NPPF) ‚Äìconstrain urban sprawl and drive re-use of previously developed brownfield land (8.2.1)\nMonitoring Green Belt & open greenspace [detailed below]\n\n\nUrban greening (street trees, green roofs, green walls, and rain gardens) (8.5.2)\nSuggesting/optimizing tree placement in the hottest areas of new developments & public space (MacLachlan et al. 2021)\nSuggesting green roof locations in areas with darker roofs and higher temperature.\n\n\nManage heat risk through applying cooling hierarchy in new developments (through design, layout, orientation, materials and the incorporation of green infrastructure) (SI 4A; SI 4B; 9.4.1)\nNot RS‚Äôs specialty, largely depends on design/project management/planning enforcement.\nNevertheless, energy-efficient architecture layout can be generated through deep learning (Wan et al. 2022)and Agent Based Modelling (Rahbar et al. 2022)!\n\n\n\n\nLondon Green Belt\n\nLondon‚Äôs Green Belt provides an important long-term benefit for all those living in, around and visiting London; its landscape beauty and the haven it provides for an improved and thriving wildlife; its significant contribution to the mitigation of the climate emergency and enhancing people‚Äôs health and wellbeing; the facilities it offers for outdoor recreation, and its resource for food and farming close to London; all this in addition to its traditional role of containing urban sprawl and encouraging regeneration. (Source: CPRE, 2019)\n\n\n\n\n4.1.2 Green Belt and open space\nRough workflow:\n\nAnalyse spatial and temporal patterns of urban growth and loss of greenspace.\nInvestigate the quality of GB and open greenspace. (since it is found that densification of existing urban areas and development of inner-city brownfield sites are the main source of land use change, instead of expansion to GB which is controlled by GB policies in 2000 (‚ÄúA Comparison of Greenspace Loss and Urban Expansion over Time in London and Nairobi  EOES Hub‚Äù 2017))\n\nTo see the boundary of GB (land cover / land use changes):\n\nSentinel ‚Äì> classification (veg vs land) (e.g.¬†a supervised classifier (Random Forest). (‚ÄúA Comparison of Greenspace Loss and Urban Expansion over Time in London and Nairobi  EOES Hub‚Äù 2017)\n\nTo measure heat vulnerability / temperature through LST:\n\n‚úîÔ∏è1) strong correlations between LST and air temperature;\n‚úîÔ∏è2) Compared to other measures such as air and surface temperature values taken at meteorological stations with coarse spatial resolution, satellite imagery derived LST presents data at higher spatial resolutions, thereby enabling comparisons among different neighborhoods.\n‚ùå1) does not fully capture the set of micrometeorological conditions that factor into human thermal comfort or heat stress;\n‚ùå2) Some of the images might be covered by clouds, which could seriously affect LST estimates. => limit the data to only clear-sky images\nMOD11A2 Level-3 MODIS Land Surface Temperature and Emissivity (LST/E) 8-day products (1-km resolution) (Chen, Lin, and Chiu 2022)\n\n‚ùå Spatial resolution of 1-km might be too broad for land use analysis.. so may require downscaling (could be achieved based on the inverse relationship between LST and NDVI)\n\nECOSTRESS Land Surface Temperature and Emissivity products (Li et al. 2022)\n\n‚úîÔ∏è Fine-scaled atmospherically-corrected imagery throughout diurnal cycles at a 70m spatial resolution base on MODIS data, which allows the estimation of daytime and nighttime LSTs.\n\nSOLWEIG: localised temperature modelling(MacLachlan et al. 2021)\n\nRequirement: Elevation (EO: OSM+ CSIRO) + Land cover data (EO: OSM+ CSIRO) + Meteorological data (air temperature, relative humidity, barometric pressure, wind speed, wind direction, and downward shortwave radiation) (e.g.¬†Perth International Airport weather station)\n‚úîÔ∏è 1) compare temperature dynamics within low- and high-density urban areas;\n‚úîÔ∏è 2) use as a basis for assessing a planned redevelopment and how optimizing tree placement relative to modeled temperature values could assist in mitigating localized UHI impacts.\n‚ùå Owing to these data frequently being unavailable in a spatially continuous form (e.g., raster data), the input required for SOLWEIG is often limited to point data, acquired from weather stations.\n\n\n\n\n4.1.3 Linkages to global goals\nThe 2030 Agenda for Sustainable Development tied ‚Äúsustainable cities and communities‚Äù to both safety and resilience (SDG 11)\nThe United Nation New Urban Agenda highlighted cities‚Äô importance to\n\n(g) Adopt and implement disaster risk reduction and management, reduce vulnerability, build resilience and responsiveness to natural and human-made hazards and foster mitigation of and adaptation to climate change;\n(h) Protect, conserve, restore and promote their ecosystems, water, natural habitats and biodiversity, minimize their environmental impact and change to sustainable consumption and production patterns.\nhttps://habitat3.org/the-new-urban-agenda/\n\nThe United Nation World Cities Report: fostering nature-based solutions and ecosystem services (5.4);\n\nNBSs are promising in the context of halting biodiversity loss and restoring urban ecosystem services in economically viable ways\nThe International Union for Conservation of Nature (IUCN) defines NBSs as ‚Äúactions to protect, sustainably manage, and restore (create) natural or modified ecosystems‚Äù that simultaneously address social challenges, providing both human well-being and biodiversity benefits.\nNBSs are aligned with the United Nations 2030 Agenda for Sustainable Development\nhttps://unhabitat.org/sites/default/files/2022/06/wcr_2022.pdf\n\n\n\n4.1.4 Advancing local, national and global approach\nLocal\n\nCurrent protection of GB: 1) protected from inappropriate development. 2) improvement projects (discrete cases)\nAdd-on values: Besides combating UHI (and preventing sprawl), GB also reduces air pollutions, provides local food source and enhances ecosystem and biodiversity. ¬†\nOptimization for plans: Global policies lack an effective data-driven approach in deriving optimal vegetative placement‚Äîparticularly for reducing the ever-increasing socio-economic and environmental impacts associated with UHI effects (MacLachlan et al. 2021)\nQuality and monitoring. ‚Äì long-term inspection of quality (changes through time and seasons ‚Äì identify key areas for improvements / where to spend money on)\n\nNational\n\nNational Planning Policy Framework (NPPF) states to protect the integrity of Green Belt. but does not mention how.\n\nGlobal\n\nUrban planning rarely integrates biodiversity and ecosystem services into service and design, aside from demonstration projects. (World Cities Report)\n\n\n\n4.1.5 Question\nIs there any privacy concern on monitoring via remotely sensed data? (e.g.¬†in the case of watering gardens, what if the residents get angry about being monitored and refuse to make changes?)"
  },
  {
    "objectID": "5_GEE.html#summary",
    "href": "5_GEE.html#summary",
    "title": "5¬† Google Earth Engine",
    "section": "5.1 Summary",
    "text": "5.1 Summary\nGoogle Earth Engine (GEE) is a geospatial processing service, analyzing near Earth‚Äôs surface at any space at scale. The key benefit of using GEE is that the datasets are cloud-hosted and efficient computations can be executed through servers (Gandhi and Howarth, n.d.).\n\nClient: browser; polygons imported from local\nServer: data storage; Earth Engine Objects\n\nMap, not looping: to just load the image collection once and use function to repeat the calculations for each image, ensure more efficient codes and computation. + know the amount of objects in the collection (otherwise the looping use x+1..)\n\n5.1.1 Scale\n\nscale = pixel resolution\nImages are pre-processed (cut into 256x256 tiles in original projection and resolution) (Gorelick et al. 2017)\n‚úîÔ∏è enable fast and efficient access and fast visualization (Gorelick et al. 2017)\n\n\n\n\n\n\nImportant\n\n\n\nTo ensure the consistency of the values across analysis, scale should be set. (explore pixel resolution values at different scales > set pixel resolution when Map.addLayer)\n\n\nScale is related to the spatial resolution of the datasets. For example, the scale of Landsat-8 10m and 30m has the same value. why? - the nominal/native resolution of Landsat-8 is at 30m.\nScale can be influenced by zoom levels.\nFor different purpose of analysis, the resolution / scale would be different. Continental level analysis may use coarse scale and forest/tree placement may require fine scale.\n\n\n\n5.1.2 Filter\n\nfor image (raster)\n\nby date\nby location (specified path and row)/boundary/polygon (imported shapefile or drawn manually) (similar to st.join/st.intersect)\nby bands\n\nfor feature (vector/polygon)\n\nby ID/attributes\n\n\n\n\n5.1.3 Reducer\n\nZonal statistics, similar to groupby\nSummarize lots of images to one image composite\n\nby median of the pixels in collections\n\nMedian is good for distinct/large difference in index values (e.g.¬†forest vs.¬†non-forest)\nbut.. not good when the area has few pixels > use the normalizing statistics (= percentiles) instead (high percentiles concentrate on top indicate the classifier is more robust)\nand.. not representing changes across seasons (esp.¬†for vegetation/crop/forest) > medians of the pixels in 4 seasons (divide the time series into 4 in a list) (Source: Google Earth)\n\nimage.reduceRegion: one boundary (e.g.¬†GLA boundary)\nimage.reduceRegions: sub-divided regions within a boundary (e.g.¬†Boroughs within GLA boundary) - more like zonal statistics\n\n\n\n\n\nFilter, map, reduce\n\n\n(Cardille et al., n.d.)\n\n\n5.1.4 Join\n\nspatial join\ncan be applied to 2+ datasets (e.g.¬†Landsat and Sentinel) and/or images\n\n\n\n5.1.5 Risk/limitation of using GEE\n\nuncertainty of future change in GEE openness (can be closed / charged)\nSAR phase data cannot be used on GEE. Need SNAP for this.\nGEE is better at live and year mapping but not good at joining and filtering (recommended workflow: GEE (reduce data size) > R/Python‚Ä¶ (analysis))"
  },
  {
    "objectID": "5_GEE.html#application",
    "href": "5_GEE.html#application",
    "title": "5¬† Google Earth Engine",
    "section": "5.2 Application",
    "text": "5.2 Application\nApplications utilizing the benefits of GEE in analyzing changes through timelapse and comparing across locations.\n\n5.2.1 Map built-up area / urban expansion\nThis could be further integrated to analysis on urbanization challenges like UHI, flooding‚Ä¶\n\nGIF of the urbanization trajectories using Landsat 8 Level 2 Tier 1 (Wang et al., n.d., chap. A1.2)\n\n\n\n\nmy first GEE GIF!\n\n\n\nFollowing the practical by (Wang et al., n.d., chap. A1.2), the above GIF shows the 2010-2020 changes in the area of the Kempegowda International Airport in India visually (its now the fourth busiest airport in the country). Then it would be helpful to quantify the change in the areas by classification.\n\n\nUrban / LCLU classification\n\n\nMany datasets are available, with different coverage and properties. The MODIS Land Cover Type Yearly Global can be used to map the changes in urban areas (it is the global dataset!) (Wang et al., n.d., chap. A1.2)\n\n\n\n5.2.2 UHI\n\nMODIS & Landsat (EE LST toolbox) can all be used to calculate land surface temperature (LST) (Wang et al., n.d., chap. A1.5). Since surface UHI is the urban temperature subtracts rural reference, the rural/urban classification in the previous section can be applied to 1) mask the urban area for analysis 2) calculate the difference between urban and rural LST.\n\n\n\nSurface Urban Heat Island in Kinmen\n\n\nWith reference to (Wang et al., n.d., chap. A1.5), the above map shows the spatial variability in Surface UHI in summers between 2014 and 2019 for Kinmen County using Landsat-8. (Red pixels: higher (diff.max=8¬∞C); blue pixels: lower (diff.min=2¬∞C). Summer temperature is used here to avoid the difference in seasons balancing out the peak values. The built-up area is quite small, as the county is still urbanizing slowly with a population of 140,843 within a 151.6 km2 area in 2022 as per Wikipedia. (Thus this might not be a proper site for analyzing UHI). However, the intensity of UHI is high in the most populous town Jincheng (with population density of 1,946 ppl/km2, whereas the whole county‚Äôs density is 929 ppl/km2). Plus, the usual residents is 40% of the total census population. The elderly who live alone take up a large share of the usual residents. High temperature in the urban areas may increase the threats to those vulnerable groups.\nAnother hotspot is in the central-south of the island which is the location of the Airport. More specifically, that is the location of the Airport hall, bus stops, taxi and car park, while the runway of the Airport is not classified as urban by MODIS (yet the LST is also high on runway). High reflectance of the road and building material, the absence of trees and vegetation and (possibly) the high volume of GHG emissions may contribute to the high temperature in this area compared to its rural neighbours.\n\n\n\n5.2.3 Earth Engine APP\n\ndisplay large data and information quickly\ne.g.¬†using sliders to change the year + changing cities\n\n\n\n5.2.4 Question\nI cannot figure out why i cannot export image on GEE.."
  },
  {
    "objectID": "5_GEE.html#reflection",
    "href": "5_GEE.html#reflection",
    "title": "5¬† Google Earth Engine",
    "section": "5.3 Reflection",
    "text": "5.3 Reflection\nIn the application section, i think GIF is more efficient to show changes across time compared to sliders and A/B diagrams. Sometimes using sliders takes time to load the data and makes the comparison less direct, while showing A/B diagrams in the report may be restricted to the limited specified set of years (e.g.¬†2010 and 2020, instead of all the available time).\nWhen calculating the UHI, several familiar concepts from week 1 reoccur like the different surface reflectance for materials being sampled to determine the land cover type - done by the MODIS dataset. The transformation of the data where the brightness temperature and emissivity (based on fractional vegetation cover from NDVI) are combined to find LST - done by the EE toolbox/module within a few steps.\n\n\n\n\nCardille, Jeffrey A., Gennadii Donchyts, Ujaval Gandhi, Txomin Hermosilla, Saverio Francini, Andr√©a P. Nicolau, and Michael A. Wulder. n.d. ‚ÄúF4 - Earth Engine Fundamentals and Applications - EEFA - Live Document.‚Äù https://docs.google.com/document/d/11oo1TuvXyEvReoYLDeTcoh16rEN90I8Bf5qp0KxVu7U/edit?usp=embed_facebook.\n\n\nGandhi, Ujaval, and Jeff Howarth. n.d. ‚ÄúF1 - Earth Engine Fundamentals and Applications - EEFA - Live Document.‚Äù https://docs.google.com/document/d/1dLSaGXlAnI0jK6LAB6F-gQLBA30NTT0pz1tovHfOmvI/edit?usp=sharing&usp=embed_facebook.\n\n\nGorelick, Noel, Matt Hancher, Mike Dixon, Simon Ilyushchenko, David Thau, and Rebecca Moore. 2017. ‚ÄúGoogle Earth Engine: Planetary-Scale Geospatial Analysis for Everyone.‚Äù Remote Sensing of Environment, Big Remotely Sensed Data: tools, applications and experiences, 202 (December): 18‚Äì27. https://doi.org/10.1016/j.rse.2017.06.031.\n\n\nWang, Sherrie, George Azzari, Michelle Stuhlmacher, Ran Goldblatt, Erin Trochim, Zander Venter, and Sourangsu Chowdhury. n.d. ‚ÄúA1 - Earth Engine Fundamentals and Applications - EEFA - Live Document.‚Äù https://docs.google.com/document/d/1MIPIFMJakC6eNGOhlkXLcwjUKFyY6QJLHElzBCOfyn4/edit?usp=embed_facebook."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Content",
    "section": "",
    "text": "Introduction\n\nRemote sensing data intro / sensors / resolutions (using QGIS/SNAP/R)\n\nSensor - WorldView3\nCorrections\n\nCorrections / Enhancements (using R)\n\nPolicy\nGEE\n\nFilter/reduce/map (using GEE)\n\nClassification\n\nPixel-based (supervised and unsupervised)\n\nClassification 2\n\nObject-based, sub-pixel, accuracy assessment\n\n\n\nStructure (of each chapter)\n\nSummary:\n\nContent summary (outputs from the practical, small code chunks with relevant explanation and flow charts)\n\n‚úîÔ∏è&‚ùå: indicate Pros and Cons of specific idea / concept / object‚Ä¶\n\nQuestions (data, methods, or applications)\n\nApplications:\n\nApplication of data / concepts / methods in literature / policy (largely sourced from weekly reading).\n\nReflection:\n\nA personal reflection on the presented content (e.g.¬†what was interesting, why and why might the data or tools presented this week be useful in the future to you or perhaps they won‚Äôt be useful but something similar might be)"
  },
  {
    "objectID": "6_classification.html#summary",
    "href": "6_classification.html#summary",
    "title": "6¬† Classification 1",
    "section": "6.1 Summary",
    "text": "6.1 Summary\nHuman is good at finding patterns in imagery while computers are not. The patterns / land cover types are useful for analysis, but it is tedious to digitize hugeamount of data manually. Hence, the task is given to the computers, extracting patterns from remote sensing data. Decision trees replicate human decisions on detecting patterns and making conclusions based on given information (expert system!). Multiple methods based on decision trees are developed to classify remote sensing image!\n\nImage classification: Segregate pixels of a remote sensing image into groups of similar spectral character / spectral categorical classification.\n\n\n6.1.1 3 types of image classification\n\nUnsupervised image classification\n\n\n\n\n(GISGeography, 2014)\n\n\nProcess: Clustering algorithm: K-means; ISODATA > number of clusters [Fewer clusters have more resembling pixels within groups. More clusters increase the variability within groups. (GISGeography 2014)] > manually assign land cover classes to each cluster\nNot know the class (except the number of cluster) before the process.\nScale: pixel-based\n\nSupervised image classification\n\n\n\n\n(GISGeography, 2014)\n\n\nProcess: Select representative training samples for each land cover class > generate a signature file, storing all training samples‚Äô spectral information > use the signature file to run a classification (through one of the classification algorithm: Maximum likelihood (normal distribution/parametric); Density slicing; Nearest neighbor; Minimum-distance; Principal components; Support vector machine (SVM); CART; RF; Iso cluster; Neural network) > pixel assignment > accuracy assessment\nPattern recognition / ML\nScale: pixel-based\n\nCART: a tree\nRF: merging many trees, trained with bagging methods (to create a combination of learning models which improves the overall result)\nSVM: optimal multi-dimensional decision hyperplane boundary that divides the dataset (test all possibilities of C and Gamma > compare with testing data > choose the combination with best accuracy)\n\n\nObject-based image analysis (OBIA)\n\n\n\n\n(GISGeography, 2014)\n\n\nSegmentation algorithms: Multi-resolution segmentation in eCognition; The segment mean shift tool in ArcGIS > different methods to classify objects (shape; texture; spectral; geographic context; nearest neighbor)\nScale: object-based.. (groups pixels into representative vector shapes/objects)\n\n\n\n\n\n\nNote\n\n\n\n‚úîÔ∏è: Esp. good for high spatial resolution image by avoiding the noisiness in the outputs of pixel-based methods, more like human in processing patterns. Because OBIA used both spectral and contextual information, it had higher accuracy compared to pixel-based methods (when comparing high and medium spatial resolution imagery) (Weih and Riggan, n.d.). > gaining popularity due to increasingly amount of high-resolution data available! More in next chapter..\n\n\n\n\n6.1.2 Overfitting (of trees)\n\nhave leaves with one pixel value.. Large difference between predicted values and true value (= high bias = oversimplified model); High variability of a model for a given point (= high variance = not generalize enough)\n\n\n6.1.2.1 2 methods to balance bias and variance\n\nLimit the minimum number of pixels in leaves (usually 20 pixels) = top-down, easier to perform, but less mathematically sound.\nWeakest link pruning with tree score (find the weakest link and delete it) = bottom-up.\n\nTree score = SSR + tree penalty (alpha) * T(number of leaves)\nFor all data > Use alpha=0 for all data (=full tree = SSR) > increase alpha values > find the Alpha with lowest tree score compared to the full tree when decreasing number of leaves\nTrain and test split > Use the Alpha for train data > new trees > put test data in new trees > calculate SSR for test data > find the tree/alpha with the smallest SSR\nRepeat 10 times the above train and test split (using different data combinations) > find the alpha with lowest SSR across 10 repetitions\nApply this final alpha to the whole data\n\n\n\n\n\n6.1.3 Questions:\n\n(Practical) Whats the difference between .reduce(ee.Reducer.median()) and .median() ??\n\n\nTested - mostly no difference in the outputs. but the band name becomes B1_median when using reducer.median..\n\n\n\noutput using .reduce\n\n\n\n\n\noutput using .median\n\n\n\n\n(Practical) Why the background vector map is not consistent with the remote sensing map (like the roads and buildings are not in the same position, see below snapshot)? Will this influence the data selection and accuracy (i assume other datasets may also have different consistency)?\n\n\n\n(A: projection, but dont bother..)\n\n\n(Practical) How to select high and low urban samples for training for supervised classification? (High and low as of albedo or as of density? Based on Andy‚Äôs practical workbook, it is albedo. Is this for analyzing the impact of albedo/building material on the micro-climate and earth surface temperature?)\n\n\nA: Albedo - building reflectence - analysing the energy and temperature. For density - Google building data - areas of building / area of whole pixel ..\n\n\n(Practical) Error occur when trying to print the training data after selecting different land cover as feature collection: FeatureCollection: Collection query aborted after accumulating over 5000 elements.\n\n\nAnswers online: when printing the training data, use .limit(5000) to allow printing subset of large data. (not sure if it is the right way to do, but this is the checking process afterall) (and not sure why the data is so large..)"
  },
  {
    "objectID": "6_classification.html#application",
    "href": "6_classification.html#application",
    "title": "6¬† Classification 1",
    "section": "6.2 Application",
    "text": "6.2 Application\nClassification of EO imagery allows extracting (and predicting) patterns/land cover from the data. This supports analysis on LULC, urban expansion, urban green space, illegal logging, forest fire, etc.\n\n6.2.1 CART & Random Forest\nAs done in the practical, the Sentinel data is classified using CART and RF. When selecting training data (selecting land cover geometries as variables), the false inference on the landuse and the inclusion of other land cover type in the geometry may add noise to the prediction, hence lowering the accuracy. Also, mentioned in the practical, when splitting the data into training and testing (for accuracy testing), the pixels of the selected geometries should be used, rather than the geometry that may add more noise to the results.\n\n\n\nOutput from practical - land cover classification using CART\n\n\n\n\n\nOutput from practical - land cover classification using RF\n\n\nThe accuracy is not as high as Andy‚Äôs output. For RF, the OOB error is 6%.. and the accuracy is 93%. Resubstitution accuracy is 99% (original training data vs.¬†model output). When comparing testing data and model output, the accuracy gives 93%. > Is there any correlations between OOB accuracy and the confusion matrix? (and is it possible to add the legend to the output?)\nComparing two outputs visually, RF captures the difference in high and low urban land cover types better than CART. However, both methods produce outputs that seems like salt and pepper since they are pixel-based. Although the low urban type might exist in the forest (like meterological stations), it might not be necessary when drawing out the forest boundary. Object-based methods could be used for this purpose and for higher resolution building boundary detection for instance.\n\n\n6.2.2 SVM\n[Technical / methods] Study by (Ustuner, Sanli, and Dixon 2015) constructs the a classification model for agricultural landuse in Turkey using SVM method with RapidEye imargery. With fieldwork and Google Earth information on land cover types, it compares the classification accuracy with the result from Maximum Likelihood Classification (MLC) and internally among the results using different parameters (error penalty (C), gamma, bias term (r), polynomial degree (d)) and kernel types (linear, polynomial, radial basis function, sigmoid). Accuracy is assessed through kappa coefficient (comparing classified images against ground truth data). Results show that the SVM method outperforms MLC and classification accuracy is influenced by the choice of parameters (and kernels) (Ustuner, Sanli, and Dixon 2015). However, the generalization performance of kernels is influenced by the types of dataset (multi- or hyper-spectural or SAR‚Ä¶) so the conclusion on the best-performing kernel type is not fixed (may vary due to dataset).\n[Context / application] The country‚Äôs agricultural productivity highly influence its economy. However, the data on agricultural statistics is manually collected by government employees from farmers‚Äô declaration. The data could be unreliable (Ustuner, Sanli, and Dixon 2015) and labour-intensive, being not cost-effective for the government. Hence, methods like applying image classification on remote sensing data could provide viable, up-to-data and reliable information for sustainable crop management and planning. Before putting into practice, the sensitivity / reliability of the methods is tested through comparing between different models and within SVM using different parameters and kernels. The best combination of parameter and kernel will be used to inform decisions.\n\n\n\n(Ustuner, Sanli and Dixon, 2015)\n\n\n[Result / recommendation] The above output shows highest accuracy selections (compared to results from other models with different error penalty in the same kernel) of four different kernels from SVM + the result from MLC. Kappa for MS9 = 0.8209, MR5 = 0.8222, ML11 = 0.8223, MP9 = 0.8411. >> Recommendation from the authors: optimum parameters for SVM should be analyzed in detail before choosing one for best classification result.\nAnother study by (Pal and Mather 2005) suggests that SVM (using pair-wise comparison for multi-class) achieves higher accuracy than ML and ANN. Nevertheless, effective use depends on the values of a few user‚Äêdefined parameters. SVM in dealing with multi-class: n hyperplanes should be determined (comparing one class with the rest > may produce unclassified data, hence lowing the accuracy) or n(n-1)/2 classifiers (pair-wise comparison) (Pal and Mather 2005)."
  },
  {
    "objectID": "6_classification.html#reflection",
    "href": "6_classification.html#reflection",
    "title": "6¬† Classification 1",
    "section": "6.3 Reflection",
    "text": "6.3 Reflection\n\nWhich classifier to choose when performing image classification?\n\nReference to literature on relevant themes might hint the direction.\nPerforming/comparing different classifiers might just be within several lines of code in GEE. (but.. Does the accuracy means everything? Choosing the one with highest accuracy might not be reproducible in the sense that different regions/time of year/giving new data could yield varying results?)\nThe choice of classifier depends on the intended outcomes and the data quality (Pragati21 2020; lanenok 2015).\n\n> SVM > sparse data & binary classification & non-linear data (faster and better results, gives distance to boundary)\n> RF > numerical and categorical features & multi-class (gives probability of belonging to class)\n> MLC (parametric) > assuming normally distributed data (not common in LULC data > may results in lower accuracy)\n\n\nImage classification workflow: DN/reflectance of imagery > (some fieldwork / Google Earth selection of training land cover type data >) being divided based on similarities/closeness to each other using different forms of classifiers/algorithms > revealing/predicting the LULC of the Earth surface > testing accuracy > being used for further analysis / practical applications in assisting decision making\nIt seems like performing classification requires some knowledge on the study area‚Äôs land cover, especially classifying detailed land cover like agricultural landuse. From the ground truth map, different crop types usually looks similar to human eyes while obtaining different reflectance. Hence, field works would be required to collect in-situ point data using GPS and Google Earth ancillary data could be the additional data source with experts opinions (Ustuner, Sanli, and Dixon 2015).\nAdvancement in sensors increases the possibility of recording more data in the imagery, leading to better accuracy in predictions (RedEdge band in RapidEye for example).\n\n\n\n\n\nGISGeography. 2014. ‚ÄúImage Classification Techniques in Remote Sensing.‚Äù https://gisgeography.com/image-classification-techniques-remote-sensing/.\n\n\nlanenok. 2015. ‚ÄúAnswer to \"When to Use Random Forest over SVM and Vice Versa?\".‚Äù https://datascience.stackexchange.com/a/6855.\n\n\nPal, M., and P. M. Mather. 2005. ‚ÄúSupport Vector Machines for Classification in Remote Sensing.‚Äù International Journal of Remote Sensing 26 (5): 1007‚Äì11. https://doi.org/10.1080/01431160512331314083.\n\n\nPragati21. 2020. ‚ÄúSVM AND RANDOM FOREST: A Case Study.‚Äù https://medium.com/@pandeypragati2112/svm-and-random-forest-a-case-study-6213da5be02f.\n\n\nUstuner, Mustafa, Fusun Balik Sanli, and Barnali Dixon. 2015. ‚ÄúApplication of Support Vector Machines for Landuse Classification Using High-Resolution RapidEye Images: A Sensitivity Analysis.‚Äù European Journal of Remote Sensing 48 (1): 403‚Äì22. https://doi.org/10.5721/EuJRS20154823.\n\n\nWeih, Robert C, and Norman D Riggan. n.d. ‚ÄúOBJECT-BASED CLASSIFICATION VS. PIXEL-BASED CLASSIFICATION: COMPARITIVE IMPORTANCE OF MULTI-RESOLUTION IMAGERY.‚Äù"
  },
  {
    "objectID": "7_classification2.html#summary",
    "href": "7_classification2.html#summary",
    "title": "7¬† Classification 2",
    "section": "7.1 Summary",
    "text": "7.1 Summary\n\n7.1.1 OBIA\nCritique on pixel-based classification: Spatial autocorrelation (test/train) may influence the outcome of accuracy assessment (Tobler 1st Law)\n\nThis could be solved by\n\n1) applying distance filter/metrics or Moran‚Äôs I to the test / train data\n2) or classify the image by Object-based image analysis (OBIA)\n\nIf not consider SA ‚Äì model would be too good / high accuracy\n\n2 parameters for OBIA:\n\nDistance (between centroids/seeds)\nHomogeneity/similarity of pixels around the centroids\n\nThe output would be features of the objects (e.g.¬†mean of the pixel values) >> look like art rather than imagery\nApplications in medical and surgery (e.g.¬†cancer detection)\n\n\n7.1.2 Sub-pixel\nFraction of selected features per pixel > spectrally pure endmembers\nCons: difficult to assess accuracy (no test/train split) > harden\nApplications on pollution detection and % of vegetation\n\nspectrally pure ENDMEMBER selection: library (), lab, points/polygon (one point), value specification\nendmember * fraction >> unconstrained >> constrained (sum to one)\nif multiple points = MESMA\n\n\n\n7.1.3 Accuracy Assessment\nRandom sampling > test/train > model output > test output > matrix\nPA (producer accuracy): \\(\\frac{TP}{TP+FN}\\) == recall / sensitivity (correctly classified pixel vs.¬†groud truth data)\n\nHigh PA: Low FN and High FP: e.g.¬†predicted urban but actually other land cover type\n\n\n\nError of omission = 100-PA\n\nUA (user accuracy): \\(\\frac{TP}{TP+FP}\\) == precision (correctly classified pixel vs.¬†same class pixels as classified)\n\nHigh UA: High FN and Low FP: e.g.¬†predicted other but actually urban\n\n\n\nError of commission = 100-UA\n\nOA (overall accuracy): (TP+FP+FN+TN)\n\n\n\n\n\n\nNote\n\n\n\nPA and UA never both good: model with Low FN and Low FP does not exist. Since data is not balanced, changes in decision threshold of classification may vary the outcomes. Increasing FP (more predicted positive) > UA worsens > FN reduces > PA improves. The matrix are related and may change together. The trade-offs between the two make the ideal situation with high PA and high UA impossible.\nHence, one of them would be more important than the other under different scenarios and the one with higher relevance to the problem should be picked when analyzing accuracy and designing the model (Wilber, n.d.):\n\nRecall/PA is important when we believe False Negatives are more important than False Positives (e.g.¬†our problem of cancer detection).\nPrecision/UA is important when we believe False Positives are more important than False Negatives (e.g.¬†spam detection).\n\n\n\n\n7.1.3.1 F1 score\n\nF1 score\n\nTo solve the issue above with decision threshold, F1 score includes the information of both PA and UA in one single coefficient. \\(\\frac{TP}{TP+\\frac{1}{2}‚àó(FP+FN)}\\)\n\n\n\n\n\n(Wilber, 2022)\n\n\nWhen PA and UA are similarly well-performed, the F1 and Accuracy are also highest.\nCritiques on F1 score:\n\nNot considering TN\nAssuming UA and PA equally important\n\n\nOther matrix to assess accuracy: calibration, popular diagnostic tools (specificity, likelihood ratios, etc.), expectation frameworks, Receiver Operating Characteristic Curve (ROC), Area Under the Receiver Operator Characteristic Curve (AUROC) (popular for binomial model).\n\n\n\n7.1.3.2 Kappa\n\nKappa coefficient\n\nThe accuracy of an image compared to the results by chance\\(k=\\frac{p_o‚àíp_e}{1‚àíp_e}\\)\n\\(p_o\\): the proportion of cases correctly classified (accuracy)\n\\(p_e\\): expected cases correctly classified by chance\n\n\nCritiques on Kappa coefficient:\n\ndifferent definitions by authors in terms of good Kappa\ndifferent accuracy can have different ranges of kappa\n\n\n\n7.1.3.3 Cross validation\nData-splitting: based on simple, stratified, random selection.\nRepeated selection (resampling by bootstrapping): to compute the sampling variability of the accuracy metric (changing the split) (Karasiak et al. 2022)\nFind the average of different scenarios to test how generalisable the model is\nCritique on averaging accuracy:\n\nRandomly distributed points for testing may have spatial autocorrelation with nearby training data > influencing overestimating the accuracy / overfitting the model.\n\nSpatial cross validation\nTo mitigate issue with Spatial autocorrelation in Cross validation, randomly distributed clusters of points (clustering through Moran‚Äôs I, DBSCAN, Distance metrics..) are selected for testing (Lovelace, Nowosad, and Muenchow 2019).\n\nreference data are also split into subsets like in cross validation but the number of subsets can vary (k-fold) (Karasiak et al. 2022).\n\n\n\nk-fold > random sample > > best values of C and gamma for SVM > fold >> ML3 IN R > GEE not good at data analysis but for remote sensing data\n\n\n\n\n(Lovelace et al., 2019)\n\n\n\n\n\n\n\n\nNote\n\n\n\nmlr3 to split data for spatial CV:\n3 stages: 1) task: data specification (including response and predictor variables) and the model type (such as regression or classification). 2) learner defines the specific learning algorithm that is applied to the created task. 3) resampling approach assesses the predictive performance of the model, i.e., its ability to generalize to new data.\nDetailed example see (Lovelace, Nowosad, and Muenchow 2019).\n\n\nLeave one out (for everything except one point) ‚Äì more extreme / computationally extensive\n\n\n\n\n\n\nNote\n\n\n\nSelecting data for training / testing / accuracy:\n>> reproducible (same model for different years data) == (choose land that not change to much ‚Äì ¬†pseudo-invariant features) / (manual selection of ROI) / (choose same parcel/feature from different years = generalizable) == no fixed rules\n\n\n\n\n\n7.1.4 Questions\n\nWhat‚Äôs the neighborhood size (shouldn‚Äôt it be 100 if its 2*seed size)? When calculating std, why max size should be the same as NS?"
  },
  {
    "objectID": "7_classification2.html#application",
    "href": "7_classification2.html#application",
    "title": "7¬† Classification 2",
    "section": "7.2 Application",
    "text": "7.2 Application\nBelow are some examples of pre-classified data that could be imported in GEE.\n\n7.2.1 Dynamic world\n\nGEE data catalog\nNear real time data at 10m resolution (Sentinel-2 with 2-5 days revisit)\nProcess: World / region / biomes > experts / non-experts to label training pixels (5x5) > pre-processing (> TOA > rotate > band math/ratioing) > normalisation (log) > classification (CNN)\nCritique: Blobbing ‚Äì since ppl/users train data + CNN (deep learning, moving window of filtering..)\nWeird: worse the resolution of sentinel\nAccuracy (confusion matrix, but‚Ä¶)\n\n\n\n7.2.2 Google open building data\n\nGEE data catalog\n50cm high-resolution\nCurrently constrains to Africa, South Asia and South-East Asia locations\nInclude building info like outlines, footprints on the ground, confidence score (on if this is a building / accuracy), the centroid of the building. (not having info like building typology, address, and other details beyond geometry.)\n\n\n7.2.2.1 Application\nThoughts on applications suggested by developers:\n\nPopulation mapping: largely related to the population estimates based on building block. Estimating population based on building outline seems less convincing as the building height data is not assessed. This could be solved by combining the method of detecting building shades from satellite imagery and sample building height annotations with longitude, latitude, and elevation from the ICESat-2, ATL03 photons (Zhao et al. 2023). Hence, a 3D building data can be used to estimate population more accurately. However, the population density per building may vary spatially and over time, influenced by the building functions. Offices for instance should be omitted during prediction. The detailed land use type per building may be beyond the scope of remote sensing data. That said, population estimation for informal settlements can be valuable, which is not included in the census data.\nHumanitarian response: the location and density of settlements could be used to evaluate the risk zones and potential loss due to natural disasters, integrated with deep learning from data like past disaster events, social media, and weather reports to forecast the affected areas and consolidate early-warning system. Te detailed methods may subject to the types of disasters (flooding/earthquake/landslide/volcanic eruptions..). Corresponding interventions (e.g.¬†relocation of hospitals and residence within the risk zones) in relation to the local demographics of vulnerable groups can be integrated to reduce risks, complying to the Sendai Framework for Disaster Risk reduction 2015-2030. Nevertheless, the LULC classifications may already achieve this goal, albeit without building outline..\nAddressing systems & Statistical indicators: the location of buildings can be used to simulate transport demands and routing, hence planning a more robust transport system.\n\nOther possible uses of the data:\n\nPlanning support: The space between buildings / street width could be useful for analyzing the environmental conditions in urban public realm, guiding regulations on building heights ‚Äì narrow streets with high buildings should be avoided, increasing wind speed and reducing daylight penetration.\n\n\n\n7.2.2.2 Accuracy\nThe accuracy is enhanced through the novel method using U-Net Model (mixup, self-training, distance weighting with Gaussian convolutions, and residual decoder blocks) (Sirko et al., n.d.). For randomly selected test data (Figure2c), the areas with potential bias are omitted, including those with vast rural land and empty area (.ibid).\n\n\n\n(Sirko et al, 2021)\n\n\nU-Net Model originates from biomed image semantic segmentation (Ronneberger, Fischer, and Brox 2015; Li et al. 2021), having wide range of applications in different fields, outperforming the original sliding-window convolutional network.\n\n\n\nU-Net Architecture (Ronneberger, Fischer and Brox, 2015)\n\n\nThe performance of open building data can be accessed from the confidence score. However, there is difference in the performance spatially. Some areas like single building in rural area and dessert terrain can have lower accuracy (Sirko et al., n.d.). In urban areas, large buildings may be split into smaller ones, with most cases seen in Egypt - Cairo (ibid.).\n\n\n\n(Sirko et al, 2021)"
  },
  {
    "objectID": "7_classification2.html#reflection",
    "href": "7_classification2.html#reflection",
    "title": "7¬† Classification 2",
    "section": "7.3 Reflection",
    "text": "7.3 Reflection\n\n\n\n\nKarasiak, N., J.-F. Dejoux, C. Monteil, and D. Sheeren. 2022. ‚ÄúSpatial Dependence Between Training and Test Sets: Another Pitfall of Classification Accuracy Assessment in Remote Sensing.‚Äù Machine Learning 111 (7): 2715‚Äì40. https://doi.org/10.1007/s10994-021-05972-1.\n\n\nLi, Meng-Yi, Ding-Ju Zhu, Wen Xu, Yu-Jie Lin, Kai-Leung Yung, and Andrew W. H. Ip. 2021. ‚ÄúApplication of U-Net with Global Convolution Network Module in Computer-Aided Tongue Diagnosis.‚Äù Journal of Healthcare Engineering 2021 (November): e5853128. https://doi.org/10.1155/2021/5853128.\n\n\nLovelace, Robin, Jakub Nowosad, and Jannes Muenchow. 2019. Chapter 12 Statistical Learning | Geocomputation with R. https://r.geocompx.org/spatial-cv.html.\n\n\nRonneberger, Olaf, Philipp Fischer, and Thomas Brox. 2015. ‚ÄúU-Net: Convolutional Networks for Biomedical Image Segmentation.‚Äù In, edited by Nassir Navab, Joachim Hornegger, William M. Wells, and Alejandro F. Frangi, 9351:234‚Äì41. Cham: Springer International Publishing. http://link.springer.com/10.1007/978-3-319-24574-4_28.\n\n\nSirko, Wojciech, Sergii Kashubin, Marvin Ritter, Abigail Annkah, Yasser Salah Eddine Bouchareb, Yann Dauphin, Daniel Keysers, Maxim Neumann, Moustapha Cisse, and John Quinn. n.d. ‚ÄúContinental-Scale Building Detection from High Resolution Satellite Imagery.‚Äù\n\n\nWilber, Jared. n.d. ‚ÄúPrecision and Recall.‚Äù https://mlu-explain.github.io/precision-recall/.\n\n\nZhao, Yi, Bin Wu, Qiaoxuan Li, Lei Yang, Hongchao Fan, Jianping Wu, and Bailang Yu. 2023. ‚ÄúCombining ICESat-2 Photons and Google Earth Satellite Images for Building Height Extraction.‚Äù International Journal of Applied Earth Observation and Geoinformation 117 (March): 103213. https://doi.org/10.1016/j.jag.2023.103213."
  },
  {
    "objectID": "8_temperature.html#summary",
    "href": "8_temperature.html#summary",
    "title": "8¬† Temperature",
    "section": "8.1 Summary",
    "text": "8.1 Summary\nThis week‚Äôs lecture goes into the application of remote sensing data on urban temperature / Urban Heat Island (UHI) mitigation (mentioned under week 4 policy section of this learning diary as well) through several policy case studies in different cities/countries. This section will elaborate UHI impacts and some limitations of related policies.\n\n8.1.1 UHI and its impacts\nUHI is correlated with the material (e.g.¬†darker surfaces absorb and retain more heat than reflective ones), vegetation that cools the environment through evapotranspiration and shading, building heights and road widths (e.g.¬†low Sky View Factor reduces outgoing longwave radiation), hard surface that reduces the emitance of heat (as opposed to vegetation/soft surface) and air speed, etc. Some of the factors may also related to others. For example, low SVF with clusters of high-rise buildings can sometimes cause high wind speed and reflective building material.\nUHI has wide impacts socially, economically and environmentally on urban areas and its periphery:\n\n\n\n\n\n\n\npillars\nimpacts\n\n\n\n\nSocial\n\nHeat-related illness\nHigher mortality rate\n\n\n\nEconomic\n\nLower GDP in some areas\nLocal government and related sectors increase spending on coping with UHI impacts\n\n\n\nEnvironmental\n\nPositive feedback loop where people would use more energy for cooling at high temperature, increasing GHG emissions which further contributing to higher temperature..\nRising use of energy (burning fossil fuels) increases air pollution\n\n\n\n\n\n\n8.1.2 UHI and policy response\nDifferent policy strategies and scales can have varying outcomes on GHG emissions and related UHI impacts at non-identical rates. Global policies (and national policies) are broader and context-less, guiding the overall directions and providing some standard indicators (like New Urban Agenda and Sustainable Development Goals). In some ways, global policies may boost creativity and diversity in approaches to climate mitigation and adaptations.\nLocal policies tend to be more detailed, considering the context and implementation. However, the actual interventions/projects can diverge from the policy statements due to several reasons. First, limited resources (funding/technique/human capital) slow down policy enforcement by the government and other stakeholders. For example, (in the British planning system) the viability assessment can be provided by the developers to claim/negotiate for a lower amount of affordable housing provision than initially planned in the application to ensure the project delivery and viability (and so can the green infrastructure provision be reduced by this means!). Second, the quality of green infrastructure is usually not guaranteed, relying on the developers‚Äô efforts. Plus, the interventions may not be in the location of demands. Usually people with more decision-making power vote for plans benefiting the wealthier neighborhoods, where people are less affected by the heat, neglecting the poorer ones (e.g.¬†informal settlements). Third, implementations take time to become effective or accepted by the public, while the change in political conditions can influence the project objectives. Introducing projects that are operated by businesses and funded by the government, benefiting the public, would effectively mitigate this challenge as the external political factors may have limited impacts on project delivery."
  },
  {
    "objectID": "8_temperature.html#application",
    "href": "8_temperature.html#application",
    "title": "8¬† Temperature",
    "section": "8.2 Application",
    "text": "8.2 Application\nRemote sensing data steps in to cope with the detection of factors related to urban heat. For instance, albedo could be classified through LULC. Areas/buildings with reflective roofs would be areas of focus on introducing green roofs. Also, land surface temperature could be monitored using Sentinel data. The census/demographic data (or other social background information like redlining areas) can be incorporated into the temperature analysis, uncovering places that are most in need of mitigation and adaptation, providing equitable solutions to the residents while making justice changes to the neighborhood.\nThe building outline (pre)classified data such as Google open building data (see last week‚Äôs application section) can be applied to investigate urban morphology, implying street width and suggesting appropriate building height for each application. This could be included in the planning process at site-level, rather than using current planning guidance that depends on some zoning / special area regulation which is at area-scale and negotiable. The figure-ground map could also be used to masterplan the transport system. Borrowing the idea from Barcelona superblocks, the transformation of roads could be low-cost solution to promote sustainable mobility."
  },
  {
    "objectID": "8_temperature.html#reflection",
    "href": "8_temperature.html#reflection",
    "title": "8¬† Temperature",
    "section": "8.3 Reflection",
    "text": "8.3 Reflection\nThe applications of remote sensing data tend to be passive and focus on the aftermath analysis of urban challenges (heat/temperature and climate change, as well as natural disasters and illegal logging, etc.). This may be less valuable in reversing and recovering the loss to the city.\nFront-ended/active applications like incorporating the optimization of tree placement in the planning process through remote sensing techniques should increase the spread to cover more expansive areas. More similar approaches could be developed to increase the awareness of the applicability and usefulness of remote sensing data. It would also be valuable to form the quadruple helix collaboration between government, industry, academia and the public to develop innovative business plans for such applications, ensuring long-term use and maintenance.\nNevertheless, barriers in remote sensing data such as the temporal resolution and accuracy may limit the application scope. Although there could be efficient and reproducible project management plans, the actual acquisition of data may be time-consuming, lagging the data processing and analysis, delaying the interventions and rapid response. Comparable indicators/methods and agreed analytic frameworks would be needed to cope with the great diversity of contextual scenarios. Plus, the remote sensing surface temperature may not imply the trend of air temperature experienced by normal human.. This could be further proved with increasing the coverage of temperature sensors."
  }
]